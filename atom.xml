<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>awokezhou&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2023-02-02T11:56:16.247Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>awokezhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>SharedMemocry优化矩阵乘法</title>
    <link href="http://yoursite.com/2023/01/16/SharedMemocry%E4%BC%98%E5%8C%96%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/"/>
    <id>http://yoursite.com/2023/01/16/SharedMemocry优化矩阵乘法/</id>
    <published>2023-01-16T02:37:33.000Z</published>
    <updated>2023-02-02T11:56:16.247Z</updated>
    
    <content type="html"><![CDATA[<p>巧妙的使用共享内存Shared memory，能够减少线程对全局内存Global memory的访问，提升CUDA程序在访存方面的性能。本文以矩阵乘法为例，通过对比不使用共享内存的普通矩阵乘法实现和使用共享内存的矩阵乘法优化版本，展示共享内存对程序性能的提升，并分析使用共享内存的条件和注意点</p><h1 id="普通矩阵乘法"><a href="#普通矩阵乘法" class="headerlink" title="普通矩阵乘法"></a>普通矩阵乘法</h1><p>矩阵乘法的基本原理如下图所示</p><img src="/2023/01/16/SharedMemocry优化矩阵乘法/01.png"><p>矩阵A与矩阵B相乘，得到矩阵C，相乘的一个重要条件是矩阵A的列数或者宽度与矩阵B的行数或者高度要相等，相乘得到的矩阵C的列数(宽度)与矩阵B的列数(宽度)相等，行数(高度)与矩阵A的行数(高度)相等，假设A为2x3的矩阵，B为3x4的矩阵，A和B相乘结果是C为2x4，注意这里的表述是行在前列在后。乘法中单个元素的对应关系是，C中的每个元素是A中对应行与B中对应列的逐元素相乘的累加和，如图中黄色部分，整个乘法过程可以抽象成一个两层循环，外层循环是C中每个元素位置的循环，内层循环是A的行与B的列的逐元素循环</p><p>普通矩阵乘法的示例代码如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"cuda_runtime.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"device_launch_parameters.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MATRIX_A_WIDTH    1024</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MATRIX_A_HEIGHT   1920</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MATRIX_B_WIDTH    1280</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MATRIX_B_HEIGHT   MATRIX_A_WIDTH</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BLOCK_SIZE        16</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAT_ELEM_NUM(m)   (m.width * m.height)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAT_SIZE(m)       (MAT_ELEM_NUM(m) * sizeof(float))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> width;</span><br><span class="line">    <span class="keyword">int</span> height;</span><br><span class="line">    <span class="keyword">float</span> *data;</span><br><span class="line">&#125; Matrix;</span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">mat_mul_kernel_v1</span><span class="params">(Matrix A, Matrix B, Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/* get row/col index */</span></span><br><span class="line">    <span class="keyword">int</span> row = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">int</span> col = blockDim.y + blockIdx.y + threadIdx.y;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> value = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* foreach element in A's row and B's col */</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;A.width; i++) &#123;</span><br><span class="line">        value += A.data[row * A.width + i] * </span><br><span class="line">                 B.data[i * B.height + col];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* write sum value to C */</span></span><br><span class="line">    c.data[row * C.width + col] = value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">MatMulKernel</span><span class="params">(Matrix A, Matrix B, Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix d_A, d_B, d_C;</span><br><span class="line"></span><br><span class="line">    d_A.width  = A.width;</span><br><span class="line">    d_A.height = A.height;</span><br><span class="line">    d_B.width  = B.width;</span><br><span class="line">    d_B.height = B.height;</span><br><span class="line">    d_C.width  = C.width;</span><br><span class="line">    d_C.height = C.height;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Alloc cuda mem for A, B, C */</span></span><br><span class="line">    cudaMalloc(&amp;d_A.data, MAT_SIZE(A));</span><br><span class="line">    cudaMalloc(&amp;d_B.data, MAT_SIZE(B));</span><br><span class="line">    cudaMalloc(&amp;d_C.data, MAT_SIZE(C));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Copy mem from host to device */</span></span><br><span class="line">    cudaMemcpy(d_A.data, A.data, MAT_SIZE(A), cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(d_B.data, B.data, MAT_SIZE(B), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Create and invoke cuda kernel */</span></span><br><span class="line">    <span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(BLOCK_SIZE, BLOCK_SIZE)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">numBlocks</span><span class="params">(C.height / BLOCK_SIZE, C.width / BLOCK_SIZE)</span></span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"call kernel with blocks&#123;%d,%d&#125; threads&#123;%d,%d&#125;\n"</span>, B.width / BLOCK_SIZE,         A.height / BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE);</span><br><span class="line">    mat_mul_kernel_v1&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Copy mem from device to host*/</span></span><br><span class="line">    cudaMemcpy(C.data, d_C.data, MAT_SIZE(C), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Free cuda mem */</span></span><br><span class="line">    cudaFree(d_A.data);</span><br><span class="line">    cudaFree(d_B.data);</span><br><span class="line">    cudaFree(d_C.data);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix A, B, C;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Initialize A,B,C and alloc memory for them */</span></span><br><span class="line">    A.width = MATRIX_A_WIDTH;</span><br><span class="line">    A.height = MATRIX_A_HEIGHT;</span><br><span class="line">    A.data   = (<span class="keyword">float</span> *)<span class="built_in">malloc</span>(MAT_SIZE(A));</span><br><span class="line"></span><br><span class="line">       B.width  = MATRIX_B_WIDTH;</span><br><span class="line">    B.height = MATRIX_B_HEIGHT;</span><br><span class="line">    B.data   = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(MAT_SIZE(B));</span><br><span class="line"></span><br><span class="line">    C.width  = MATRIX_B_WIDTH;</span><br><span class="line">    C.height = MATRIX_A_HEIGHT;</span><br><span class="line">    C.data   = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(MAT_SIZE(C));</span><br><span class="line"></span><br><span class="line">    MatMulKernel(A, B, C);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">free</span>(A.data);</span><br><span class="line">    <span class="built_in">free</span>(B.data);</span><br><span class="line">    <span class="built_in">free</span>(C.data);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>程序中为每个block分配了16x16的二维线程数，block的大小由数据大小决定，每个线程计算C中的一个元素，通过线程的二维ID来确定当前线程计算C中的哪个元素</p><h1 id="使用共享内存优化矩阵乘法"><a href="#使用共享内存优化矩阵乘法" class="headerlink" title="使用共享内存优化矩阵乘法"></a>使用共享内存优化矩阵乘法</h1><p>在普通矩阵乘法中，每个线程负责计算C中的一个元素，每个元素都会读取A中的一行和B中的一列。例如在计算C[2][1]时，线程1要读取一次A的第2行和B的第1列，在计算C[2][2]时，线程2要读取一次A的第2行和B的第2列，可以看到两个线程各进行了一次对A第二行的读取操作，由于从全局内存中读取数据是非常缓慢的，这种重复的读取如果可以被避免的话，能够有效提升程序性能。如下图所示，在优化的程序中，将最终要计算的结果矩阵C拆分成一个一个大小为 <code>BLOCK_SIZE*BLOCK_SIZE</code>的子矩阵$C<em>{sub}$，每个线程块负责计算一个子矩阵$C</em>{sub}$，而每个线程负责计算子矩阵中的每个元素。对A、B的读取也是以块为单位的，每次将读取的数据放入SharedMemory中，这样在计算完一个子矩阵$C_{sub}$时，对A的行读取、B的列读取能够从SharedMemory中获得，而不是每次都从全局内存中获取</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"cuda_runtime.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"device_launch_parameters.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MATRIX_A_WIDTH    1024</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MATRIX_A_HEIGHT   1920</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MATRIX_B_WIDTH    1280</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MATRIX_B_HEIGHT   MATRIX_A_WIDTH</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BLOCK_SIZE        16</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAT_ELEM_NUM(m)   (m.width * m.height)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAT_SIZE(m)       (MAT_ELEM_NUM(m) * sizeof(float))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> width;</span><br><span class="line">    <span class="keyword">int</span> height;</span><br><span class="line">    <span class="keyword">int</span> stride;</span><br><span class="line">    <span class="keyword">float</span> *data;</span><br><span class="line">&#125; Matrix;</span><br><span class="line"></span><br><span class="line">__<span class="function">device__ <span class="keyword">void</span> <span class="title">DevMatSetElement</span><span class="params">(Matrix m, <span class="keyword">int</span> row, <span class="keyword">int</span> col, <span class="keyword">float</span> value)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    m.data[m.stride * row + col] = value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__<span class="function">device__ <span class="keyword">float</span> <span class="title">DevMatGetElement</span><span class="params">(Matrix m, <span class="keyword">int</span> row, <span class="keyword">int</span> col)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> m.data[m.stride * row + col];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__<span class="function">device__ Matrix <span class="title">DevMatGetSub</span><span class="params">(Matrix m, <span class="keyword">int</span> row, <span class="keyword">int</span> col)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix sub;</span><br><span class="line">    sub.width  = BLOCK_SIZE;</span><br><span class="line">    sub.height = BLOCK_SIZE;</span><br><span class="line">    sub.stride = m.stride;</span><br><span class="line">    sub.data   = &amp;m.data[m.stride * BLOCK_SIZE * row + </span><br><span class="line">                                    BLOCK_SIZE * col];</span><br><span class="line">    <span class="keyword">return</span> sub;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">mat_mul_kernel_v2</span><span class="params">(Matrix A, Matrix B, Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> blockRow = blockIdx.y;</span><br><span class="line">    <span class="keyword">int</span> blockCol = blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> row = threadIdx.y;</span><br><span class="line">    <span class="keyword">int</span> col = threadIdx.x;</span><br><span class="line"></span><br><span class="line">    Matrix CSub = DevMatGetSub(C, blockRow, blockCol);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> Cvalue = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* foreach sub */</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> m=<span class="number">0</span>; m&lt;(A.width/BLOCK_SIZE); m++) &#123;</span><br><span class="line"></span><br><span class="line">        Matrix ASub = DevMatGetSub(A, blockRow, m);</span><br><span class="line">        Matrix BSub = DevMatGetSub(B, m, blockCol);</span><br><span class="line"></span><br><span class="line">        __shared__ <span class="keyword">float</span> As[BLOCK_SIZE][BLOCK_SIZE];</span><br><span class="line">        __shared__ <span class="keyword">float</span> Bs[BLOCK_SIZE][BLOCK_SIZE];</span><br><span class="line"></span><br><span class="line">        As[row][col] = DevMatGetElement(ASub, row, col);</span><br><span class="line">        Bs[row][col] = DevMatGetElement(BSub, row, col);</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* foreach elem */</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> e=<span class="number">0</span>; e&lt;BLOCK_SIZE; e++) &#123;</span><br><span class="line">            Cvalue += As[row][e] * Bs[e][col];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    DevMatSetElement(CSub, row, col, Cvalue);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">MatMulKernel</span><span class="params">(Matrix A, Matrix B, Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix d_A, d_B, d_C;</span><br><span class="line"></span><br><span class="line">    d_A.width  = A.width;</span><br><span class="line">    d_A.height = A.height;</span><br><span class="line">    d_A.stride = A.stride;</span><br><span class="line">    d_B.width  = B.width;</span><br><span class="line">    d_B.height = B.height;</span><br><span class="line">    d_B.stride = B.stride;</span><br><span class="line">    d_C.width  = C.width;</span><br><span class="line">    d_C.height = C.height;</span><br><span class="line">    d_C.stride = C.stride;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Alloc cuda mem for A, B, C */</span></span><br><span class="line">    cudaMalloc(&amp;d_A.data, MAT_SIZE(A));</span><br><span class="line">    cudaMalloc(&amp;d_B.data, MAT_SIZE(B));</span><br><span class="line">    cudaMalloc(&amp;d_C.data, MAT_SIZE(C));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Copy mem from host to device */</span></span><br><span class="line">    cudaMemcpy(d_A.data, A.data, MAT_SIZE(A), cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(d_B.data, B.data, MAT_SIZE(B), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Create and invoke cuda kernel */</span></span><br><span class="line">    <span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(BLOCK_SIZE, BLOCK_SIZE)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">numBlocks</span><span class="params">(C.height / BLOCK_SIZE, C.width / BLOCK_SIZE)</span></span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"call kernel with blocks&#123;%d,%d&#125; threads&#123;%d,%d&#125;\n"</span>, B.width / BLOCK_SIZE,         A.height / BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE);</span><br><span class="line">    mat_mul_kernel_v2&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Copy mem from device to host*/</span></span><br><span class="line">    cudaMemcpy(C.data, d_C.data, MAT_SIZE(C), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Free cuda mem */</span></span><br><span class="line">    cudaFree(d_A.data);</span><br><span class="line">    cudaFree(d_B.data);</span><br><span class="line">    cudaFree(d_C.data);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix A, B, C;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Initialize A,B,C and alloc memory for them */</span></span><br><span class="line">    A.width = MATRIX_A_WIDTH;</span><br><span class="line">    A.height = MATRIX_A_HEIGHT;</span><br><span class="line">    A.stride = A.width;</span><br><span class="line">    A.data   = (<span class="keyword">float</span> *)<span class="built_in">malloc</span>(MAT_SIZE(A));</span><br><span class="line"></span><br><span class="line">    B.width  = MATRIX_B_WIDTH;</span><br><span class="line">    B.height = MATRIX_B_HEIGHT;</span><br><span class="line">    B.stride = B.width;</span><br><span class="line">    B.data   = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(MAT_SIZE(B));</span><br><span class="line"></span><br><span class="line">    C.width  = MATRIX_B_WIDTH;</span><br><span class="line">    C.height = MATRIX_A_HEIGHT;</span><br><span class="line">    C.stride = C.width;</span><br><span class="line">    C.data   = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(MAT_SIZE(C));</span><br><span class="line"></span><br><span class="line">    MatMulKernel(A, B, C);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">free</span>(A.data);</span><br><span class="line">    <span class="built_in">free</span>(B.data);</span><br><span class="line">    <span class="built_in">free</span>(C.data);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h1><div class="table-container"><table><thead><tr><th>显卡</th><th>KernelVersion</th><th>KernelLaunchTime(us)</th></tr></thead><tbody><tr><td>GTX 730(sm_35)</td><td>V1</td><td>2849372.820</td></tr><tr><td>GTX 730(sm_35)</td><td>v2</td><td>2154518.019</td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;巧妙的使用共享内存Shared memory，能够减少线程对全局内存Global memory的访问，提升CUDA程序在访存方面的性能。本文以矩阵乘法为例，通过对比不使用共享内存的普通矩阵乘法实现和使用共享内存的矩阵乘法优化版本，展示共享内存对程序性能的提升，并分析使用共享
      
    
    </summary>
    
      <category term="CUDA" scheme="http://yoursite.com/categories/CUDA/"/>
    
    
      <category term="Nvidia" scheme="http://yoursite.com/tags/Nvidia/"/>
    
      <category term="CUDA" scheme="http://yoursite.com/tags/CUDA/"/>
    
  </entry>
  
  <entry>
    <title>TensorRT部署YOLOv5-03-TensorRT</title>
    <link href="http://yoursite.com/2023/01/03/TensorRT%E9%83%A8%E7%BD%B2YOLOv5-03-TensorRT/"/>
    <id>http://yoursite.com/2023/01/03/TensorRT部署YOLOv5-03-TensorRT/</id>
    <published>2023-01-03T02:05:25.000Z</published>
    <updated>2023-02-02T11:55:21.672Z</updated>
    
    <content type="html"><![CDATA[<p>TensorRT是本专栏中最重要的内容，绝大多数内容将围绕TensorRT来展开，本文对TensorRT进行一个基本的介绍，让不熟悉TensorRT的读者能够对TensorRT是什么，如何使用它有一个较为全面的认识</p><p>Nvidia TensorRT是一个用于Nvidia GPU上高性能机器学习推理的SDK，对开发者屏蔽了模型在GPU上推理运行的CUDA计算细节，用户只需要通过一套简介易用的Python/C++ API接口，即可方便的将模型在GPU上进行加速推理。另外TensorRT还提供了模型转换、性能评估的工具，方便用户将各训练框架生成的模型转换到TensorRT能够识别的形式，以及在未进行业务开发之前快速评估模型推理的性能</p><h1 id="Build-Phase-and-Runtime-Phase"><a href="#Build-Phase-and-Runtime-Phase" class="headerlink" title="Build Phase and Runtime Phase"></a>Build Phase and Runtime Phase</h1><p>TensorRT的主要工作内容可分为构建期(Build Phase)和运行期(Runtime Phase)</p><p>构建期的目标是生成一个能够被运行期加载并运行的TensorRT推理引擎(Engine)，模型的来源可以是从各种深度学习框架(TensorFlow、Pytorch、Caffe等)训练好的模型文件，也可以是利用TensorRT API原生搭建的网络，从深度学习框架导出的权重文件中加载权重参数。推理引擎是构建期的输出，推理引擎可以以本地二进制文件的形式存在，也可以是程序中的一个类实例。构建期在引擎的创建过程中，除了进行模型结构的解析以及生成引擎之外，还有很多中间的优化工作，例如计算图优化，经典的操作Conv+Add+ReLU层融合，节点消除，节点变换(Pad、Slice、Concat、Shuffle)，并对算子在GPU上的实现进行本地运行评估和选择，所有这些优化都是工具自动进行的，但是用户可以通过一些额外的参数来调整优化过程。经过构建期生成的推理引擎，其内部的网络结构和原模型已经完全不同</p><p>运行期的作用是加载推理引擎，并在GPU上进行执行，在这个阶段，用户需要为引擎提供输入数据，并准备好输出内存，通过TensorRT提供的运行期API进行模型执行</p><p>构建期和运行期可以处于同一个程序中，也可以分开独立进行。例如可以在同一个程序中，先进行构建期将模型转换为推理引擎，然后进行执行期将推理引擎的类实例直接运行推理计算；也可以在一个单独的构建程序中进行模型转换，生成推理引擎，通过API导出为序列化的引擎文件，然后在另一个推理程序中加载引擎文件，生成引擎类实例，进行推理计算</p><h1 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h1><p>构建一个推理引擎有3种方式，这些方式各有优劣</p><ul><li><p>框架自带TRT接口</p><p>英伟达与部分深度学习框架有合作，例如Tensorflow内置了TF-TRT，Pytorch有Torch-TensorRT，使用这些框架内置的TensorRT接口，可以将训练好的模型无缝衔接，直接在原有框架上调用对应接口进行推理，这种方式的优势在于非常方便，环境统一，开发效率较高，遇到不支持的算子会返回到原框架的实现。缺点是性能较差，不能最大限度的利用TensorRT的优化加速能力，另外在很多资源有限的嵌入式设备上安装Tensorflow这种较大的深度学习工具也不现实，因此这种方式通常是应用于服务端推理，本文不对这种方式进行介绍</p></li><li><p>使用Parser</p><p>将深度学习框架导出的模型文件，经过一个中间表示，转换到TensorRT引擎，中间表示主要是使用ONNX，这种方式的优点是TensorRT能够在构建期尽可能多的操作网络结构和算子优化，因此推理性能较高。缺点也是非常明显的，由于使用了ONNX，原框架中支持的算子与ONNX支持的算子以及TensorRT支持的算子，这三者之间并不是完全覆盖的，在网络模型使用了较多较新层结构时，在算子支持方面可能会存在较多问题，并且由于ONNX本身对不支持的算子也会进行模型结构的变换，这部分并不可控，对性能也有一些损失，这种情况下要么修改网络结构适配ONNX，要么以插件的形式通过TensorRT提供的API手写自定义算子，比较复杂</p></li><li><p>TensorRT API搭建</p><p>TensorRT API本身提供了构建网络结构的API，这种方式的优点是网络细节完全由用户控制，某些情况下TensorRT转换出来的网络结构可能并非最佳方案，手工设置的网络结构性能更佳，这种情况下由用户自己搭建TensorRT的原生网络性能能够达到最大化，但是由于TensorRT API搭建网络也存在算子支持的问题，并且从网络整体结构层面进行性能优化本身是一个难度很高的事情，需要用户对计算图优化有较为深入的理解，因此这种方式开发难度最大</p></li></ul><p>总的来说，无论是哪种方式，特殊算子适配是一个绕不开的问题，必须研究插件写法以及CUDA计算细节。本文由于重点是介绍TensorRT上运行YOLOv5模型的全流程，重点将会放在整个流程的完整性上，且YOLOv5模型本身使用到的层和算子比较常规，不存在算子适配问题，因此后文主要以“使用Parser”方式进行介绍，对插件写法和TensorRT API搭建网络等方面不进行介绍</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;TensorRT是本专栏中最重要的内容，绝大多数内容将围绕TensorRT来展开，本文对TensorRT进行一个基本的介绍，让不熟悉TensorRT的读者能够对TensorRT是什么，如何使用它有一个较为全面的认识&lt;/p&gt;
&lt;p&gt;Nvidia TensorRT是一个用于Nv
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="Nvidia" scheme="http://yoursite.com/categories/AI/Nvidia/"/>
    
    
      <category term="CUDA" scheme="http://yoursite.com/tags/CUDA/"/>
    
      <category term="nvidia" scheme="http://yoursite.com/tags/nvidia/"/>
    
      <category term="TensorRT" scheme="http://yoursite.com/tags/TensorRT/"/>
    
      <category term="YOLOv5" scheme="http://yoursite.com/tags/YOLOv5/"/>
    
  </entry>
  
  <entry>
    <title>TensorRT部署YOLOv5-02-环境介绍</title>
    <link href="http://yoursite.com/2022/12/19/TensorRT%E9%83%A8%E7%BD%B2YOLOv5-02-%E7%8E%AF%E5%A2%83%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2022/12/19/TensorRT部署YOLOv5-02-环境介绍/</id>
    <published>2022-12-19T06:42:02.000Z</published>
    <updated>2023-02-02T11:59:25.561Z</updated>
    
    <content type="html"><![CDATA[<p>本文对TensorRT部署YOLOv5模型的整体环境配置及软件包进行介绍。实验环境主要从主机和JestonNano两方面进行介绍，在主机端完成模型训练并转换为onnx中间模型表示，在JestonNano进行onnx模型转换为TensorRT引擎、图片/视频加载、编解码处理、模型推理、后处理等工作</p><h1 id="主机环境"><a href="#主机环境" class="headerlink" title="主机环境"></a>主机环境</h1><p>主机是一台Windows11的台式机，使用Tensorflow的GPU版进行模型训练，生成模型文件，由于在windows操作系统上安装onnx存在一些问题，比较麻烦，不想折腾，因此我选择在Ubuntu虚拟机上进行Tensorflow模型到onnx模型的转换</p><p>主机端主要使用的软件及版本如下</p><ul><li><p>Windows11</p><ul><li><p>tensorflow-gpu 2.5.0</p></li><li><p>CUDA 11.0</p></li></ul></li><li><p>Ubuntu20.0.4虚拟机</p><ul><li><p>tensorflow-gpu 2.2.0：没啥用处，主要是为了安装tf2onnx</p></li><li><p>tf2onnx 1.12.0：用于将tensorflow模型转换为onnx</p></li><li><p>sdkmanager 1.8.1：Nvidia官方提供的镜像及软件包下载烧写工具，用于向JestonNano烧写Linux镜像和软件包</p></li></ul></li></ul><h1 id="JestonNano环境"><a href="#JestonNano环境" class="headerlink" title="JestonNano环境"></a>JestonNano环境</h1><p>JestonNano环境的配置主要包括两方面，一方面是通过sdkmanager烧写的官方镜像所携带的软件包以及官方额外提供的软件包，另一方面是自己下载并安装到JestonNano的第三方软件和库</p><ul><li><p>官方提供，列举一些常用到的</p><ul><li><p>bin</p><ul><li><p>trtexec：TensorRT的命令行工具，可以进行推理引擎生成及性能评估</p></li><li><p>nsys：CUDA性能分析工具，生成Profile文件</p></li></ul></li><li><p>python包</p><ul><li><p>numpy：张量计算，前后处理都会用到</p></li><li><p>pycuda：与nvinfer配合进行数据的拷贝(devToHost/hostToDev)，以及部分计算加速</p></li><li><p>opencv：图像预处理、图像视频加载及显示</p></li><li><p>nvinfer：TensorRT的Python包，可以进行推理引擎生成以及推理计算</p></li></ul></li><li><p>C++</p><ul><li><p>cmake：构建C++程序</p></li><li><p>opencv：图像预处理、图像视频加载及显示</p></li><li><p>nvinfer：TensorRT C++库</p></li></ul></li></ul></li><li><p>私有安装</p><ul><li><p>Python</p><ul><li><p>numba：张量计算加速，较难安装</p></li><li><p>cupy：张量计算加速，容易安装</p></li></ul></li><li><p>lbtorch</p><ul><li>pytorch的C++库，用于替代numpy，处理C++程序的张量计算</li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文对TensorRT部署YOLOv5模型的整体环境配置及软件包进行介绍。实验环境主要从主机和JestonNano两方面进行介绍，在主机端完成模型训练并转换为onnx中间模型表示，在JestonNano进行onnx模型转换为TensorRT引擎、图片/视频加载、编解码处理、
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="Nvidia" scheme="http://yoursite.com/categories/AI/Nvidia/"/>
    
    
      <category term="CUDA" scheme="http://yoursite.com/tags/CUDA/"/>
    
      <category term="nvidia" scheme="http://yoursite.com/tags/nvidia/"/>
    
      <category term="TensorRT" scheme="http://yoursite.com/tags/TensorRT/"/>
    
      <category term="YOLOv5" scheme="http://yoursite.com/tags/YOLOv5/"/>
    
  </entry>
  
  <entry>
    <title>TensorRT部署YOLOv5-01-Overview</title>
    <link href="http://yoursite.com/2022/12/14/TensorRT%E9%83%A8%E7%BD%B2YOLOv5-01-Overview/"/>
    <id>http://yoursite.com/2022/12/14/TensorRT部署YOLOv5-01-Overview/</id>
    <published>2022-12-14T06:26:17.000Z</published>
    <updated>2023-02-09T08:48:36.194Z</updated>
    
    <content type="html"><![CDATA[<p>本系列对在Nvidia边缘计算平台进行深度学习模型部署进行一个全面的介绍，主要围绕TensorRT深度学习推理框架，以YOLOv5目标检测任务为例，以Jeston Nano为目标计算平台，对环境搭建、模型量化、模型推理、性能评估、后处理优化等细节进行详细说明，并给出C++和Python分别进行模型部署推理的代码实例</p><p>阅读本系列，您可以了解到</p><ul><li><p>Jeston Nano计算平台以及相关软件资源介绍</p></li><li><p>什么是TensorRT？什么是TensorRT引擎？如何将Tensorflow等深度学习框架训练好的模型转换为TensorRT引擎？转换过程需要注意什么？TensorRT对模型做了哪些优化？</p></li><li><p>如何使用TensorRT的Python/C++ API进行模型推理？如何构造输入数据并传递给推理引擎？输出数据又是什么格式，如何获取模型输出结果？</p></li><li><p>如何利用Nsight对TensoRT推理过程进行抓取，推理过程内部细节和耗时分布是什么样的？</p></li><li><p>YOLOv5这种需要前处理和后处理解码的任务如何在TensorRT上进行推理？如何使用Python/C++进行图像/视频预处理、模型推理、模型解码、非极大值抑制，并最终在输出图像上绘制预测框？</p></li><li><p>如何使用Gstreamer并利用Nvidia提供的加速插件，对视频源(摄像头/文件)进行编解码及格式转换的加速，提高视频编解码速度</p></li><li><p>Python版本视频推理性能瓶颈分析，如何提速？利用pycuda、cupy、numba等加速包进行加速，可行吗？</p></li><li><p>C++版本如何利用libtorch进行后处理解码</p></li><li><p>影响性能的因素</p></li></ul><h1 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h1><p>目前最快的方案是使用Python程序，利用pycuda进行sigmoid运算加速，fp16量化，yolov5n模型，最快fps为11</p><p>以下表格是目前不同模型规模、不同精度和不同类别数量情况下，推理引擎大小、吞吐量、延迟和进行视频检测的帧率，重点关注帧率</p><div class="table-container"><table><thead><tr><th>Model</th><th>Classes</th><th>Params</th><th>EngineSize</th><th>Precision</th><th>Throughput(qps)</th><th>Latency(ms)</th><th>Program</th><th>FPS</th></tr></thead><tbody><tr><td>YOLOv5m</td><td>20</td><td></td><td>146M</td><td>fp32</td><td>3.5738</td><td>279.722</td><td>Python</td><td>2.77</td></tr><tr><td>YOLOv5m</td><td>20</td><td></td><td>70M</td><td>fp16</td><td></td><td></td><td>Python</td><td></td></tr><tr><td>YOLOv5s</td><td>20</td><td></td><td>44M</td><td>fp32</td><td>8.67145</td><td>115.22</td><td>Python</td><td>5.21</td></tr><tr><td>YOLOv5s</td><td>20</td><td></td><td>20M</td><td>fp16</td><td>72.2289</td><td>72.2289</td><td>Python</td><td>6.66</td></tr><tr><td>YOLOv5n</td><td>20</td><td>1800481</td><td>13M</td><td>fp32</td><td>21.8709</td><td>45.4301</td><td>Python</td><td>9.85</td></tr><tr><td>YOLOv5n</td><td>20</td><td>1800481</td><td>7M</td><td>fp16</td><td>28.4845</td><td>35.0919</td><td>Python+CUDA</td><td>10.88</td></tr><tr><td>YOLOv5n</td><td>80</td><td>1881661</td><td>14M</td><td>fp32</td><td>19.8624</td><td>50.3083</td><td>Python</td><td>5.62</td></tr><tr><td>YOLOv5n</td><td>80</td><td>1881661</td><td>7M</td><td>fp16</td><td>26.0428</td><td>38.2188</td><td>Python</td><td>5.85</td></tr><tr><td>YOLOv5n</td><td>20</td><td>1800481</td><td>7M</td><td>fp16</td><td>28.4845</td><td>35.0919</td><td>C++&amp;libtorch</td><td>8.9</td></tr></tbody></table></div><ul><li><p>Model：表示YOLOv5的模型规模</p></li><li><p>Classes：模型支持的分类类别数，训练时确定</p></li><li><p>Params：模型在Tensorflow summary中输出的总参数数量</p></li><li><p>EngineSize：模型转换为TensorRT引擎后的引擎文件大小</p></li><li><p>Precision：模型转换为TensorRT引擎的转换精度</p></li><li><p>Throughput：模型转换时TensorRT评估推理吞吐量，每秒可执行的推理次数</p></li><li><p>Latency：模型转换时TensorRT评估推理延迟，即推理一次需要的时长</p></li><li><p>Program：分别用Python实现还是C++实现的检测程序</p></li><li><p>FPS：检测程序统计的平均帧率</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本系列对在Nvidia边缘计算平台进行深度学习模型部署进行一个全面的介绍，主要围绕TensorRT深度学习推理框架，以YOLOv5目标检测任务为例，以Jeston Nano为目标计算平台，对环境搭建、模型量化、模型推理、性能评估、后处理优化等细节进行详细说明，并给出C++和
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="Nvidia" scheme="http://yoursite.com/categories/AI/Nvidia/"/>
    
    
      <category term="CUDA" scheme="http://yoursite.com/tags/CUDA/"/>
    
      <category term="nvidia" scheme="http://yoursite.com/tags/nvidia/"/>
    
      <category term="TensorRT" scheme="http://yoursite.com/tags/TensorRT/"/>
    
      <category term="YOLOv5" scheme="http://yoursite.com/tags/YOLOv5/"/>
    
  </entry>
  
  <entry>
    <title>每月见闻202211</title>
    <link href="http://yoursite.com/2022/11/11/%E6%AF%8F%E6%9C%88%E8%A7%81%E9%97%BB202211/"/>
    <id>http://yoursite.com/2022/11/11/每月见闻202211/</id>
    <published>2022-11-11T08:50:59.000Z</published>
    <updated>2023-02-02T11:53:16.747Z</updated>
    
    <content type="html"><![CDATA[<h1 id="vscode注释插件"><a href="#vscode注释插件" class="headerlink" title="vscode注释插件"></a>vscode注释插件</h1><h3 id="Better-Comments"><a href="#Better-Comments" class="headerlink" title="Better Comments"></a>Better Comments</h3><p>该插件能够帮助生成易于阅读的高亮形式代码注释</p><img src="/2022/11/11/每月见闻202211/01.PNG"><p>插件需要通过settings.json添加配置项，在settings.json中输入”better-comments.tags”，会自动生成默认配置</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">"better-comments.tags": [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"tag"</span>: <span class="string">"!"</span>,</span><br><span class="line">            <span class="attr">"color"</span>: <span class="string">"#FF2D00"</span>,</span><br><span class="line">            <span class="attr">"strikethrough"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"underline"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"backgroundColor"</span>: <span class="string">"transparent"</span>,</span><br><span class="line">            <span class="attr">"bold"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"italic"</span>: <span class="literal">false</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"tag"</span>: <span class="string">"?"</span>,</span><br><span class="line">            <span class="attr">"color"</span>: <span class="string">"#3498DB"</span>,</span><br><span class="line">            <span class="attr">"strikethrough"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"underline"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"backgroundColor"</span>: <span class="string">"transparent"</span>,</span><br><span class="line">            <span class="attr">"bold"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"italic"</span>: <span class="literal">false</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"tag"</span>: <span class="string">"//"</span>,</span><br><span class="line">            <span class="attr">"color"</span>: <span class="string">"#474747"</span>,</span><br><span class="line">            <span class="attr">"strikethrough"</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">"underline"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"backgroundColor"</span>: <span class="string">"transparent"</span>,</span><br><span class="line">            <span class="attr">"bold"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"italic"</span>: <span class="literal">false</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"tag"</span>: <span class="string">"todo"</span>,</span><br><span class="line">            <span class="attr">"color"</span>: <span class="string">"#FF8C00"</span>,</span><br><span class="line">            <span class="attr">"strikethrough"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"underline"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"backgroundColor"</span>: <span class="string">"transparent"</span>,</span><br><span class="line">            <span class="attr">"bold"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"italic"</span>: <span class="literal">false</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"tag"</span>: <span class="string">"*"</span>,</span><br><span class="line">            <span class="attr">"color"</span>: <span class="string">"#98C379"</span>,</span><br><span class="line">            <span class="attr">"strikethrough"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"underline"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"backgroundColor"</span>: <span class="string">"transparent"</span>,</span><br><span class="line">            <span class="attr">"bold"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"italic"</span>: <span class="literal">false</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>插件支持自定义关键字和颜色，例如我定义的自定义关键字</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">        &#123;</span><br><span class="line">    <span class="attr">"tag"</span>: <span class="string">"&lt;todo&gt;"</span>,</span><br><span class="line">    <span class="attr">"color"</span>: <span class="string">"#FF8C00"</span>,</span><br><span class="line">    <span class="attr">"strikethrough"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"underline"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"backgroundColor"</span>: <span class="string">"transparent"</span>,</span><br><span class="line">    <span class="attr">"bold"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"italic"</span>: <span class="literal">false</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"tag"</span>: <span class="string">"&lt;test&gt;"</span>,</span><br><span class="line">    <span class="attr">"color"</span>: <span class="string">"#32CD32"</span>,</span><br><span class="line">    <span class="attr">"strikethrough"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"underline"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"backgroundColor"</span>: <span class="string">"transparent"</span>,</span><br><span class="line">    <span class="attr">"bold"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"italic"</span>: <span class="literal">false</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"tag"</span>: <span class="string">"&lt;note&gt;"</span>,</span><br><span class="line">    <span class="attr">"color"</span>: <span class="string">"#007FFF"</span>,</span><br><span class="line">    <span class="attr">"strikethrough"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"underline"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"backgroundColor"</span>: <span class="string">"transparent"</span>,</span><br><span class="line">    <span class="attr">"bold"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"italic"</span>: <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>tag就是匹配的关键字</p></li><li><p>color字段填写你想要的颜色编码</p></li><li><p>strikethrough是否用删除线</p></li><li><p>underline 是否用下划线</p></li><li><p>backgroundColor 背景色</p></li><li><p>bold 是否加粗</p></li><li><p>italic 是否为斜体</p></li></ul><p>在C代码中显示的效果如下</p><img src="/2022/11/11/每月见闻202211/02.PNG"><h3 id="koroFileHeader"><a href="#koroFileHeader" class="headerlink" title="koroFileHeader"></a>koroFileHeader</h3><p>该插件用于自动生成文件头部注释和函数注释</p><img src="/2022/11/11/每月见闻202211/03.PNG"><p>详细配置参见 <a href="https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE%E5%AD%97%E6%AE%B5" target="_blank" rel="noopener">koro1FileHeade wiki</a></p><p>主要功能</p><ul><li><p>文件头部注释</p><ul><li><p>自动更新创建时间和最后编辑时间</p></li><li><p>配置好模板后，通过快捷键自动添加</p></li><li><p>支持自定义属性</p></li></ul></li><li><p>函数注释</p><ul><li>支持自定义属性</li></ul></li></ul><img src="/2022/11/11/每月见闻202211/04.PNG"><h1 id="Z-Library没了怎么办"><a href="#Z-Library没了怎么办" class="headerlink" title="Z-Library没了怎么办"></a>Z-Library没了怎么办</h1><p>环球最大的数字图书馆Z-Library因版权问题被美国邮政检查局查封，所有DNS服务器全部封禁</p><img src="/2022/11/11/每月见闻202211/05.PNG"><p>在Z-Library上下载了好多电子书，没有了Z-Library怎么办呢。我找到了一个Z-Library的替代方案，那就是<a href="https://libgen.gs/" target="_blank" rel="noopener">Library Genesis</a></p><img src="/2022/11/11/每月见闻202211/06.PNG"><p>虽然没有Z-Library的图书那么全那么多，但是很多比较新的英文书籍也是可以找到的，例如最近正在研究的PyCUDA</p><img src="/2022/11/11/每月见闻202211/07.PNG">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;vscode注释插件&quot;&gt;&lt;a href=&quot;#vscode注释插件&quot; class=&quot;headerlink&quot; title=&quot;vscode注释插件&quot;&gt;&lt;/a&gt;vscode注释插件&lt;/h1&gt;&lt;h3 id=&quot;Better-Comments&quot;&gt;&lt;a href=&quot;#Better
      
    
    </summary>
    
    
      <category term="每月见闻" scheme="http://yoursite.com/tags/%E6%AF%8F%E6%9C%88%E8%A7%81%E9%97%BB/"/>
    
  </entry>
  
  <entry>
    <title>Mosica数据增强</title>
    <link href="http://yoursite.com/2022/11/11/Mosica%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"/>
    <id>http://yoursite.com/2022/11/11/Mosica数据增强/</id>
    <published>2022-11-11T08:03:18.000Z</published>
    <updated>2023-02-02T11:52:01.664Z</updated>
    
    <content type="html"><![CDATA[<p>Yolov4中使用了Mosica数据增强方法，能够在有限数据集情况下极大程度的增加增强样本量。本文对Mosica数据增强方法进行Python代码实现介绍</p><h1 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h1><p>本实现需要以下相关数据和文件准备</p><ul><li><p>VOC数据集(本实验使用的是VOC2007)</p></li><li><p>classes文件</p></li></ul><p>将VOC数据集预先经过处理后，得到一个合并所有标注信息的文件’annotations.txt’，其中每一行是图像绝对路径和BoundingBox和标签信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">VOCdevkit/VOC2007/JPEGImages/000005.jpg 263,211,324,339,8 165,264,253,372,8 5,244,67,374,8 241,194,295,299,8 277,186,312,220,8</span><br><span class="line">VOCdevkit/VOC2007/JPEGImages/000007.jpg 141,50,500,330,6</span><br><span class="line">VOCdevkit/VOC2007/JPEGImages/000009.jpg 69,172,270,330,12 150,141,229,284,14 285,201,327,331,14 258,198,297,329,14</span><br><span class="line">VOCdevkit/VOC2007/JPEGImages/000012.jpg 156,97,351,270,6</span><br><span class="line">VOCdevkit/VOC2007/JPEGImages/000016.jpg 92,72,305,473,1</span><br><span class="line">VOCdevkit/VOC2007/JPEGImages/000017.jpg 185,62,279,199,14 90,78,403,336,12</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h1 id="导入依赖包"><a href="#导入依赖包" class="headerlink" title="导入依赖包"></a>导入依赖包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw, ImageFont</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><ul><li><p>random用于生成随机数，以进行随机参数的变换</p></li><li><p>numpy用于图像和numpy的转换以及数据处理</p></li><li><p>Image用于图像加载和变换</p></li><li><p>ImageDraw和ImageFont用于在图像上画BoundingBox</p></li><li><p>pyplot用于绘图显示图像</p></li></ul><h1 id="定义一些工具函数"><a href="#定义一些工具函数" class="headerlink" title="定义一些工具函数"></a>定义一些工具函数</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于生成指定范围的随机数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_rate</span><span class="params">(a=<span class="number">0</span>, b=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.random.rand()*(b-a) + a</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于从classes文件得到classes数组</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_classes</span><span class="params">(classes_path)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(classes_path, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_names = f.readlines()</span><br><span class="line">    class_names = [c.strip() <span class="keyword">for</span> c <span class="keyword">in</span> class_names]</span><br><span class="line">    <span class="keyword">return</span> class_names</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在图像上绘制box矩形框以及标签文字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_bndbox</span><span class="params">(image, bboxes, classes)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> box <span class="keyword">in</span> bboxes:</span><br><span class="line">        label = classes[int(box[<span class="number">-1</span>])]</span><br><span class="line">        font = ImageFont.truetype(font=<span class="string">'SIMYOU.TTF'</span>, </span><br><span class="line">            size=np.floor(<span class="number">1.5e-2</span> * np.shape(image)[<span class="number">1</span>] + <span class="number">15</span>).astype(<span class="string">'int32'</span>))</span><br><span class="line">        draw = ImageDraw.Draw(image)</span><br><span class="line">        label_size = draw.textsize(label, font)</span><br><span class="line">        text_origin = np.array([box[<span class="number">0</span>], box[<span class="number">1</span>] - label_size[<span class="number">1</span>]])</span><br><span class="line">        draw.rectangle([box[<span class="number">0</span>], box[<span class="number">1</span>], box[<span class="number">2</span>], box[<span class="number">3</span>]], outline=<span class="string">'red'</span>,width=<span class="number">3</span>)</span><br><span class="line">        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=<span class="string">'red'</span>)</span><br><span class="line">        draw.text(text_origin, str(label), fill=(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), font=font)</span><br><span class="line">        <span class="keyword">del</span> draw</span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure><h1 id="图像样本显示"><a href="#图像样本显示" class="headerlink" title="图像样本显示"></a>图像样本显示</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 变量预先设置</span></span><br><span class="line">input_shape = [<span class="number">640</span>, <span class="number">640</span>]</span><br><span class="line">max_boxes = <span class="number">100</span></span><br><span class="line">annotation_path = <span class="string">'annotations.txt'</span></span><br><span class="line"><span class="keyword">with</span> open(annotation_path, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    train_indexes = f.readlines()</span><br><span class="line">classes_path = <span class="string">'voc_classes.txt'</span></span><br><span class="line">classes = get_classes(classes_path)</span><br></pre></td></tr></table></figure><p>Mosica数据增强是以4副图像合并为一副图像，首先获取4副图像进行显示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">12</span>))</span><br><span class="line">samples = train_indexes[:<span class="number">4</span>]</span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> enumerate(samples):</span><br><span class="line">    line_content = sample.split()</span><br><span class="line">    bboxes = np.array([np.array(list(map(int,box.split(<span class="string">','</span>)))) <span class="keyword">for</span> box <span class="keyword">in</span> line_content[<span class="number">1</span>:]])</span><br><span class="line">    image = Image.open(line_content[<span class="number">0</span>])</span><br><span class="line">    image = draw_bndbox(image, bboxes, classes)</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.title(<span class="string">'sample&#123;&#125;'</span>.format(i))</span><br><span class="line">    plt.imshow(image)</span><br></pre></td></tr></table></figure><img src="/2022/11/11/Mosica数据增强/01.png"><h1 id="Mosica处理"><a href="#Mosica处理" class="headerlink" title="Mosica处理"></a>Mosica处理</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line">index = <span class="number">0</span></span><br><span class="line">image_datas = []</span><br><span class="line">boxes_datas = []</span><br><span class="line"><span class="comment"># 生成4副图像的分割比例和坐标</span></span><br><span class="line">min_offset_x = random_rate(<span class="number">0.3</span>, <span class="number">0.7</span>)</span><br><span class="line">min_offset_y = random_rate(<span class="number">0.3</span>, <span class="number">0.7</span>)</span><br><span class="line">cutx = int(w * min_offset_x)</span><br><span class="line">cuty = int(h * min_offset_y)</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">12</span>))</span><br><span class="line"><span class="keyword">for</span> sample <span class="keyword">in</span> samples:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读入图像和box</span></span><br><span class="line">    line_content = sample.split()</span><br><span class="line">    image = Image.open(line_content[<span class="number">0</span>])</span><br><span class="line">    iw, ih = image.size</span><br><span class="line">    box = np.array([np.array(list(map(int,box.split(<span class="string">','</span>)))) <span class="keyword">for</span> box <span class="keyword">in</span> line_content[<span class="number">1</span>:]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机翻转</span></span><br><span class="line">    flip = random_rate() &lt; <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">if</span> flip <span class="keyword">and</span> len(box)&gt;<span class="number">0</span>:</span><br><span class="line">        image = image.transpose(Image.FLIP_LEFT_RIGHT)</span><br><span class="line">        <span class="comment"># 图像进行翻转，box也需要翻转</span></span><br><span class="line">        box[:, [<span class="number">0</span>,<span class="number">2</span>]] = iw - box[:, [<span class="number">2</span>,<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图像长宽比例和大小随机变换</span></span><br><span class="line">    beta1 = random_rate(<span class="number">1</span>-jitter, <span class="number">1</span>+jitter)</span><br><span class="line">    beta2 = random_rate(<span class="number">1</span>-jitter, <span class="number">1</span>+jitter)</span><br><span class="line">    rate  = iw/ih*beta1 / beta2</span><br><span class="line">    scale = random_rate(<span class="number">.4</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> rate &lt; <span class="number">1</span>:</span><br><span class="line">        nh = int(scale*h)</span><br><span class="line">        nw = int(nh*rate)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        nw = int(scale*w)</span><br><span class="line">        nh = int(nw/rate)</span><br><span class="line">    image = image.resize((nw, nh), Image.BICUBIC)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每幅图像的左上角相对最后生成图的偏移</span></span><br><span class="line">    <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">        dx = cutx - nw</span><br><span class="line">        dy = cut - nh</span><br><span class="line">    <span class="keyword">elif</span> index == <span class="number">1</span>:</span><br><span class="line">        dx = icutx- nw</span><br><span class="line">        dy = cutx</span><br><span class="line">    <span class="keyword">elif</span> index == <span class="number">2</span>:</span><br><span class="line">        dx = cutx</span><br><span class="line">        dy = cuty</span><br><span class="line">    <span class="keyword">elif</span> index == <span class="number">3</span>:</span><br><span class="line">        dx = cutx</span><br><span class="line">        dy = cuty - nh</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建与最终合成图大小一致的灰色背景图，用于将变换图粘贴到其中</span></span><br><span class="line">    new_image = Image.new(<span class="string">'RGB'</span>, (w,h), (<span class="number">128</span>,<span class="number">128</span>,<span class="number">128</span>))</span><br><span class="line">    new_image.paste(image, (dx, dy))</span><br><span class="line"></span><br><span class="line">    image_data = np.array(new_image)</span><br><span class="line"></span><br><span class="line">    bboxs_data = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图像进行了长宽比例和大小随机变换，box也需要进行尺度变换，并限制边界</span></span><br><span class="line">    <span class="keyword">if</span> len(box)&gt;<span class="number">0</span>:</span><br><span class="line">        np.random.shuffle(box)</span><br><span class="line">        box[:, [<span class="number">0</span>,<span class="number">2</span>]] = box[:, [<span class="number">0</span>,<span class="number">2</span>]]*nw/iw + dx</span><br><span class="line">        box[:, [<span class="number">1</span>,<span class="number">3</span>]] = box[:, [<span class="number">1</span>,<span class="number">3</span>]]*nh/ih + dy</span><br><span class="line">        box[:, <span class="number">0</span>:<span class="number">2</span>][box[:, <span class="number">0</span>:<span class="number">2</span>]&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        box[:, <span class="number">2</span>][box[:, <span class="number">2</span>]&gt;w] = w</span><br><span class="line">        box[:, <span class="number">3</span>][box[:, <span class="number">3</span>]&gt;h] = h</span><br><span class="line">        box_w = box[:, <span class="number">2</span>] - box[:, <span class="number">0</span>]</span><br><span class="line">        box_h = box[:, <span class="number">3</span>] - box[:, <span class="number">1</span>]</span><br><span class="line">        box = box[np.logical_and(box_w&gt;<span class="number">1</span>, box_h&gt;<span class="number">1</span>)]</span><br><span class="line">        bboxs_data = np.zeros((len(box),<span class="number">5</span>))</span><br><span class="line">        bboxs_data[:len(box)] = box</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,index+<span class="number">1</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.title(<span class="string">'sample&#123;&#125;'</span>.format(index))</span><br><span class="line">    new_image = draw_bndbox(new_image, box, classes)</span><br><span class="line">    plt.imshow(new_image)</span><br><span class="line"></span><br><span class="line">    index = index + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    image_datas.append(image_data)</span><br><span class="line">    boxes_datas.append(bboxs_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成最终合成图，并将4副图像粘贴到对应位置</span></span><br><span class="line">new_image = np.zeros([h, w, <span class="number">3</span>])</span><br><span class="line">new_image[:cuty, :cutx, :] = image_datas[<span class="number">0</span>][:cuty, :cutx, :]</span><br><span class="line">new_image[cuty:, :cutx, :] = image_datas[<span class="number">1</span>][cuty:, :cutx, :]</span><br><span class="line">new_image[cuty:, cutx:, :] = image_datas[<span class="number">2</span>][cuty:, cutx:, :]</span><br><span class="line">new_image[:cuty, cutx:, :] = image_datas[<span class="number">3</span>][:cuty, cutx:, :]</span><br><span class="line">new_image = np.array(new_image, np.uint8)</span><br><span class="line">new_image = Image.fromarray(new_image)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">这里可以进行一些色域变换</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># box处理</span></span><br><span class="line">new_boxes = merge_bboxes(boxes_datas, cutx, cuty)</span><br><span class="line">box_data = np.zeros((max_boxes, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">if</span> len(new_boxes)&gt;<span class="number">0</span>:</span><br><span class="line">    <span class="keyword">if</span> len(new_boxes)&gt;max_boxes: new_boxes = new_boxes[:max_boxes]</span><br><span class="line">    box_data[:len(new_boxes)] = new_boxes</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.title(<span class="string">'merge'</span>)</span><br><span class="line">new_image = draw_bndbox(new_image, new_boxes, classes)</span><br><span class="line">plt.imshow(new_image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>box合并处理的函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_bboxes</span><span class="params">(bboxes, cutx, cuty)</span>:</span></span><br><span class="line">    merge_bbox = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(bboxes)):</span><br><span class="line">        <span class="keyword">for</span> box <span class="keyword">in</span> bboxes[i]:</span><br><span class="line">            tmp_box = []</span><br><span class="line">            x1, y1, x2, y2 = box[<span class="number">0</span>], box[<span class="number">1</span>], box[<span class="number">2</span>], box[<span class="number">3</span>]</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> y1 &gt; cuty <span class="keyword">or</span> x1 &gt; cutx:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> y2 &gt;= cuty <span class="keyword">and</span> y1 &lt;= cuty:</span><br><span class="line">                    y2 = cuty</span><br><span class="line">                <span class="keyword">if</span> x2 &gt;= cutx <span class="keyword">and</span> x1 &lt;= cutx:</span><br><span class="line">                    x2 = cutx</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> y2 &lt; cuty <span class="keyword">or</span> x1 &gt; cutx:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> y2 &gt;= cuty <span class="keyword">and</span> y1 &lt;= cuty:</span><br><span class="line">                    y1 = cuty</span><br><span class="line">                <span class="keyword">if</span> x2 &gt;= cutx <span class="keyword">and</span> x1 &lt;= cutx:</span><br><span class="line">                    x2 = cutx</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">if</span> y2 &lt; cuty <span class="keyword">or</span> x2 &lt; cutx:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> y2 &gt;= cuty <span class="keyword">and</span> y1 &lt;= cuty:</span><br><span class="line">                    y1 = cuty</span><br><span class="line">                <span class="keyword">if</span> x2 &gt;= cutx <span class="keyword">and</span> x1 &lt;= cutx:</span><br><span class="line">                    x1 = cutx</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">if</span> y1 &gt; cuty <span class="keyword">or</span> x2 &lt; cutx:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> y2 &gt;= cuty <span class="keyword">and</span> y1 &lt;= cuty:</span><br><span class="line">                    y2 = cuty</span><br><span class="line">                <span class="keyword">if</span> x2 &gt;= cutx <span class="keyword">and</span> x1 &lt;= cutx:</span><br><span class="line">                    x1 = cutx</span><br><span class="line">            tmp_box.append(x1)</span><br><span class="line">            tmp_box.append(y1)</span><br><span class="line">            tmp_box.append(x2)</span><br><span class="line">            tmp_box.append(y2)</span><br><span class="line">            tmp_box.append(box[<span class="number">-1</span>])</span><br><span class="line">            merge_bbox.append(tmp_box)</span><br><span class="line">    <span class="keyword">return</span> merge_bbox</span><br></pre></td></tr></table></figure><p>将4副样本进行随机翻转、尺度变换后放置在背景图中的效果</p><img src="/2022/11/11/Mosica数据增强/02.png"><p>最终合成图的效果</p><img src="/2022/11/11/Mosica数据增强/03.png">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Yolov4中使用了Mosica数据增强方法，能够在有限数据集情况下极大程度的增加增强样本量。本文对Mosica数据增强方法进行Python代码实现介绍&lt;/p&gt;
&lt;h1 id=&quot;数据准备&quot;&gt;&lt;a href=&quot;#数据准备&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
  </entry>
  
  <entry>
    <title>VitisAI-07-模型部署</title>
    <link href="http://yoursite.com/2022/08/27/VitisAI-07-%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2022/08/27/VitisAI-07-模型部署/</id>
    <published>2022-08-27T06:23:50.000Z</published>
    <updated>2023-02-02T11:50:59.019Z</updated>
    
    <content type="html"><![CDATA[<p>本文以自定义模型为例，对使用VitisAI进行模型量化部署的流程进行介绍</p><h1 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h1><ul><li><p>数据集为fashion_mnist</p></li><li><p>使用Tensorflow2搭建一个简单分类网络并进行训练，导出模型文件</p></li><li><p>使用VitsiAI docker中的vai_q_tensorflow2工具进行模型量化和校准，得到校准模型文件</p></li><li><p>使用VitisAI docker中的vai_c_tensorflow2工具进行模型编译，生成能够部署在DPU上的模型文件</p></li><li><p>编写模型推理程序(Python)，并将推理程序、编译后的模型文件以及测试图片导入设备中，运行推理程序进行图片分类</p></li></ul><h1 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h1><p>keras内置了fashion_mnist数据集，该数据集是小尺寸商品分类数据集，由28x28的单通道灰度图构成，训练集为60000张图片，测试集为10000张图片</p><p>导入包并加载数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fashion_mnist = keras.datasets.fashion_mnist</span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()</span><br></pre></td></tr></table></figure><p>查看数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(train_images.shape)</span><br><span class="line">print(test_images.shape)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(60000, 28, 28)</span><br><span class="line">(10000, 28, 28)</span><br></pre></td></tr></table></figure><p>保存一些测试数据为图片</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_image_save</span><span class="params">(images, num=<span class="number">32</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        img = Image.fromarray(images[i])</span><br><span class="line">        img.save(<span class="string">'images/&#123;&#125;.jpg'</span>.format(i), quality=<span class="number">100</span>)</span><br><span class="line">test_image_save(test_images, num=<span class="number">32</span>)</span><br></pre></td></tr></table></figure><p>构建模型并打印summary</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">train_images = train_images.reshape((<span class="number">60000</span>, <span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))</span><br><span class="line">test_images = test_images.reshape((<span class="number">10000</span>, <span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))</span><br><span class="line">np.save(<span class="string">'train_images'</span>, train_images)</span><br><span class="line">np.save(<span class="string">'test_images'</span>, test_images)</span><br><span class="line">np.save(<span class="string">'test_labels'</span>, test_labels)</span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    keras.layers.Conv2D(<span class="number">16</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>, </span><br><span class="line">                        input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)),</span><br><span class="line">    keras.layers.Flatten(),</span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">conv2d (Conv2D)              (None, 26, 26, 16)        160       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten (Flatten)            (None, 10816)             0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                (None, 128)               1384576   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 10)                1290      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 1,386,026</span><br><span class="line">Trainable params: 1,386,026</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure><p>编译并训练模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 1.9238 - accuracy: 0.8173</span><br><span class="line">Epoch 2/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.3347 - accuracy: 0.8827</span><br><span class="line">Epoch 3/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.2755 - accuracy: 0.8995</span><br><span class="line">Epoch 4/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.2399 - accuracy: 0.9123 0s -</span><br><span class="line">Epoch 5/20</span><br><span class="line">1875/1875 [==============================] - 14s 7ms/step - loss: 0.2122 - accuracy: 0.9227</span><br><span class="line">Epoch 6/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.1852 - accuracy: 0.9323 0s -</span><br><span class="line">Epoch 7/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.1617 - accuracy: 0.9408</span><br><span class="line">Epoch 8/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.1429 - accuracy: 0.9478</span><br><span class="line">Epoch 9/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.1321 - accuracy: 0.9518</span><br><span class="line">Epoch 10/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.1153 - accuracy: 0.9586</span><br><span class="line">Epoch 11/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.1039 - accuracy: 0.9626</span><br><span class="line">Epoch 12/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.0935 - accuracy: 0.9658</span><br><span class="line">Epoch 13/20</span><br><span class="line">...</span><br><span class="line">Epoch 19/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.0579 - accuracy: 0.9800</span><br><span class="line">Epoch 20/20</span><br><span class="line">1875/1875 [==============================] - 13s 7ms/step - loss: 0.0550 - accuracy: 0.9805</span><br></pre></td></tr></table></figure><p>在测试集验证精度并保存模型为.h5文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'\nTest accuracy:'</span>, test_acc)</span><br><span class="line">model.save(<span class="string">'tf2_fmnist_model.h5'</span>)</span><br></pre></td></tr></table></figure><p>精度还可以吧，毕竟只是随便搭个模型验证流程用的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">313/313 - 1s - loss: 1.0434 - accuracy: 0.8792</span><br><span class="line">Test accuracy: 0.8791999816894531</span><br></pre></td></tr></table></figure><h1 id="Quantization-and-Compile"><a href="#Quantization-and-Compile" class="headerlink" title="Quantization and Compile"></a>Quantization and Compile</h1><p>VitisAI的量化和编译工具在docker中。VAI(VitisAi)量化器以一个浮点模型作为输入，这个浮点模型可以是Tensorflow1.x/2.x、Caffe或者PyTorch生成的模型文件，在量化器中会进行一些预处理，例如折叠BN、删除不需要的节点等，然后对权重、偏置和激活函数量化到指定的位宽(目前仅支持INT8)<br>为了抓取激活函数的统计信息并提高量化模型的准确性，VAI量化器必须运行多次推理来进行校准。校准需要一个100~1000个样本的数据作为输入，这个过程只需要unlabel的图片就可以<br>校准完成后生成量化过的定点模型，该模型还必须经过编译，以生成可以部署在DPU上的模型</p><h2 id="Quantization-the-model"><a href="#Quantization-the-model" class="headerlink" title="Quantization the model"></a>Quantization the model</h2><p>由于训练模型使用的是Tensorflow2，因此这里必须使用docker的vai_q_tensorflow2来进行量化，读者如果使用的是其他框架，请使用对应的量化工具。请注意这里的vai_q_tensorflow2等量化工具并非是Tensorflow提供的，而是VitisAI为不同的深度学习框架定制的量化工具，请勿混淆</p><p>VitisAI中共支持以下4种量化方式</p><ul><li>vai_q_tensorflow：用于量化Tensorflow1.x训练的模型</li><li>vai_q_tensorflow2：用于量化Tensorflow2.x训练的模型</li><li>vai_q_pytorch：用于量化Pytorch训练的模型</li><li>vai_q_caffe：用于量化caffe训练的模型</li></ul><p>这四种量化工具都在docker中，但是在不同的conda虚拟环境中，因此启动进入docker后需要先激活对应的conda环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./docker_run.sh xilinx/vitis-ai</span><br><span class="line">conda activate vitis-ai-tensorflow2</span><br></pre></td></tr></table></figure><p>vai_q_tensorflow2支持两种不同的方法来量化模型</p><ul><li>Post-training quantization (PTQ)：PTQ是一种将预先训练好的浮点模型转换为量化模型的技术，模型精度几乎没有降低。需要一个具有代表性的数据集对浮点模型进行batch推断，以获得激活函数的分布。这个过程也叫量化校准</li><li>Quantization aware training(QAT)：QAT在模型量化期间对前向和后向过程中的量化误差进行建模，对于QAT，建议从精度良好的浮点预训练模型开始，而不是从头开始</li></ul><p>本文选用的是PTQ方式。在VitisAI/models路径下创建文件夹mymodel，将以下文件放入其中</p><ul><li>训练生成的tf2_fmnist_model.h5文件</li><li>训练集train_images.npy用于校准</li><li>测试集test_images.npy、测试标签test_labels用于校准后的评估</li></ul><p>编写quantization.py量化脚本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow_model_optimization.quantization.keras <span class="keyword">import</span> vitis_quantize</span><br><span class="line"></span><br><span class="line">train_images = np.load(<span class="string">'train_images.npy'</span>)</span><br><span class="line">test_images = np.load(<span class="string">'test_images.npy'</span>)</span><br><span class="line">test_labels = np.load(<span class="string">'test_labels.npy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load float model</span></span><br><span class="line">float_model = tf.keras.models.load_model(<span class="string">'tf2_fmnist_model.h5'</span>)</span><br><span class="line"></span><br><span class="line">quantizer = vitis_quantize.VitisQuantizer(float_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set calibration dataset to train_images, save quantized model to quantized.h5</span></span><br><span class="line">quantized_model = quantizer.quantize_model(</span><br><span class="line">    calib_dataset=train_images[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">    include_cle=<span class="literal">True</span>,</span><br><span class="line">    cle_steps=<span class="number">10</span>,</span><br><span class="line">    include_fast_ft=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">quantized_model.save(<span class="string">'quantized.h5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load quantized model</span></span><br><span class="line">quantized_model = keras.models.load_model(<span class="string">'quantized.h5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate quantized model</span></span><br><span class="line">quantized_model.compile(</span><br><span class="line">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">    metrics=[<span class="string">'sparse_categorical_accuracy'</span>]</span><br><span class="line">)</span><br><span class="line">quantized_model.evaluate(test_images, test_labels, batch_size=<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dump quantized model</span></span><br><span class="line">quantizer.dump_model(</span><br><span class="line">    quantized_model, dataset=train_images[<span class="number">0</span>:<span class="number">1</span>], dump_float=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>运行该脚本<br><img src="/2022/08/27/VitisAI-07-模型部署/01.png"></p><p>在目录下生成了quantized.h5量化模型文件，可以看到量化后的模型在测试集上评估精度为0.8797</p><h2 id="Compile-the-model"><a href="#Compile-the-model" class="headerlink" title="Compile the model"></a>Compile the model</h2><p>编译模型需要准备以下文件</p><ul><li><p>quantized.h5：量化生成的模型文件</p></li><li><p>arch.json：DPU描述文件，在vitis项目中，dpu_trd_system_hw_link/Hardware/dpu.build/link/vivado/vpl/prj/prj.gen/sources_1/bd/design_1/ip/design_1_DPUCZDX8G_1_0/arch.json<br>将arch.json拷贝到本目录下，运行以下命令进行编译</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vai_c_tensorflow2 -m quantized.h5 -a arch.json -o ./ -n tf2_cnn_fmnist</span><br></pre></td></tr></table></figure></li></ul><img src="/2022/08/27/VitisAI-07-模型部署/02.png"><p>在目录下生成了tf2_cnn_fmnist.xmodel</p><h1 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h1><p>首先在设备上需要安装VART相关工具，安装脚本在VitisAI仓库的setup/mpsoc/VART中，将该目录下的target_vart_setup.sh拷贝到设备上运行</p><p>编写推理Python程序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> xir</span><br><span class="line"><span class="keyword">import</span> vart</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_graph_from_model</span><span class="params">(path)</span>:</span></span><br><span class="line">    graph = xir.Graph.deserialize(path)</span><br><span class="line">    root = graph.get_root_subgraph()</span><br><span class="line">    <span class="keyword">if</span> root.is_leaf:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    cs = root.toposort_child_subgraph()</span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> cs</span><br><span class="line">        <span class="keyword">if</span> cc.has_attr(<span class="string">"device"</span>) <span class="keyword">and</span> c.get_attr(<span class="string">"device"</span>).upper() == <span class="string">"DPU"</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_preprocess</span><span class="params">(path, input_scale)</span>:</span></span><br><span class="line">    print(<span class="string">'input_scale:&#123;&#125;'</span>.format(input_scale))</span><br><span class="line">    image = cv2.imread(path, <span class="number">0</span>)</span><br><span class="line">    image = image / <span class="number">2</span></span><br><span class="line">    image = image.astype(np.int8)</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_run</span><span class="params">(runner, img)</span>:</span></span><br><span class="line">    input_tensors = runner.get_input_tensors()</span><br><span class="line">    output_tensors = runner.get_output_tensors()</span><br><span class="line">    print(<span class="string">'input tensor type:&#123;&#125;'</span>.format(input_tensors))</span><br><span class="line">    input_ndim = tuple(input_tensors[<span class="number">0</span>].dims)</span><br><span class="line">    print(<span class="string">'input_ndim:&#123;&#125;'</span>.format(input_ndim))</span><br><span class="line">    output_ndim = tuple(output_tensors[<span class="number">0</span>].dims)</span><br><span class="line">    print(<span class="string">'output_ndim:&#123;&#125;'</span>.format(output_ndim))</span><br><span class="line">    input_data = [np.empty(input_ndim, dtype=np.int8, order=<span class="string">"C"</span>)]</span><br><span class="line">    output_data = [np.empty(output_ndim, dtype=np.int8, order=<span class="string">"C"</span>)]</span><br><span class="line">    print(<span class="string">'image shape:&#123;&#125;'</span>.format(img.shape))</span><br><span class="line">    <span class="comment">#input_data[0] = img.reshape(input_ndim[1:])</span></span><br><span class="line">    job_id = runner.execute_async(img.reshape((<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)), output_data)</span><br><span class="line">    runner.wait(job_id)</span><br><span class="line">    print(output_data)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(output_data[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv)</span>:</span></span><br><span class="line">    image_path = argv[<span class="number">1</span>]</span><br><span class="line">    model_path = argv[<span class="number">2</span>]</span><br><span class="line">    print(<span class="string">'image path:&#123;&#125;\nmodel path:&#123;&#125;'</span>.format(</span><br><span class="line">        image_path, model_path))</span><br><span class="line"></span><br><span class="line">    graph = get_graph_from_model(model_path)</span><br><span class="line">    dpu_runner = vart.Runner.create_runner(graph[<span class="number">0</span>], <span class="string">"run"</span>)</span><br><span class="line">    input_fixpos = dpu_runner.get_input_tensors()[<span class="number">0</span>].get_attr(<span class="string">"fix_point"</span>)</span><br><span class="line">    input_scale = <span class="number">2</span>**input_fixpos</span><br><span class="line">    image_data = image_preprocess(image_path, input_scale)</span><br><span class="line">    print(<span class="string">'image shape:&#123;&#125;'</span>.format(image_data.shape))</span><br><span class="line">    print(<span class="string">'&#123;&#125;'</span>.format(image_data.reshape((<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))))</span><br><span class="line">    time_start = time.time()</span><br><span class="line">    pred = model_run(dpu_runner, image_data)</span><br><span class="line">    print(<span class="string">'pred:&#123;&#125;'</span>.format(pred))</span><br><span class="line">    time_end = time.time()</span><br><span class="line"></span><br><span class="line">    timetotal = time_end - time_start</span><br><span class="line">    print(<span class="string">'total time:&#123;&#125;'</span>.format(timetotal))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main(sys.argv)</span><br></pre></td></tr></table></figure><p>将推理程序、编译后的xmodel模型文件以及测试图片拷贝到设备中，运行推理程序，传入测试图片路径和模型文件路径进行推理，会打印出预测结果</p><p>推理代码主要使用了VART API，主要步骤为</p><ul><li>加载模型并转换为计算图graph</li><li>根据计算图生成DPU Runner</li><li>加载输入图片预处理，并构建输入输出Tensor，需要注意各Tensor的shape和dtype</li><li>输入输出Tensor传入DPU Runner，异步执行，并同步等待结果</li><li>输出Tensor转换为期望的预测数据格式</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文以自定义模型为例，对使用VitisAI进行模型量化部署的流程进行介绍&lt;/p&gt;
&lt;h1 id=&quot;Workflow&quot;&gt;&lt;a href=&quot;#Workflow&quot; class=&quot;headerlink&quot; title=&quot;Workflow&quot;&gt;&lt;/a&gt;Workflow&lt;/h1&gt;&lt;ul&gt;

      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
  </entry>
  
  <entry>
    <title>VitisAI-06-DPU-Configuration</title>
    <link href="http://yoursite.com/2022/07/31/VitisAI-06-DPU-Configuration/"/>
    <id>http://yoursite.com/2022/07/31/VitisAI-06-DPU-Configuration/</id>
    <published>2022-07-31T10:53:21.000Z</published>
    <updated>2023-02-02T11:50:21.392Z</updated>
    
    <content type="html"><![CDATA[<p>本文对DPU的一些配置选项进行介绍。主要参考文档为pg338，”DPUCZDX8G for Zynq UltraScale+MPSoCs Product Guide”</p><h1 id="DPU配置文件"><a href="#DPU配置文件" class="headerlink" title="DPU配置文件"></a>DPU配置文件</h1><p>对DPU配置的描述在Vitis工程中，以本系列使用的Vitis工程路径为例，在dpu_trd_system/dpu_trd_kernels/src/prj/Vitis/dpu_conf.vh文件中</p><img src="/2022/07/31/VitisAI-06-DPU-Configuration/01.png"><p>该文件中对DPU的配置项主要有以下6个部分</p><ul><li><p>Architecture Options</p></li><li><p>URAM Enable/Disable</p></li><li><p>DRAM Enable/Disable</p></li><li><p>RAM Usage Configuration</p></li><li><p>Channel Augmentation Configuration</p></li><li><p>DepthWiseConv Configuration</p></li><li><p>Pool Average Configuration</p></li><li><p>Multiplication Feature Maps</p></li><li><p>RELU Type Configuration</p></li><li><p>DSP48 Usage Configuration</p></li><li><p>Power Configuration</p></li><li><p>DEVICE Configuration</p></li></ul><h1 id="Architecture-Options"><a href="#Architecture-Options" class="headerlink" title="Architecture Options"></a>Architecture Options</h1><p>DPU可以被配置为多种多样的卷积架构，这些架构与卷积单元的并行度有关。DPUCZDX8G的可选架构有：B512、B800、B1024、B1152、B1600、B2304、B3136和B4096。不同的架构对逻辑资源的要求不同，更大的架构能够获得更高性能但是代价是占用更多资源</p><p>以下是不同架构在LUT、Register、Block RAM、DSP方面的资源占用情况</p><div class="table-container"><table><thead><tr><th>Architecture</th><th>LUT</th><th>Register</th><th>Block RAM</th><th>DSP</th></tr></thead><tbody><tr><td>B512</td><td>27893</td><td>35435</td><td>73.5</td><td>78</td></tr><tr><td>B800</td><td>30468</td><td>42773</td><td>91.5</td><td>117</td></tr><tr><td>B1024</td><td>34471</td><td>50763</td><td>105.5</td><td>154</td></tr><tr><td>B1152</td><td>33238</td><td>49040</td><td>123</td><td>164</td></tr><tr><td>B1600</td><td>38716</td><td>63033</td><td>127.5</td><td>232</td></tr><tr><td>B2304</td><td>42842</td><td>73326</td><td>167</td><td>326</td></tr><tr><td>B3136</td><td>47667</td><td>85778</td><td>210</td><td>436</td></tr><tr><td>B4096</td><td>53540</td><td>105008</td><td>257</td><td>562</td></tr></tbody></table></div><p>在DPUCZDX8G的卷积操作有3个维度的并行度：像素级并行(Pixel Parallelism，PP)、输入通道并行(Input Channel Parallelism，ICP)和输出通道并行(Output Channel Parallelism， OCP)，以下是不同架构的并行度情况</p><div class="table-container"><table><thead><tr><th>Architecture</th><th>PP</th><th>ICP</th><th>OCP</th><th>Peak Ops</th></tr></thead><tbody><tr><td>B512</td><td>4</td><td>8</td><td>8</td><td>512</td></tr><tr><td>B800</td><td>4</td><td>10</td><td>10</td><td>800</td></tr><tr><td>B1024</td><td>8</td><td>8</td><td>8</td><td>1024</td></tr><tr><td>B1152</td><td>4</td><td>12</td><td>12</td><td>1152</td></tr><tr><td>B1600</td><td>8</td><td>10</td><td>10</td><td>1600</td></tr><tr><td>B2304</td><td>8</td><td>12</td><td>12</td><td>2304</td></tr><tr><td>B3136</td><td>8</td><td>14</td><td>14</td><td>3136</td></tr><tr><td>B4096</td><td>8</td><td>16</td><td>16</td><td>4096</td></tr></tbody></table></div><p>可以看到，架构的命名方式是以每个时钟周期的操作量而定，因为卷积操作是一个乘法跟一个加法，因此单周期操作数为PP*ICP*OCP*2</p><p>dpu_config.vh文件中，可以通过如下部分设置所选用的架构</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">/*====== Architecture Options ======*/</span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line">// | Support 8 DPU size</span><br><span class="line">// | It relates to model. if change, must update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> B512               </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> B800                 </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> B1024                 </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> B1152                 </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> B1600                 </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> B2304                 </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> B3136                 </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> B4096                 </span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> B1024</span><br></pre></td></tr></table></figure><p>这里选用的是B1024，如果选用其他架构，直接修改B1024替换为所选用架构的名称即可</p><h1 id="RAM-Usage"><a href="#RAM-Usage" class="headerlink" title="RAM Usage"></a>RAM Usage</h1><p>权重、偏置和运算过程的一些立即数据是存储在片上内存中的，片上内存包括Block RAM和UltraRAM，不同架构的RAM占用情况不同，高内存占用(High Usage)意味着DPU能够更加灵活的处理中间数据，更高的性能</p><p>dpu_config.vh中与RAM相关的配置有URAM、DRAM和RAM</p><p>以下配置用于开启或关闭URAM的使用，请注意你所使用的FPGA芯片是否有支持URAM</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// |------------------------------------------------------|</span><br><span class="line">// | If the FPGA has Uram. You can <span class="keyword">define</span> URAM_EN parameter               </span><br><span class="line">// | if change, Don't need update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | for zcu104 : `<span class="keyword">define</span> URAM_ENABLE               </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | for zcu102 : `<span class="keyword">define</span> URAM_DISABLE                 </span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> URAM_DISABLE</span><br></pre></td></tr></table></figure><p>以下配置用于开启或关闭DRAM，请注意你所使用的FPGA芯片是否有支持DRAM</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// |------------------------------------------------------|</span><br><span class="line">// | You can use DRAM if FPGA has extra LUTs               </span><br><span class="line">// | if change, Don't need update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Enable DRAM  : `<span class="keyword">define</span> DRAM_ENABLE               </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Disable DRAM : `<span class="keyword">define</span> DRAM_DISABLE                 </span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> DRAM_DISABLE</span><br></pre></td></tr></table></figure><p>以下配置用于选择Block RAM的使用是高占用还是低占用</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// |------------------------------------------------------|</span><br><span class="line">// | RAM Usage Configuration              </span><br><span class="line">// | It relates to model. if change, must update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | RAM Usage High : `<span class="keyword">define</span> RAM_USAGE_HIGH               </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | RAM Usage Low  : `<span class="keyword">define</span> RAM_USAGE_LOW                 </span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> RAM_USAGE_LOW</span><br></pre></td></tr></table></figure><h1 id="Channel-Augmentation"><a href="#Channel-Augmentation" class="headerlink" title="Channel Augmentation"></a>Channel Augmentation</h1><p>通道增强可以用于提升DPU效率，不同架构DPU输入通道最大可以到8的并行度，而一般的卷积运算尤其是图像领域，输入通道通常为3，这样没有充分利用所有输入通道的并行性，而启用通道增强，可以最大程度利用输入通道的并行性</p><p>以下是对通道增强的配置，只能选择开启或关闭</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// |------------------------------------------------------|</span><br><span class="line">// | Channel Augmentation Configuration</span><br><span class="line">// | It relates to model. if change, must update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Enable  : `<span class="keyword">define</span> CHANNEL_AUGMENTATION_ENABLE              </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Disable : `<span class="keyword">define</span> CHANNEL_AUGMENTATION_DISABLE                </span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> CHANNEL_AUGMENTATION_ENABLE</span><br></pre></td></tr></table></figure><h1 id="DepthwiseConv"><a href="#DepthwiseConv" class="headerlink" title="DepthwiseConv"></a>DepthwiseConv</h1><p> 在标准的卷积操作中，每个输入通道对应一个kernel，将所有通道的运算结果结合得到最终卷积结果。而在深度可分离卷积中，运算分为两个步骤：深度卷积和点卷积。深度卷积是指对每个特征图进行单独计算。点卷积是进行1x1的标准卷积。深度可分卷积的并行度只有标准卷积的一半，可以大大提升卷积效率</p><p>以下是深度可分卷积的配置</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// |------------------------------------------------------|</span><br><span class="line">// | DepthWiseConv Configuration</span><br><span class="line">// | It relates to model. if change, must update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Enable  : `<span class="keyword">define</span> DWCV_ENABLE              </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Disable : `<span class="keyword">define</span> DWCV_DISABLE               </span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> DWCV_ENABLE</span><br></pre></td></tr></table></figure><h1 id="ElementWise-Multiply"><a href="#ElementWise-Multiply" class="headerlink" title="ElementWise Multiply"></a>ElementWise Multiply</h1><p>元素点积计算两个特征图的Hadamard乘积</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// |------------------------------------------------------|</span><br><span class="line">// | support multiplication of two feature maps</span><br><span class="line">// | It relates to model. if change, must update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Enable  : `<span class="keyword">define</span> ELEW_MULT_ENABLE           </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Disable : `<span class="keyword">define</span> ELEW_MULT_DISABLE               </span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> ELEW_MULT_DISABLE</span><br></pre></td></tr></table></figure><h1 id="AveragePool"><a href="#AveragePool" class="headerlink" title="AveragePool"></a>AveragePool</h1><p>该选项决定DPU是否支持平均池化，大小可选2x2、3x3到8x8</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// |------------------------------------------------------|</span><br><span class="line">// | Pool Average Configuration</span><br><span class="line">// | It relates to model. if change, must update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Enable  : `<span class="keyword">define</span> POOL_AVG_ENABLE              </span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | Disable : `<span class="keyword">define</span> POOL_AVG_DISABLE                </span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> POOL_AVG_ENABLE</span><br></pre></td></tr></table></figure><h1 id="ReLU-Type"><a href="#ReLU-Type" class="headerlink" title="ReLU Type"></a>ReLU Type</h1><p>ReLU类型决定DPU可用哪种ReLU函数，默认支持ReLU和ReLU6</p><p>以下是ReLU的配置，最多只能选择ReLU+LeakyReLU+ReLU6</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | RELU Type Configuration</span><br><span class="line">// | It relates to model. if change, must update model</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> RELU_RELU6</span><br><span class="line">// +------------------------------------------------------+</span><br><span class="line">// | `<span class="keyword">define</span> RELU_LEAKYRELU_RELU6</span><br><span class="line">// |------------------------------------------------------|</span><br><span class="line"></span><br><span class="line">`<span class="keyword">define</span> RELU_LEAKYRELU_RELU6</span><br></pre></td></tr></table></figure><h1 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h1><p>该选项可以在硬件实现Softmax操作，硬件实现的Softmax是一个独立的加速器，能够支持INT8输入和浮点输出。硬件实现的Softmax比MPSoC上软件实现的Softmax快160倍。硬件实现的Softmax最大只支持1023个分类的任务，如果类别数超过1023则只能使用软件实现</p><p>硬件Softmax并非在dpu_config.vh中配置，而是在vitis的UI界面中添加</p><img src="/2022/07/31/VitisAI-06-DPU-Configuration/02.png"><img src="/2022/07/31/VitisAI-06-DPU-Configuration/03.png">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文对DPU的一些配置选项进行介绍。主要参考文档为pg338，”DPUCZDX8G for Zynq UltraScale+MPSoCs Product Guide”&lt;/p&gt;
&lt;h1 id=&quot;DPU配置文件&quot;&gt;&lt;a href=&quot;#DPU配置文件&quot; class=&quot;header
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="VitisAI" scheme="http://yoursite.com/categories/AI/VitisAI/"/>
    
    
      <category term="Xilinx" scheme="http://yoursite.com/tags/Xilinx/"/>
    
      <category term="Vitis AI" scheme="http://yoursite.com/tags/Vitis-AI/"/>
    
      <category term="DPU" scheme="http://yoursite.com/tags/DPU/"/>
    
      <category term="PetaLinux" scheme="http://yoursite.com/tags/PetaLinux/"/>
    
  </entry>
  
  <entry>
    <title>每月见闻202207</title>
    <link href="http://yoursite.com/2022/07/16/%E6%AF%8F%E6%9C%88%E8%A7%81%E9%97%BB202207/"/>
    <id>http://yoursite.com/2022/07/16/每月见闻202207/</id>
    <published>2022-07-16T07:10:59.000Z</published>
    <updated>2023-02-02T11:49:18.520Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Label-Studio"><a href="#Label-Studio" class="headerlink" title="Label Studio"></a>Label Studio</h1><p>在研究目标检测任务时，必定需要了解如何对自定义的数据集做标注，网络上提到最多的就是labelme，然而我觉得labelme并没有那么好用，这是由于标注这块目前还是挺乱的，一方面目标检测数据集的格式各不相同，例如VOC数据集使用的是xml格式的标注images+annotations，标注坐标为xmin、ymin、xmax、ymax，而YOLO又有自己的标注格式images+labels，标注文件是txt格式，很多开源的目标检测源码支持的格式也各不相同，有些是直接将xml、yolo格式的数据集读进来做训练，有些又是转换成AI框架的数据集格式例如tfrecord，再读取进行训练。在了解标注工具时，我了解到Label Studio这个好用的工具，能够对语音识别、目标检测、实例分割等多种任务的数据进行标注</p><img src="/2022/07/16/每月见闻202207/01.png"><p>在目标检测的标注任务中，Label Studio能够方便添加label，而且可以对不同类别的Bounding Box自由选择颜色</p><img src="/2022/07/16/每月见闻202207/02.png"><p>将标注好的数据支持YOLO、VOC、COCO等格式的导出，非常方便</p><img src="/2022/07/16/每月见闻202207/03.png"><p>可以直接在pip中安装label studio，注意不要安装最新版本，访问有些问题</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U label-studio==1.4</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Label-Studio&quot;&gt;&lt;a href=&quot;#Label-Studio&quot; class=&quot;headerlink&quot; title=&quot;Label Studio&quot;&gt;&lt;/a&gt;Label Studio&lt;/h1&gt;&lt;p&gt;在研究目标检测任务时，必定需要了解如何对自定义的数据集做标注
      
    
    </summary>
    
    
      <category term="每月见闻" scheme="http://yoursite.com/tags/%E6%AF%8F%E6%9C%88%E8%A7%81%E9%97%BB/"/>
    
  </entry>
  
  <entry>
    <title>VitisAI-05-Vitis Flow</title>
    <link href="http://yoursite.com/2022/07/06/VitisAI-05-Vitis-Flow/"/>
    <id>http://yoursite.com/2022/07/06/VitisAI-05-Vitis-Flow/</id>
    <published>2022-07-06T13:15:27.000Z</published>
    <updated>2023-02-02T11:48:30.782Z</updated>
    
    <content type="html"><![CDATA[<p>本文承接VitisAI-04-PetaLinux Flow，介绍使用Xilinx的Vitis工具利用Vivado生成的design_1_wrapper.xsa文件以及PetaLinux编译的rootfs和内核镜像，生成制作好的SD卡镜像文件sd_card.img</p><h1 id="PetaLinux工程准备编译好的各文件"><a href="#PetaLinux工程准备编译好的各文件" class="headerlink" title="PetaLinux工程准备编译好的各文件"></a>PetaLinux工程准备编译好的各文件</h1><p>PetaLinux编译成功后的输出文件在PetaLinux工程的image/linux下，进入此目录，并在其中创建pfm文件夹，并创建boot和sd_dir两个子目录，将Vitis工程需要的PetaLinux输出文件拷贝到新创建的文件夹下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd image/linux</span><br><span class="line">mkdir pfm</span><br><span class="line">mkdir pfm/boot</span><br><span class="line">mkdir pfm/sd_dir</span><br></pre></td></tr></table></figure><p>拷贝以下文件到pfm/boot</p><ul><li><p>bl31.elf</p></li><li><p>pmufw.elf</p></li><li><p>zynqmp_fsbl.elf</p></li><li><p>u-boot.elf</p></li><li><p>system.dtb</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp bl31.elf pmufw.elf zynqmp_fsbl.elf u-boot.elf system.dtb pfm/boot</span><br></pre></td></tr></table></figure><p>拷贝以下文件到pfm/sd_dir</p><ul><li><p>boot.scr</p></li><li><p>system.dtb</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp boot.scr system.dtb pfm/sd_dir</span><br></pre></td></tr></table></figure><h1 id="创建Vitis-Platform-Project"><a href="#创建Vitis-Platform-Project" class="headerlink" title="创建Vitis Platform Project"></a>创建Vitis Platform Project</h1><p>运行Vitis环境变量脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/opt/pkg/xilinx/Vitis/2021.1/settings64.sh</span><br></pre></td></tr></table></figure><p>在dpu_custom下创建dpu_vitis文件夹，并进入，打开vitis</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir dpu_vitis</span><br><span class="line">cd dpu_vitis</span><br><span class="line">vitis</span><br></pre></td></tr></table></figure><p>此时的各项目文件夹路径关系为</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">|--dpu_custom</span><br><span class="line">  |--dpu_vivado</span><br><span class="line">  |--dpu_plnx</span><br><span class="line">  |--dpu_vitis</span><br></pre></td></tr></table></figure><p>选择workspace为dpu_vitis，选择File-&gt;New-&gt;Platform Project，创建一个平台项目，设置项目名为dpu_base，点击Next，选择dpu_vivado中的.xsa硬件描述文件，Operating system选linux，取消勾选Generate boot components，点击Finish</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/01.png"><p>选中linux on psu_cortexa53，在Bif File处点击下三角生成Bif File文件，Boot Components Directory选择PetaLinux项目中创建的pfm/boot，FAT32 Partition Directory选择pfm/sd_dir</p><p>右键工程编译工程，该编译过程很快(1分钟以内)</p><h1 id="Vitis安装Vitis-AI"><a href="#Vitis安装Vitis-AI" class="headerlink" title="Vitis安装Vitis AI"></a>Vitis安装Vitis AI</h1><h2 id="克隆Vitis-AI仓库到本地"><a href="#克隆Vitis-AI仓库到本地" class="headerlink" title="克隆Vitis AI仓库到本地"></a>克隆Vitis AI仓库到本地</h2><p>在Vitis中添加DPU需要预先将Vitis AI仓库克隆到本地，使用如下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/Xilinx/Vitis-AI</span><br></pre></td></tr></table></figure><h2 id="安装Vitis-AI到Vitis"><a href="#安装Vitis-AI到Vitis" class="headerlink" title="安装Vitis AI到Vitis"></a>安装Vitis AI到Vitis</h2><p>在Vitis中选择Windows→Preferences</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/02.png"><p>点击Add添加一个库</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/03.png"><p>ID设置为vitis ai，Name设置为Vitis AI，Location设置为Vitis AI仓库路径</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/04.png"><p>点击Apply and Close</p><h1 id="安装交叉编译环境sdk"><a href="#安装交叉编译环境sdk" class="headerlink" title="安装交叉编译环境sdk"></a>安装交叉编译环境sdk</h1><p>点击<a href="https://www.xilinx.com/bin/public/openDownload?filename=sdk-2021.2.0.0.sh" target="_blank" rel="noopener">sdk-2021.2.0.0.sh</a>下载该sdk，运行以下命令，将其安装到PetaLinux路径下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sdk-2021.2.0.0.sh</span><br></pre></td></tr></table></figure><p>安装完成后PetaLinux安装路径下会出现environment-setup-cortexa72-cortexa53-xilinx-linux的文件</p><h1 id="创建Vitis-Application-工程"><a href="#创建Vitis-Application-工程" class="headerlink" title="创建Vitis Application 工程"></a>创建Vitis Application 工程</h1><p>File→New→Application Project，点击Next，上文创建的platform工程自动出现在选项中，选中并点击Next</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/05.png"><p>设置项目名为dpu_trd，点击Next</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/06.png"><p>设置sysroot path为安装的交叉编译链位置：~/opt/pkg/petalinux/2021.2/sysroots/cortexa72-cortexa53-xilinx-linux，Root FS为dpu_plnx/image/linux/rootfs.ext4，Kernel Image为dpu_plnx/image/linux/image</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/07.png"><p>点击Next，在左侧选中dsa→DPU Kernel(RTL Kernel)，点击Finish(必须在Vitis中成功安装了VitisAi仓库，这一步中才会出现DPU Kernel选项)</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/08.png"><p>将Emulation-SW修改为Hardware</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/09.png"><p>选择dpu_trd_system→dpu_trd_kernel→src→prj→Vitsi→dpi_conf.vh，将B4096改为B1024，之所以改为B1024是因为本文实验环境使用的FPGA芯片资源有限，只能选择B1024的DPU，这里的B1024和B4096是DPU不同架构配置，越大的数字代表了越高的并行度和计算性能，但同时占用更多片上资源(LUT、RAM、DSP)，关于DPU相关的配置参数和资源占用，包括dpi_conf.vh文件中可选的参数含义，后续会专门出一片文章来介绍</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/10.png"><p>选择dpu_trd_system→dpu_trd_system_hw_link→dpu_trd_system_hw_link.prj，去除sfm_xrt_top，减少DPU数量为1(将DPU数量减小到1也是由于本文使用的FPGA资源受限)</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/11.png"><img src="/2022/07/06/VitisAI-05-Vitis-Flow/12.png"><p>在Assistant窗口双击dpu_trd_system，弹出窗口</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/13.png"><p>选择dpu_trd_system→dpu_trd_system_hw_link→Hardware→dpu</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/14.png"><p>点击V++configuration settings的省略号按钮，为其添加时钟配置</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/15.png"><p>添加如下代码</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[clock]</span><br><span class="line">id=1:DPUCZDX8G_1.aclk</span><br><span class="line">id=2:DPUCZDX8G_1.ap_clk_2</span><br><span class="line"></span><br><span class="line">[connectivity]</span><br><span class="line">sp=DPUCZDX8G_1.M_AXI_GP0:HPC0</span><br><span class="line">sp=DPUCZDX8G_1.M_AXI_HP0:HP0</span><br><span class="line">sp=DPUCZDX8G_1.M_AXI_HP2:HP1</span><br></pre></td></tr></table></figure><p>这里的时钟接口和vivado中配置的时钟一一对应</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/16.png"><p>有些版本Vitis编译过程会出现找不到opencv库的error，点击Apply and Close，在dpu_trd_system→dpu_trd上右键选择C/C+= Build Settings</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/17.png"><p>在includes中添加</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;SYSROOT&#125;/usr/<span class="keyword">include</span>/opencv4</span><br></pre></td></tr></table></figure><p>点击Apply</p><p>右键dpu_trd_system进行编译，该过程耗时较长，本机环境编译时长在20~30分钟。编译成功后，在vitis工程路径下的dpu_trd_system/Hardware/package路径下会生成sd_card.img</p><img src="/2022/07/06/VitisAI-05-Vitis-Flow/18.png"><p>该文件是合并了linux内核镜像、uboot、dpu,xclbin二进制文件以及设备树文件的SD卡镜像文件，SD卡分区已经做好的，直接使用balenaEtcher将该文件烧写到SD卡中即可</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文承接VitisAI-04-PetaLinux Flow，介绍使用Xilinx的Vitis工具利用Vivado生成的design_1_wrapper.xsa文件以及PetaLinux编译的rootfs和内核镜像，生成制作好的SD卡镜像文件sd_card.img&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="VitisAI" scheme="http://yoursite.com/categories/AI/VitisAI/"/>
    
    
      <category term="Xilinx" scheme="http://yoursite.com/tags/Xilinx/"/>
    
      <category term="Vitis AI" scheme="http://yoursite.com/tags/Vitis-AI/"/>
    
      <category term="DPU" scheme="http://yoursite.com/tags/DPU/"/>
    
      <category term="PetaLinux" scheme="http://yoursite.com/tags/PetaLinux/"/>
    
  </entry>
  
  <entry>
    <title>VitisAI-04-PetaLinux Flow</title>
    <link href="http://yoursite.com/2022/06/30/VitisAI-04-PetaLinux-Flow/"/>
    <id>http://yoursite.com/2022/06/30/VitisAI-04-PetaLinux-Flow/</id>
    <published>2022-06-30T08:56:43.000Z</published>
    <updated>2023-02-02T11:47:51.815Z</updated>
    
    <content type="html"><![CDATA[<p>本文承接VitisAI-03-Vivado Flow，介绍使用Xilinx的PetaLinux工具将Vivado生成的design_1_wrapper.xsa文件创建PetaLinux并编译生成Linux镜像和rootfs的过程</p><h1 id="创建PetaLinux工程"><a href="#创建PetaLinux工程" class="headerlink" title="创建PetaLinux工程"></a>创建PetaLinux工程</h1><p>首先运行PetaLinux的环境变量脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/opt/pkg/Xilinx/PetaLinux/2021.2/settings.sh</span><br></pre></td></tr></table></figure><p>在dpu_vivado同级目录下，通过以下命令创建一个PetaLinux工程”dpu_plnx”</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">petalinux-create --type project --template zynqMP --name dpu_plnx</span><br></pre></td></tr></table></figure><p>将vivado生成的.xsa文件拷贝到PetaLinux工程目录下并进行工程配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp dpu_vivado/dpu_hardware/design_1_wrapper.xsa dpu_plnx</span><br><span class="line">cd dpu_plnx</span><br><span class="line">petalinux-config --get-hw-description=.</span><br></pre></td></tr></table></figure><p>运行配置命令后，会弹出类似配置内核时的menuconfig界面</p><img src="/2022/06/30/VitisAI-04-PetaLinux-Flow/01.png"><h2 id="设置离线编译"><a href="#设置离线编译" class="headerlink" title="设置离线编译"></a>设置离线编译</h2><p>由于PetaLinux的编译过程中需要从网络中下载很多包资源，并且很多包的源是外网，编译过程会很缓慢。Xilinx为PetaLinux的编译提供了离线下载方式，官网将PetaLinux编译依赖的包资源进行了打包处理，预先将依赖包下载到本地，再进行PetaLinux编译时，可以极大的加快编译速度，非常建议使用。离线编译包的下载在VitisAI-02-环境与资源文章中已经介绍，离线编译的缺点是需要占用100G+的磁盘容量</p><p>本文环境，已将downloads_2021.2.tar.gz和sstate_aarch64_2021.2.tar.gz两个文件下载并解压至~/opt/sstate-cache/downloads_2021.2和~/opt/sstate-cache/sstate_aarch64_2021.2路径下</p><ol><li><p>关闭Enable Network sstate feeds</p><p>petalinux-config中，进入Yocto Settings，取消选择Yocto Settings→Enable Network sstate feeds</p></li><li><p>开启Enable BB NO Network</p><p>选中Yocto Settings→Enable Network sstate feeds</p></li><li><p>设置local sstate feeds url</p><p>Yocto Settings→local sstate feeds url设置为”/home/username/opt/sstate-cache/sstate_aarch64_2021.2/aarch64”</p></li><li><p>设置Add pre-mirror url path</p><p>Yocto Settings→Add pre-mirror url path设置为”file:///home/username/opt/sstate-cache/downloads_2021.2”</p></li></ol><img src="/2022/06/30/VitisAI-04-PetaLinux-Flow/02.png"><h2 id="修改文件系统类型为ext4"><a href="#修改文件系统类型为ext4" class="headerlink" title="修改文件系统类型为ext4"></a>修改文件系统类型为ext4</h2><p>petalinux-config退回到根目录，选择Image Packaging Configuration-&gt;Root filesystem type为EXT4</p><img src="/2022/06/30/VitisAI-04-PetaLinux-Flow/03.png"><p>由于本文所使用FPGA开发板有EMMC和SD卡两个外部存储，根文件系统是放在SD卡中，SD卡为分区1，因此还需要修改SD卡的分区为/dev/mmcblk1p2</p><img src="/2022/06/30/VitisAI-04-PetaLinux-Flow/04.png"><p>至此，在petalinux-config需要修改的内容完毕</p><h1 id="去掉dnndk"><a href="#去掉dnndk" class="headerlink" title="去掉dnndk"></a>去掉dnndk</h1><p>dnndk是vitisai老版本中使用的开发工具，新版本中已经废除了，需要在vitisai.bb中去掉dnndk</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim components/yocto/layers/meta-petalinux/recipes-core/packagegroups/packagegroup-petalinux-vitisai.bb</span><br></pre></td></tr></table></figure><h1 id="修改设备树文件"><a href="#修改设备树文件" class="headerlink" title="修改设备树文件"></a>修改设备树文件</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim project-spec/meta-user/recipes-bsp/device-tree/files/system-user.dtsi</span><br></pre></td></tr></table></figure><p>修改为</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/include/ "system-conf.dtsi"</span><br><span class="line">/ &#123;</span><br><span class="line">        chosen &#123;</span><br><span class="line">                bootargs = "earlycon console=ttyPS0,115200 clk_ignore_unused root=/dev/mmcblk1p2 rw rootwait cma=512M";</span><br><span class="line">        &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&amp;sdhci1 &#123;</span><br><span class="line">        no-1-8-v;</span><br><span class="line">        disable-wp;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">/* USB */</span><br><span class="line">&amp;dwc3_0 &#123;</span><br><span class="line">    status="okay";</span><br><span class="line">    dr_mode="host";</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h1 id="配置kernel"><a href="#配置kernel" class="headerlink" title="配置kernel"></a>配置kernel</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">petalinux-config -c kernel</span><br></pre></td></tr></table></figure><h1 id="配置rootfs"><a href="#配置rootfs" class="headerlink" title="配置rootfs"></a>配置rootfs</h1><h2 id="rootfs添加user-package"><a href="#rootfs添加user-package" class="headerlink" title="rootfs添加user package"></a>rootfs添加user package</h2><p>vim打开user-rootfsconfig文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim project-spec/meta-user/conf/user-rootfsconfig</span><br></pre></td></tr></table></figure><p>添加以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CONFIG_xrt</span><br><span class="line">CONFIG_dnf</span><br><span class="line">CONFIG_e2fsprogs-resize2fs</span><br><span class="line">CONFIG_parted</span><br><span class="line">CONFIG_resize-part</span><br><span class="line">CONFIG_packagegroup-petalinux-vitisai</span><br><span class="line">CONFIG_packagegroup-petalinux-self-hosted</span><br><span class="line">CONFIG_cmake</span><br><span class="line">CONFIG_packagegroup-petalinux-vitisai-dev</span><br><span class="line">CONFIG_xrt-dev</span><br><span class="line">CONFIG_opencl-clhpp-dev</span><br><span class="line">CONFIG_opencl-headers-dev</span><br><span class="line">CONFIG_packagegroup-petalinux-opencv</span><br><span class="line">CONFIG_packagegroup-petalinux-opencv-dev</span><br><span class="line">CONFIG_mesa-megadriver</span><br><span class="line">CONFIG_packagegroup-petalinux-x11</span><br><span class="line">CONFIG_packagegroup-petalinux-v4lutils</span><br><span class="line">CONFIG_packagegroup-petalinux-matchbox</span><br></pre></td></tr></table></figure><p>配置rootfs</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">petalinux-config -c rootfs</span><br></pre></td></tr></table></figure><p>选择user packages，选中所有内容</p><img src="/2022/06/30/VitisAI-04-PetaLinux-Flow/05.png"><h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">petalinux-build</span><br></pre></td></tr></table></figure><p>编译后在工程目录下的images/linux路径下会生成u-boot、rootfs、linux image等文件</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文承接VitisAI-03-Vivado Flow，介绍使用Xilinx的PetaLinux工具将Vivado生成的design_1_wrapper.xsa文件创建PetaLinux并编译生成Linux镜像和rootfs的过程&lt;/p&gt;
&lt;h1 id=&quot;创建PetaLinu
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="VitisAI" scheme="http://yoursite.com/categories/AI/VitisAI/"/>
    
    
      <category term="Xilinx" scheme="http://yoursite.com/tags/Xilinx/"/>
    
      <category term="Vitis AI" scheme="http://yoursite.com/tags/Vitis-AI/"/>
    
      <category term="DPU" scheme="http://yoursite.com/tags/DPU/"/>
    
      <category term="PetaLinux" scheme="http://yoursite.com/tags/PetaLinux/"/>
    
  </entry>
  
  <entry>
    <title>Arm Cortex-M 高效神经网络计算</title>
    <link href="http://yoursite.com/2022/05/31/Arm-Cortex-M-%E9%AB%98%E6%95%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%A1%E7%AE%97/"/>
    <id>http://yoursite.com/2022/05/31/Arm-Cortex-M-高效神经网络计算/</id>
    <published>2022-05-31T09:15:59.000Z</published>
    <updated>2023-02-02T11:46:43.651Z</updated>
    
    <content type="html"><![CDATA[<p>本文源自ARM CMSIS-NN项目的一篇论文”CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs”。CMSIS-NN是一种高效的内核，用于将最大化性能和最小化内存占用的神经网络应用于Arm Cortex-M处理器上。基于CMSIS-NN核的神经网络在推理运行时间上提高4.6倍，在能效上提高4.9倍</p><p>随着物联网的发展，各种边缘设备的规模迅速发展，各种边缘设备收集的数据需要经由无线网络传送到云端处理。随着节点数量的增加，对网络带宽造成了很大的负担，并增加了延迟，另一方面是数据的安全问题。一个好的解决方案是边缘计算</p><p>另一方面，深度神经网络在很多复杂任务中的表现已经超过人类，例如图像分类、语音识别、自然语言处理等。但是由于计算复杂度和资源要求较高，NN的执行主要局限于高性能服务器或专用硬件加速的云计算服务，这增加了网络负担。如果能在数据收集的边缘设备上部署一些小型的神经网络进行简单轻量化任务，这将减少整个网络的延迟和能源消耗</p><p>CMSIS-NN的神经网络内核结构如图，内核代码包括两部分：NNFunctions和NNSupportFunctions。NNFunctions包括一些神经网络层函数，如卷积、深度可分离卷积、全连接、池化和激活等，这些函数可被应用程序代码调用以实现神经网络推理。NNSupportFunctions包括一些实用的计算函数，如数据转换、一些查找表</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/01.PNG"><h1 id="定点量化"><a href="#定点量化" class="headerlink" title="定点量化"></a>定点量化</h1><p>神经网络模型使用32位浮点数据进行训练，然而在推理过程中并不需要这么高的精度。研究表明，即使在低精读定点表示下，神经网络也能很好的工作。定点量化有助于避免昂贵的浮点计算，并减少存储权重和激活函数的内存占用，这对于资源受限的平台至关重要。CMSIS-NN同时支持8位和16位的定点</p><p>CMSIS-NN中使用<code>q7_t</code>和<code>q15_t</code>来表示<code>int8</code>和<code>int16</code>类型。量化方式使用的是”Power of 2”，即将数据表示为$A \times 2^{n}$的形式，其中$A$为整数值，$n$为缩放因子，内核在进行运算时使用移位来量化和反量化。这种量化方式的好处是不需要额外的FPU来进行浮点数据运算，很多微控制器没有FPU</p><h1 id="优化的内核"><a href="#优化的内核" class="headerlink" title="优化的内核"></a>优化的内核</h1><p>Arm Cortex-M处理器支持SIMD指令，特别是对神经网络计算非常有效的16位乘积指令</p><h2 id="Support-Functions"><a href="#Support-Functions" class="headerlink" title="Support Functions"></a>Support Functions</h2><p>大多数NNFunctions使用16位的乘积指令，因此需要将<code>q7_t</code>转为<code>q15_t</code>。CMSIS提供了一个实用的函数<code>arm_q7_to_q15</code>。数据转换分两步完成，第一步是通过使用符号扩展指令<code>__SXTB16</code>将8位数据扩展为16位，第二步是重新排列数据，使输出数据与输入数据顺序相同</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/02.PNG"><p>因为在NN计算过程中，需要调用很多次数据转换，因此它的性能至关重要。如果两个操作数遵循相同的的顺序，则可以省略第二步的重新排序。为了更好的利用这一点，创建了另一个版本的数据转换，不需要重新排序</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/03.PNG"><h2 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h2><p>矩阵乘法是神经网络中最重要的计算核，CMSIS中使用2x2的核来实现。乘积结果是32位数据，乘积使用<code>__SMLAD</code></p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/04.PNG"><p>正常的操作下，Sum11是由A的第一行与B的第一列对应元素乘积的和构成，每次取一个元素，则需要循环4次</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/05.PNG"><p><code>__SIMD32</code>指令一次取32位数据，由于数据是<code>q15_t</code>的，因此一次可以读入2个数据，只需循环两次即可完成</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/06.PNG"><p>上文中提到<code>q7_t</code>扩展到<code>q15_t</code>去掉重新排列的问题，在矩阵乘法中，可以不用进行重排来提高性能。但是当元素数量不是4倍数时，数据对齐会比较棘手</p><p>如下图，<code>q7_t</code>扩展到<code>q15_t</code>时，A和B的数据元素位置都交错了，但是由于相乘时元素的对应关系没有改变，因此结果不变</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/07.PNG"><p>另一种场景是<code>q7_t</code>的权重和<code>q15_t</code>的激活函数。这种情况下，权重可以通过交换每32位的第二和第三字节进行预处理，即将[1,2,3,4]转换为[1,3,2,4]，经过预处理后，不需要重新排序，扩展后的权重数据顺序会回到[1,2,3,4]</p><p>全连接层的向量与矩阵乘法也可以利用1x2的核来提高性能</p><p>由于权重一直保持不变，并在推断期间重复使用，可以重新排序权重矩阵，以便行数据交错，并且只需要一个指针访问就可以读取。这种权重调整如图所示</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/08.PNG"><p>矩阵向量相乘时，使用相同的<code>q7_t</code>扩展到<code>q15_t</code>函数，不需要重新排列，这样可以使用可用的寄存器来容纳1x4的内核</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/09.PNG"><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>通常，一个基于CPU的卷积实现被分解位输入重新排序和展开(im2col)以及矩阵乘法。im2col是将类似图像的输入转换为表示每个卷积滤波器所需数据的列的过程</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/10.PNG"><p>im2col的主要问题是内存占用很高，im2col矩阵中有很多重复项。为了解决内存占用问题，同时保留im2col带来的性能优势，为卷积内核实现了部分im2col。内核只会扩展为有限的列，足以从矩阵乘法内核获得最大性能提升，同时保持最小内核开销</p><p>数据格式也会影响卷积性能。当batchsize为1时，卷积操作是对3D数据的二维卷积，延两个方向移动</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/11.PNG"><p>最常见的两种图像数据格式是CHW和HWC。在HWC格式中，沿通道的数据以步长1存储，沿宽度的数据以通道计数的步长存储，沿高度的数据以(通道计数x图像宽度)步长存储。HWC格式的数据可以实现高效的数据移动，每个像素是连续存储的，可以通过SIMD指令高效的复制。在Arm Cortex-M7上将CHW和HWC进行了比较，HWC输入固定为16x16x16，当输出通道为0时，意味着只执行im2col操作，不执行矩阵乘法。与CHW格式相比，相同矩阵乘法，HWC有更少的运行时间</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/12.PNG"><h2 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h2><p>与卷积类似，池化是一个基于窗口的操作，具有给定的内核大小，步长和填充。与卷积不同，池化通常在同一通道内操作，并独立于其他通道的数据。一个有效的池化替代方案是将池化操作分为x池化和y池化。这样，x方向上的池化操作(最大、平均)可以在y方向上重复使用，从而减少了操作总数，称这种方法为x-y池化。x-y池化的一个潜在问题是数据安排，因为需要额外的内存来存储中间结果。为了消除额外内存的要求，内核在原位进行池化，这样池化对输入数据进行了破坏</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/13.PNG"><h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p>CMSIS中使用类似SWAR的概念来实现ReLU。关键是识别<code>q7_t</code>的符号位，如果数字为负数，则使其为0。实现方式如下图</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/14.PNG"><p>将符号位提取出来构成一个字节，通过使用字节级减法指令<code>__QSUB8</code>将0与符号位提取生成的字节数相减，得到一个掩码，如果是负数，则提取的字节为0x01，0减去0x01为0xFF，那么原始数据与0xFF的非得到0，如果是整数，0减0依然是0，原始数据与0x00的非还是原始数据</p><h2 id="Sigmoid-and-Tanh"><a href="#Sigmoid-and-Tanh" class="headerlink" title="Sigmoid and Tanh"></a>Sigmoid and Tanh</h2><p>sigmoid和tanh需要使用专用的数学函数，这种计算在Cortex-M架构的CPU上计算程本很高，因此使用固定输入和固定输出的查找表来实现。有两种方式实现的查找表，第一种是对所有范围使用一个统一的表，输入粒度固定，输入的MSB用于识别查找表中的条目，LSB可以用于线性插值</p><p>另一种选择是实现两个独立的表，以覆盖函数的不同区域，这样精度更高，因为sigmoid和tanh都是高度非线性的。对于0附近的输入区域，应该有一个细粒度的表，对于绝对值较大的区域，有另一个粗粒度的表</p><p>确定sigmoid和tanh函数表的范围是很重要的，CMSIS中使用了[-8,8]，因为sigmoid(8)=0.9997，tanh(8)=0.9999</p><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>在CIFAR-10数据集上训练的CNN测试了CMSIS-NN内核，该数据集由6万张32x32的彩色图像组成，分为10个类别。网络结构如下表，3个卷积层和一个全连接层。所有权重和激活函数都量化为<code>q7_t</code></p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/15.PNG"><p>整个图像分类每张约运行99.1ms，帧频约为10fps。运行该网络时，CPU计算吞吐量大约为每秒249MOps。在CIFAR-10测试集上，预量化网络准确率达到80.3%，在Arm Cortex-M7上运行的8位量化网络达到79.9%。使用CMSIS-NN内核最大内存占用为133KB，其中使用部分im2col实现卷积以节省内存。如果不使用部分im2col，内存开销将到达332KB</p><p>为了量化CMSIS-NN内核相对于现有方案的优势，使用了一维卷积函数实现了一个基线版本。下表总结了基线版本与CMSIS-NN的结果比较，CMSIS-NN在运行时间上比基线版本提高了2.6倍，吞吐量上提高了5.4倍</p><img src="/2022/05/31/Arm-Cortex-M-高效神经网络计算/16.PNG"><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://arm-software.github.io/CMSIS_5/NN/html/index.html" target="_blank" rel="noopener">CMSIS NN Software Library</a></p><p><a href="https://github.com/ARM-software/CMSIS_5" target="_blank" rel="noopener">GitHub - CMSIS_5</a></p><p><a href="https://www.arxiv.org/abs/1801.06601" target="_blank" rel="noopener">arxiv - CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文源自ARM CMSIS-NN项目的一篇论文”CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs”。CMSIS-NN是一种高效的内核，用于将最大化性能和最小化内存占用的神经网络应用于Arm Co
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="量化与加速" scheme="http://yoursite.com/categories/AI/%E9%87%8F%E5%8C%96%E4%B8%8E%E5%8A%A0%E9%80%9F/"/>
    
    
      <category term="Arm Cortex-M" scheme="http://yoursite.com/tags/Arm-Cortex-M/"/>
    
      <category term="神经网络" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="加速计算" scheme="http://yoursite.com/tags/%E5%8A%A0%E9%80%9F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="神经网络量化" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>DIP-boxfilter快速窗口求和</title>
    <link href="http://yoursite.com/2022/05/25/DIP-boxfilter%E5%BF%AB%E9%80%9F%E7%AA%97%E5%8F%A3%E6%B1%82%E5%92%8C/"/>
    <id>http://yoursite.com/2022/05/25/DIP-boxfilter快速窗口求和/</id>
    <published>2022-05-25T07:43:45.000Z</published>
    <updated>2023-02-02T11:45:59.111Z</updated>
    
    <content type="html"><![CDATA[<p>在很多图像处理任务中，需要对局部图像数据进行窗口运算，许多运算都需要获得局部区域像素的均值和方差，这些计算都离不开求和运算。我在研究引导滤波时，发现何凯明在其提供的引导滤波matlab参考代码中，使用了boxfilter的快速计算方法，能够以$O(1)$的时间复杂度对矩阵进行局部快速求和运算</p><p>本文对以python代码为例，对boxfilter的运算细节进行可视化分析，使读者对整个计算过程有一个直观的感受，然后将正常的卷积局部求和操作与boxfilter进行性能比较</p><h1 id="运算过程分析"><a href="#运算过程分析" class="headerlink" title="运算过程分析"></a>运算过程分析</h1><p>首先对boxfilter的输入和输出进行说明，boxfilter的输入是要计算局部窗口和的整幅图像$I$，输出是与输入图像尺寸相同的图像$F$，输出图像某个像素的值$F(x,y)$是以$I(x,y)$为中心的一个窗口内所有像素值的和，窗口在图像上滑动，与卷积操作类似，窗口大小也是一个输入参数，一般以窗口半径$r$来表示。下图是输入与输出关系的示意图</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/01.png"><p>输出图像是将一个窗口的求和作用于输入图像的结果，上图中窗口半径为1，则窗口尺寸为3x3，图中输入图像中的黄色3x3区域即为一个窗口，该窗口内输入图像的像素之和对应于输出图像的黄色像素</p><p>下面将详细介绍整个快速计算的过程，引入依赖库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>定义一个8x8的二维单位矩阵作为输入图像，定义窗口半径为1，则kernel size为3x3，创建一个与输入图像相同shape的0矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">r = <span class="number">1</span></span><br><span class="line">imSrc = np.ones((<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">I = imSrc.copy()</span><br><span class="line">imDst = np.zeros(I.shape)</span><br><span class="line">h, w = I.shape</span><br></pre></td></tr></table></figure><p>打印imSrc</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(imSrc)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[1. 1. 1. 1. 1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1. 1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1. 1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1. 1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1. 1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1. 1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1. 1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1. 1. 1. 1. 1.]]</span><br></pre></td></tr></table></figure><p>打印imDst</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(imDst)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]]</span><br></pre></td></tr></table></figure><p>对输入图像进行行方向的累加求和，并打印</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">I = np.cumsum(I, <span class="number">0</span>)</span><br><span class="line">print(I)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[1. 1. 1. 1. 1. 1. 1. 1.]</span><br><span class="line"> [2. 2. 2. 2. 2. 2. 2. 2.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [4. 4. 4. 4. 4. 4. 4. 4.]</span><br><span class="line"> [5. 5. 5. 5. 5. 5. 5. 5.]</span><br><span class="line"> [6. 6. 6. 6. 6. 6. 6. 6.]</span><br><span class="line"> [7. 7. 7. 7. 7. 7. 7. 7.]</span><br><span class="line"> [8. 8. 8. 8. 8. 8. 8. 8.]]</span><br></pre></td></tr></table></figure><p>将累加求和后的矩阵2、3两行复制到imDst的第1、2行，并打印(本文中描述第n行，n从1开始)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imDst[:r+<span class="number">1</span>, :] = I[r:<span class="number">2</span>*r+<span class="number">1</span>, :]</span><br><span class="line">print(imDst)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[2. 2. 2. 2. 2. 2. 2. 2.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]]</span><br></pre></td></tr></table></figure><p>这一步的过程如下图所示</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/02.png"><p>该操作的含义是当求和窗口未完全在图像内部时的图像边缘求和处理</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/03.png"><p>然后将累加矩阵的第4到8行减去1到5行的结果复制到imDst的第3到7行，并打印</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imDst[r+<span class="number">1</span>:h-r, :] = I[<span class="number">2</span>*r+<span class="number">1</span>:, :] - I[:h<span class="number">-2</span>*r<span class="number">-1</span>, :]</span><br><span class="line">print(imDst)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[2. 2. 2. 2. 2. 2. 2. 2.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [0. 0. 0. 0. 0. 0. 0. 0.]]</span><br></pre></td></tr></table></figure><p>示意图如下</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/04.png"><p>然后将累加矩阵的最后一行与第6行相减，结果复制到imDst的第8行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imDst[h-r:,:]=np.matlib.repmat(I[h<span class="number">-1</span>,:],r,<span class="number">1</span>)-I[h<span class="number">-2</span>*r<span class="number">-1</span>:h-r<span class="number">-1</span>,:]</span><br><span class="line">print(imDst))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[2. 2. 2. 2. 2. 2. 2. 2.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [3. 3. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [2. 2. 2. 2. 2. 2. 2. 2.]]</span><br></pre></td></tr></table></figure><p>示意图如下</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/05.png"><p>这里使用的repmat含义是将累加矩阵的最后一行复制为一个r行的矩阵，因为r为1，因此不进行任何操作。如果r大于1时，在下边缘处的窗口计算，就需要补一行</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/06.png"><p>至此，行处理完成，接下来进行列处理。首先是对输入图像进行列方向的累加求和，并打印</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">I = np.cumsum(imDst, <span class="number">1</span>)</span><br><span class="line">print(I)</span><br></pre></td></tr></table></figure><p>注意列方向进行累加求和是在行方向累加求和基础上做的</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[ 2.  4.  6.  8. 10. 12. 14. 16.]</span><br><span class="line"> [ 3.  6.  9. 12. 15. 18. 21. 24.]</span><br><span class="line"> [ 3.  6.  9. 12. 15. 18. 21. 24.]</span><br><span class="line"> [ 3.  6.  9. 12. 15. 18. 21. 24.]</span><br><span class="line"> [ 3.  6.  9. 12. 15. 18. 21. 24.]</span><br><span class="line"> [ 3.  6.  9. 12. 15. 18. 21. 24.]</span><br><span class="line"> [ 3.  6.  9. 12. 15. 18. 21. 24.]</span><br><span class="line"> [ 2.  4.  6.  8. 10. 12. 14. 16.]]</span><br></pre></td></tr></table></figure><p>然后将累加和的前第2、3列拷贝到imDst的第1、2列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imDst[:,:r+<span class="number">1</span>] = I[:,r:<span class="number">2</span>*r+<span class="number">1</span>]</span><br><span class="line">print(imDst)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[4. 6. 2. 2. 2. 2. 2. 2.]</span><br><span class="line"> [6. 9. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [6. 9. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [6. 9. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [6. 9. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [6. 9. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [6. 9. 3. 3. 3. 3. 3. 3.]</span><br><span class="line"> [4. 6. 2. 2. 2. 2. 2. 2.]]</span><br></pre></td></tr></table></figure><p>示意图如下</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/07.png"><p>然后将累加和的第4到8列减去1到5列，结果拷贝到imDst的第3到7列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imDst[:,r+<span class="number">1</span>:w-r] = I[:,<span class="number">2</span>*r+<span class="number">1</span>:]-I[:,:w<span class="number">-2</span>*r<span class="number">-1</span>]</span><br><span class="line">print(imDst)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[4. 6. 6. 6. 6. 6. 6. 2.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 3.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 3.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 3.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 3.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 3.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 3.]</span><br><span class="line"> [4. 6. 6. 6. 6. 6. 6. 2.]]</span><br></pre></td></tr></table></figure><p>示意图如下</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/08.png"><p>最后将累加和第8列减去第6列，结果复制到imDst的第8列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imDst[:,w-r:] = np.matlib.repmat(I[:,w<span class="number">-1</span>].reshape(<span class="number">-1</span>,<span class="number">1</span>),<span class="number">1</span>,r)-I[:,w<span class="number">-2</span>*r<span class="number">-1</span>:w-r<span class="number">-1</span>]</span><br><span class="line">print(imDst)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[4. 6. 6. 6. 6. 6. 6. 4.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [4. 6. 6. 6. 6. 6. 6. 4.]]</span><br></pre></td></tr></table></figure><p>示意图如下</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/09.png"><p>这个结果是否正确呢？可以选取几个局部窗口位置计算一下，可以看到，结果确实是正确的</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/10.png"><p>整合之后的boxfilter函数如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">boxfilter</span><span class="params">(im, r)</span>:</span></span><br><span class="line">    I = im.copy()</span><br><span class="line">    imDst = np.zeros(I.shape)</span><br><span class="line">    h, w = I.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># row process</span></span><br><span class="line">    I = np.cumsum(I, <span class="number">0</span>)</span><br><span class="line">    imDst[:r+<span class="number">1</span>, :] = I[r:<span class="number">2</span>*r+<span class="number">1</span>, :]</span><br><span class="line">    imDst[r+<span class="number">1</span>:h-r, :] = I[<span class="number">2</span>*r+<span class="number">1</span>:, :] - I[:h<span class="number">-2</span>*r<span class="number">-1</span>, :]</span><br><span class="line">    imDst[h-r:,:]=np.matlib.repmat(I[h<span class="number">-1</span>,:],r,<span class="number">1</span>)-I[h<span class="number">-2</span>*r<span class="number">-1</span>:h-r<span class="number">-1</span>,:]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># col process</span></span><br><span class="line">    I = np.cumsum(imDst, <span class="number">1</span>)</span><br><span class="line">    imDst[:,:r+<span class="number">1</span>] = I[:,r:<span class="number">2</span>*r+<span class="number">1</span>]</span><br><span class="line">    imDst[:,r+<span class="number">1</span>:w-r] = I[:,<span class="number">2</span>*r+<span class="number">1</span>:]-I[:,:w<span class="number">-2</span>*r<span class="number">-1</span>]</span><br><span class="line">    imDst[:,w-r:] = np.matlib.repmat(I[:,w<span class="number">-1</span>].reshape(<span class="number">-1</span>,<span class="number">1</span>),<span class="number">1</span>,r)-I[:,w<span class="number">-2</span>*r<span class="number">-1</span>:w-r<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> imDst</span><br></pre></td></tr></table></figure><h1 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h1><p>本节使用正常的卷积局部求和操作与boxfilter局部求和进行对比分析，看看boxfilter性能到底如何。这里使用的卷积操作与这篇文章中的代码一致</p><p>利用卷积操作来进行局部求和，只需要将卷积核定义为如下形式即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel = np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br></pre></td></tr></table></figure><p>这样就定义了一个3x3的局部求和卷积核，验证一下卷积局部求和与boxfilter的输出结果是否一致</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">imSrc = np.ones((<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">kernel = np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">im_new = image_conv2d(imSrc, kernel)</span><br><span class="line">print(im_new)</span><br></pre></td></tr></table></figure><p>输出结果为</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[4. 6. 6. 6. 6. 6. 6. 4.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [6. 9. 9. 9. 9. 9. 9. 6.]</span><br><span class="line"> [4. 6. 6. 6. 6. 6. 6. 4.]]</span><br></pre></td></tr></table></figure><p>可以看出与boxfilter输出结果相同。接下来以3x3的窗口大小，分别以不同大小的单位矩阵来模拟不同分辨率的图像，对比两种运算随着分辨率的提升运算效率的变化情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># resolution define</span></span><br><span class="line">resList = []</span><br><span class="line">resList.append((<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">resList.append((<span class="number">64</span>,<span class="number">64</span>))</span><br><span class="line">resList.append((<span class="number">128</span>,<span class="number">128</span>))</span><br><span class="line">resList.append((<span class="number">256</span>,<span class="number">256</span>))</span><br><span class="line">resList.append((<span class="number">512</span>,<span class="number">512</span>))</span><br><span class="line">resList.append((<span class="number">640</span>,<span class="number">480</span>))</span><br><span class="line">resList.append((<span class="number">800</span>,<span class="number">600</span>))</span><br><span class="line">resList.append((<span class="number">1024</span>,<span class="number">768</span>))</span><br><span class="line">resList.append((<span class="number">1280</span>,<span class="number">960</span>))</span><br><span class="line">resList.append((<span class="number">1600</span>,<span class="number">1200</span>))</span><br><span class="line">resList.append((<span class="number">2048</span>,<span class="number">1536</span>))</span><br><span class="line">resList.append((<span class="number">2272</span>,<span class="number">1704</span>))</span><br><span class="line">resList.append((<span class="number">2560</span>,<span class="number">1920</span>))</span><br><span class="line">resList.append((<span class="number">3000</span>,<span class="number">2000</span>))</span><br><span class="line">resList.append((<span class="number">3264</span>,<span class="number">2488</span>))</span><br><span class="line">resList.append((<span class="number">4080</span>,<span class="number">2720</span>))</span><br><span class="line">resList.append((<span class="number">4536</span>,<span class="number">3024</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># convolution calculate</span></span><br><span class="line">conv_stats = []</span><br><span class="line"><span class="keyword">for</span> res <span class="keyword">in</span> resList:</span><br><span class="line">    imSrc = np.ones(res)</span><br><span class="line">    kernel = np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">    start = time.time()</span><br><span class="line">    im_new = image_conv2d(imSrc, kernel)</span><br><span class="line">    runtimes = time.time()-start</span><br><span class="line">    conv_stats.append(runtimes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># boxfilter calculate</span></span><br><span class="line">bxf_stats = []</span><br><span class="line"><span class="keyword">for</span> res <span class="keyword">in</span> resList:</span><br><span class="line">    imSrc = np.ones(res)</span><br><span class="line">    start = time.time()</span><br><span class="line">    im_new = boxfilter(imSrc, <span class="number">1</span>)</span><br><span class="line">    runtimes = time.time() - start</span><br><span class="line">    bxf_stats.append(runtimes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">x = [<span class="string">'&#123;&#125;x&#123;&#125;'</span>.format(res[<span class="number">0</span>], res[<span class="number">1</span>]) <span class="keyword">for</span> res <span class="keyword">in</span> resList]</span><br><span class="line">plt.plot(x, conv_stats, label=<span class="string">'convolution'</span>)</span><br><span class="line">plt.plot(x, bxf_stats, label=<span class="string">'boxfilter'</span>)</span><br><span class="line">plt.title(<span class="string">'Comparison of convolution and boxfilter'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'radius'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'runtime(sec)'</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">0</span>, <span class="number">20</span>, step=<span class="number">2</span>))</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>测试结果如下</p><div class="table-container"><table><thead><tr><th>Resolution</th><th>Convolution Runtimes(sec)</th><th>Boxfilter Runtimes(sec)</th></tr></thead><tbody><tr><td>32x32</td><td>0.015528</td><td>0.008734</td></tr><tr><td>64x64</td><td>0.023325</td><td>0.000000</td></tr><tr><td>128x128</td><td>0.088296</td><td>0.000972</td></tr><tr><td>256x256</td><td>0.351377</td><td>0.000971</td></tr><tr><td>512x512</td><td>1.396757</td><td>0.006795</td></tr><tr><td>640x480</td><td>1.637542</td><td>0.006794</td></tr><tr><td>800x600</td><td>2.556762</td><td>0.010676</td></tr><tr><td>1024x768</td><td>4.169978</td><td>0.019385</td></tr><tr><td>1280x960</td><td>6.543228</td><td>0.032032</td></tr><tr><td>1600x1200</td><td>10.234725</td><td>0.049505</td></tr><tr><td>2048x1536</td><td>16.729388</td><td>0.109683</td></tr><tr><td>2272x1704</td><td>20.630525</td><td>0.102891</td></tr><tr><td>2560x1920</td><td>26.146850</td><td>0.133951</td></tr><tr><td>3000x2000</td><td>31.713583</td><td>0.163045</td></tr><tr><td>3264x2488</td><td>43.213059</td><td>0.231047</td></tr><tr><td>4080x2720</td><td>59.047499</td><td>0.323232</td></tr><tr><td>4536x3024</td><td>72.816411</td><td>0.392182</td></tr></tbody></table></div><p>将测试结果绘制曲线如下</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/11.png"><p>可以看出，在相同局部大小3x3情况下，boxfilter的性能提升是巨大的，随着分辨率的增大，普通的卷积运算耗时呈类似指数增长，而boxfilter的耗时虽然也有所增加，但是其增长程度远远小于分辨率的增长程度</p><p>3x3大小的局部窗口下，boxfilter的运算效率确实很高，那么随着半径的增大，boxfilter的效果如何呢？下面对不同分辨率下不同半径的窗口大小对boxfilter进行了对比测试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">radList = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>,<span class="number">25</span>,<span class="number">30</span>,<span class="number">35</span>,<span class="number">40</span>,<span class="number">45</span>,<span class="number">50</span>]</span><br><span class="line">bxf_stats = []</span><br><span class="line"><span class="keyword">for</span> res <span class="keyword">in</span> resList:</span><br><span class="line">    imSrc = np.ones(res)</span><br><span class="line">    stat = &#123;<span class="string">'res'</span>:res, <span class="string">'times'</span>:[]&#125;</span><br><span class="line">    <span class="keyword">for</span> rad <span class="keyword">in</span> radList:</span><br><span class="line">        <span class="keyword">if</span> (rad*<span class="number">2</span>+<span class="number">1</span>)&lt;res[<span class="number">0</span>] <span class="keyword">and</span> (rad*<span class="number">2</span>+<span class="number">1</span>)&lt;res[<span class="number">1</span>]:</span><br><span class="line">            start = time.time()</span><br><span class="line">            im_new = boxfilter(imSrc, rad)</span><br><span class="line">            runtimes = time.time() - start</span><br><span class="line">            stat[<span class="string">'times'</span>].append((runtimes, rad))</span><br><span class="line">    bxf_stats.append(stat)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(bxf_stats)):</span><br><span class="line">    x = [t[<span class="number">1</span>] <span class="keyword">for</span> t <span class="keyword">in</span> bxf_stats[i][<span class="string">'times'</span>]]</span><br><span class="line">    y = [t[<span class="number">0</span>] <span class="keyword">for</span> t <span class="keyword">in</span> bxf_stats[i][<span class="string">'times'</span>]]</span><br><span class="line">    plt.plot(x,y, label=<span class="string">'&#123;&#125;'</span>.format(bxf_stats[i][<span class="string">'res'</span>]))</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">'Compare boxfilters with different radius sizes'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'radius'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'runtime(sec)'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>测试结果如下</p><img src="/2022/05/25/DIP-boxfilter快速窗口求和/12.png"><p>Amazing!!!</p><p>图中每条曲线代表一种分辨率下随着半径增大的运行时间变化情况，可以看出，固定分辨率的情况下，boxfilter的运算时间与半径大小几乎完全无关，只有分辨率增大，其运算时间才稍有增加。从boxfilter的计算原理可以理解，由于其计算过程只涉及到两次矩阵行方向与纵方向的累积求和运算，以及行方向、列方向的减法运算，因此当分辨率增大时，累积求和与减法运算的运算量会有所增加，但是由于其运算过程与半径大小的关系仅在考虑边界处的处理时，而且也是单次计算，因此半径大小带来的运算量增加与分辨率增加带来的运算量增加是非常小的</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在很多图像处理任务中，需要对局部图像数据进行窗口运算，许多运算都需要获得局部区域像素的均值和方差，这些计算都离不开求和运算。我在研究引导滤波时，发现何凯明在其提供的引导滤波matlab参考代码中，使用了boxfilter的快速计算方法，能够以$O(1)$的时间复杂度对矩阵进
      
    
    </summary>
    
      <category term="CV" scheme="http://yoursite.com/categories/CV/"/>
    
      <category term="DIP" scheme="http://yoursite.com/categories/CV/DIP/"/>
    
    
  </entry>
  
  <entry>
    <title>VitisAI-03-Vivado Flow</title>
    <link href="http://yoursite.com/2022/05/24/VitisAI-03-Vivado-Flow/"/>
    <id>http://yoursite.com/2022/05/24/VitisAI-03-Vivado-Flow/</id>
    <published>2022-05-24T13:41:09.000Z</published>
    <updated>2023-02-02T11:44:28.535Z</updated>
    
    <content type="html"><![CDATA[<p>从本文开始，将正式介绍VitisAI的工作流程。第一个流程就是Vivado Flow，在Vivado开发环境中创建一个硬件平台，最终的输出是xxx.xsa硬件描述文件，为后续的PetaLinux和Vitis提供基础。Vivado中的大部分的内容都是在Block Design中完成的，核心目标是创建一个Zynq UltraScale MPSoC的运行硬件环境，以及为DPU的正常运行提供硬件支持。这里需要注意，较老版本的VitisAI教程中，需要在Vivado中导入DPU的IP核，这种做法已经成为历史，本文介绍的流程中，在Vivado中是不需要导入DPU IP核的，只是对DPU运行环境进行支持，例如中断、时钟等</p><h1 id="创建Vivado工程"><a href="#创建Vivado工程" class="headerlink" title="创建Vivado工程"></a>创建Vivado工程</h1><p>打开vivado</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source /opt/pkg/xilinx/Vivado/2021.1/settings64.sh</span><br><span class="line">vivado</span><br></pre></td></tr></table></figure><p>vivado打开后，点击Create Project-&gt;Next</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/01.png"><p>输入项目名称，这里我输入的是”dpu_hardware”，点击Next</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/02.png"><p>在Project Type页面中选中RTL Project，并选中Project is an extensible Vitis platform，点击Next</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/03.png"><p>在Default Part页面选择Family为Zynq UltraScale+ MPSoCs，Package为sfvc784，Temperature为E，Speed为-1，并在下方的表格中选中xczu2cg-sfvc784-1-e，点击Next，再点击Finish。这里需要注意，读者的芯片类型选择需要和自己的板子匹配</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/04.png"><h1 id="Block-Design-IP核添加"><a href="#Block-Design-IP核添加" class="headerlink" title="Block Design IP核添加"></a>Block Design IP核添加</h1><p>在左侧PROJECT MANAGER→IP INTEGRATOR点击Create Block Design，在弹出框中直接点击Next创建一个Block Design</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/05.png"><p>在Diagram界面中点击加号，在搜索框中输入zynq，选择Zynq UltraScale+MPSoC，将其添加到Block Design中</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/06.png"><p>添加后如下图所示</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/07.png"><h2 id="添加Clock"><a href="#添加Clock" class="headerlink" title="添加Clock"></a>添加Clock</h2><p>添加Clocking Wizard IP核</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/08.png"><p>添加后如下图所示</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/09.png"><p>双击Clocking Wizard进入配置页面，在Output Clocks中选中clk_out1、clk_out2、clk_out3，并将Output Freq分别设置为100、200、400</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/10.png"><p>在Reset Type中选择Active Low，并点击OK</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/11.png"><h2 id="添加Processor-System-Reset"><a href="#添加Processor-System-Reset" class="headerlink" title="添加Processor System Reset"></a>添加Processor System Reset</h2><p>添加Processor System Reset</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/12.png"><p>因为有3路时钟，因此要创建3个对应的Reset模块，可点击添加的Reset，Ctrl+C/Ctrl+V复制2个出来</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/13.png"><p>将Clocking Wizard的3路输出分别与Reset0/1/2的slowest_sync_clk管脚相连，将Clocking Wizard的locked与3个Reset的dcm_locked都相连</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/14.png"><p>点击Run Connection Automation，在弹出框中将clk_in1选择为zynq的clk0，将3个reset都选择为zynq的resetn0，点击OK</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/15.png"><p>完成后Block Design如下图</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/16.png"><p>点击Platform Setup，选中Clock，将3个Clock都设置为Enable，ID号分别设置为0、1、2，并将clk_out2设置为default</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/17.png"><h2 id="添加AXI-Interrupt-Controller"><a href="#添加AXI-Interrupt-Controller" class="headerlink" title="添加AXI Interrupt Controller"></a>添加AXI Interrupt Controller</h2><p>添加AXI Interrupt Controller IP核</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/18.png"><p>双击AXI Interrupt Controller进入配置页面，将Interrupt Output Connection选择为Single，点击OK</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/19.png"><p>双击ZYNQ进入配置页面，在PS-PL Configuration→PS-PL Interfaces→Master Interface中，确保两个FPD未选中，LPD选中</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/20.png"><p>在PS-PL Configuration→General→Interrupts→PL to PS中，将IRQ0[0-7]选择为1，点击OK</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/21.png"><p>点击自动连接，默认都选择auto，点击OK</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/22.png"><p>整个Block Design如图</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/23.png"><p>将axi_intc_0的irq连接到ZYNQ的pl_ps_irq0上，再点击图标刷新画布</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/24.png"><p>在Platform Setup中将中断使能</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/25.png"><p>选择AXI Port，按照下图对端口进行配置</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/26.png"><img src="/2022/05/24/VitisAI-03-Vivado-Flow/27.png"><h1 id="Zynq-SoC配置"><a href="#Zynq-SoC配置" class="headerlink" title="Zynq SoC配置"></a>Zynq SoC配置</h1><p>双击Zynq UltraScale MPSoC，打开其配置界面</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/31.png"><h2 id="I-O配置"><a href="#I-O配置" class="headerlink" title="I/O配置"></a>I/O配置</h2><p>在I/O Configuration中，配置Bank0~Bank2电压为LVCMOS18，Bank3电压为LVCMOS33</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/32.png"><p>在下方展开Low Speed→Memory Interfaces→QSPI，勾选QSPI，设置模式为Single，Data Mode选择x4，勾选Feedback Clk</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/33.png"><p>展开SD，并勾选SD0，配置Slol Type为eMMC，Data Transfer Mode为8Bit，勾选Reset，选择MIO23</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/34.png"><p>勾选SD1，Slot Type选择SD 2.0，Data Transfer Mode选择4Bit，勾选CD，用于检测SD卡的插入</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/35.png"><p>勾选I2C 1，用于EEPROM</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/36.png"><p>勾选UART1</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/37.png"><p>勾选TTC 0~TTC3</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/38.png"><p>配置PS端以太网，勾选GEM3，勾选MDIO3</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/39.png"><p>勾选USB0，勾选USB3.0，选择GT Lane1，勾选USB Reset→USB 0</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/40.png"><p>勾选PCIe</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/41.png"><p>点击左侧Switch To Advanced Mode，选择PCIe Configuration</p><ul><li>Basic Settings→Device Port Type：RootPort</li><li>Devices IDs→Initial ID Values→Subsystem ID：0x7</li><li>Devices IDs→Class Code→Base Class：0x06</li><li>Devices IDs→Class Code→Sub Class：0x04</li></ul><img src="/2022/05/24/VitisAI-03-Vivado-Flow/42.png"><p>回到I/O Configuration，勾选Display Port，Lane Selection选择Dual Higher</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/43.png"><h2 id="时钟配置"><a href="#时钟配置" class="headerlink" title="时钟配置"></a>时钟配置</h2><p>在Clock Configuration界面，Input Clocks配置参考时钟，PCIe选择Ref Clk0，100MHz，Display Port选择Ref Clk2，27MHz，USB0选择Ref Clk1，26MHz</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/44.png"><p>在Output Clocks窗口，如果不是IOPLL，改为IOPLL，保持一致</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/45.png"><p>PL的时钟保持默认</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/46.png"><p>Full Power部分，其他保持默认，将DP_VIDEO改为VPLL，DP_AUDIO和DP_STC改为RPLL</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/47.png"><p>最下面的Interconnect修改如下</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/48.png"><h2 id="DDR配置"><a href="#DDR配置" class="headerlink" title="DDR配置"></a>DDR配置</h2><p>在DDR Configuration窗口中，Load DDR Presets选择“DDR4_MICRON_MT40A256M16GE_083E”</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/49.png"><h1 id="生成bit"><a href="#生成bit" class="headerlink" title="生成bit"></a>生成bit</h1><p>BLOCK DESIGN→Sources→design_1，右键选择Create HDL Wrapper生成top文件</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/28.png"><img src="/2022/05/24/VitisAI-03-Vivado-Flow/29.png"><p>点击Generate Bitstream图标生成bit流，等待生成完成后，点击File→Export→Export Platform，选Next、选Hardware。选Pre-synthesis+include bitstream</p><img src="/2022/05/24/VitisAI-03-Vivado-Flow/30.png"><p>设置平台名称等信息，点击Next、Finsih，可看到在dpu_hardware路径下生成了design_1_wrapper.xsa文件</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从本文开始，将正式介绍VitisAI的工作流程。第一个流程就是Vivado Flow，在Vivado开发环境中创建一个硬件平台，最终的输出是xxx.xsa硬件描述文件，为后续的PetaLinux和Vitis提供基础。Vivado中的大部分的内容都是在Block Design
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="VitisAI" scheme="http://yoursite.com/categories/AI/VitisAI/"/>
    
    
      <category term="Xilinx" scheme="http://yoursite.com/tags/Xilinx/"/>
    
      <category term="Vitis AI" scheme="http://yoursite.com/tags/Vitis-AI/"/>
    
      <category term="DPU" scheme="http://yoursite.com/tags/DPU/"/>
    
      <category term="DeepLearning" scheme="http://yoursite.com/tags/DeepLearning/"/>
    
      <category term="Vivado" scheme="http://yoursite.com/tags/Vivado/"/>
    
  </entry>
  
  <entry>
    <title>Secondary Program Loader(SPL)</title>
    <link href="http://yoursite.com/2022/05/23/Secondary-Program-Loader-SPL/"/>
    <id>http://yoursite.com/2022/05/23/Secondary-Program-Loader-SPL/</id>
    <published>2022-05-23T07:01:21.000Z</published>
    <updated>2023-02-09T08:48:36.194Z</updated>
    
    <content type="html"><![CDATA[<p>SPL在uboot的启动过程中是一个非常重要的概念，在uboot的启动相关代码中，可以看到很多与SPL相关判断和处理，了解SPL对于理解CPU以及整个系统的启动过程是很有帮助的。本文主要对以下内容进行介绍</p><ul><li><p>什么是SPL，为什么需要SPL？</p></li><li><p>SPL在uboot编译层面是如何设计的？</p></li><li><p>启动过程中SPL主要做了什么？</p></li></ul><h1 id="为什么需要SPL？"><a href="#为什么需要SPL？" class="headerlink" title="为什么需要SPL？"></a>为什么需要SPL？</h1><p>SPL全程是Secondary Program Loader，叫做第二阶段引导程序，这个”Secondary”第二阶段是怎么来的呢？uboot目前将整个启动过程设计为4个阶段</p><ul><li><p>ROM Boot</p></li><li><p>SPL</p></li><li><p>uboot</p></li><li><p>kernel</p></li></ul><p>第一阶段ROM Boot是固化在SoC内部的一小段启动程序，一般由芯片厂商在出厂时固化好，一般不需要对这段代码关心，需要关心的是芯片的启动模式有哪些，如何设置启动模式，启动地址是多少。ROM Boot会引导SPL的启动，按照预先设置的启动模式，看是从SD卡、emmc还是Flash加载SPL到片上RAM中运行；SPL引导uboot的加载，将uboot拷贝到DDR中，重定向到uboot运行；uboot又加载kernel，重定向到kernel运行</p><p>以上这整个过程中，为什么不直接用ROM Boot引导uboot到RAM中，然后让uboot将kernel拷贝到DDR中再切换到kernel运行，而要多出来一个SPL多此一举呢？</p><p>关键点在于一方面uboot慢慢发展，代码量及功能越来越多，另一方面SoC厂商由于程本、面积等方面的考虑，一般不会将片内RAM设计的太大，一般不会超过100KB，而uboot编译下来一般都会超过200KB，因此在RAM空间上就产生了矛盾。uboot为了规避这种问题，引入了SPL的概念，即将原本的uboot功能一分为二，输出2个独立的程序，一个是SPL，另一个是真正的uboot，SPL程序只包含CPU底层相关的关键启动代码，体积较小，能够完全运行在片上RAM中，SPL负责对DDR进行初始化，并将uboot拷贝到DDR中，切换到uboot运行。下图显示了不同启动阶段及引导程序的运行介质</p><img src="/2022/05/23/Secondary-Program-Loader-SPL/01.png"><p>CPU上电后，首先是从片内ROM加载ROM Boot程序，进行片上系统初始化，然后将启动介质中的SPL加载到片内RAM运行，SPL对DDR进行初始化，然后将uboot拷贝到DDR中，uboot在DDR中运行，拷贝kernel到DDR中</p><h1 id="从编译的层面理解SPL"><a href="#从编译的层面理解SPL" class="headerlink" title="从编译的层面理解SPL"></a>从编译的层面理解SPL</h1><p>SPL与真正的uboot在源代码上是同一套代码，通过编译选项<code>CONFIG_SPL_BUILD</code>进行区分，在uboot代码的很多地方，通过以下形式区分了SPL处理还是uboot处理</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SPL_BUILD</span></span><br><span class="line">    <span class="comment">/* spl process */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="comment">/* uboot process */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>在uboot的Makefile设计里，将最终uboot生成的二进制输出文件分离为了u-boot-spl.bin和u-boot.bin，u-boot-spl.bin就是SPL程序的二进制文件，而u-boot.bin是真正uboot的二进制文件。从u-boot-spl.lds和u-boot.lds链接文件可以看出，SPL和真正uboot的启动都是从_start符号开始，<code>_start</code>-&gt;<code>lowlevel_init</code>-&gt;<code>_main</code>-&gt;<code>board_init_f</code>的代码调用流程，SPL和uboot都会走一遍，只是其中执行的内容不同</p><h1 id="SPL主要内容"><a href="#SPL主要内容" class="headerlink" title="SPL主要内容"></a>SPL主要内容</h1><p>这里以u-boot-2012.10版本源码为参考，主要分析ARMv7架构的SPL处理。下图是SPL整个运行过程调用时序</p><img src="/2022/05/23/Secondary-Program-Loader-SPL/02.png"><h2 id="start-S"><a href="#start-S" class="headerlink" title="start.S"></a>start.S</h2><p>arch/arm/cpu/armv7/start.S，入口符号为<code>_start</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.globl _start</span><br><span class="line">_start: breset</span><br><span class="line">    ldrpc, _undefined_instruction</span><br><span class="line">ldrpc, _software_interrupt</span><br><span class="line">ldrpc, _prefetch_abort</span><br><span class="line">ldrpc, _data_abort</span><br><span class="line">ldrpc, _not_used</span><br><span class="line">ldrpc, _irq</span><br><span class="line">ldrpc, _fiq</span><br></pre></td></tr></table></figure><p><code>_start</code>地址为0x00000000，设置后续的几个地址为SPL的异常向量，跳转到reset</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">reset:</span><br><span class="line">blsave_boot_params</span><br><span class="line">/*</span><br><span class="line"> * set the cpu to SVC32 mode</span><br><span class="line"> */</span><br><span class="line">mrsr0, cpsr</span><br><span class="line">bicr0, r0, #0x1f</span><br><span class="line">orrr0, r0, #0xd3</span><br><span class="line">msr cpsr,r0</span><br></pre></td></tr></table></figure><p>对armv7的cpsr寄存器进行设置，设置CPU的模式为超级模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#if !(defined(CONFIG_OMAP44XX) &amp;&amp; defined(CONFIG_SPL_BUILD))</span><br><span class="line">/* Set V=0 in CP15 SCTRL register - for VBAR to point to vector */</span><br><span class="line">mrcp15, 0, r0, c1, c0, 0@ Read CP15 SCTRL Register</span><br><span class="line">bicr0, #CR_V@ V = 0</span><br><span class="line">mcrp15, 0, r0, c1, c0, 0@ Write CP15 SCTRL Register</span><br><span class="line"></span><br><span class="line">/* Set vector address in CP15 VBAR register */</span><br><span class="line">ldrr0, =_start</span><br><span class="line">mcrp15, 0, r0, c12, c0, 0@Set VBAR</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure><p>通过armv7的CP15协处理器将异常向量设置到VBAR，关于ARMv7协处理器CP15以及VBAR的详细内容后续会出其他相关文章专门介绍。这里进行了<code>CONFIG_SPL_BUILD</code>宏定义判断，说明设置这里的异常向量是SPL的操作，也就是说<code>_start</code>后面的几个异常处理是针对SPL程序而言的，uboot应该会设置其他的异常向量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#ifndef CONFIG_SKIP_LOWLEVEL_INIT</span><br><span class="line">blcpu_init_cp15</span><br><span class="line">blcpu_init_crit</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure><p>这里是调用了<code>cpu_init_cp15</code>和<code>cpu_init_crit</code>两个函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">ENTRY(cpu_init_cp15)</span><br><span class="line">/*</span><br><span class="line"> * Invalidate L1 I/D</span><br><span class="line"> */</span><br><span class="line">movr0, #0@ set up for MCR</span><br><span class="line">mcrp15, 0, r0, c8, c7, 0@ invalidate TLBs</span><br><span class="line">mcrp15, 0, r0, c7, c5, 0@ invalidate icache</span><br><span class="line">mcrp15, 0, r0, c7, c5, 6@ invalidate BP array</span><br><span class="line">mcr     p15, 0, r0, c7, c10, 4@ DSB</span><br><span class="line">mcr     p15, 0, r0, c7, c5, 4@ ISB</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"> * disable MMU stuff and caches</span><br><span class="line"> */</span><br><span class="line">mrcp15, 0, r0, c1, c0, 0</span><br><span class="line">bicr0, r0, #0x00002000@ clear bits 13 (--V-)</span><br><span class="line">bicr0, r0, #0x00000007@ clear bits 2:0 (-CAM)</span><br><span class="line">orrr0, r0, #0x00000002@ set bit 1 (--A-) Align</span><br><span class="line">orrr0, r0, #0x00000800@ set bit 11 (Z---) BTB</span><br><span class="line">#ifdef CONFIG_SYS_ICACHE_OFF</span><br><span class="line">bicr0, r0, #0x00001000@ clear bit 12 (I) I-cache</span><br><span class="line">#else</span><br><span class="line">orrr0, r0, #0x00001000@ set bit 12 (I) I-cache</span><br><span class="line">#endif</span><br><span class="line">mcrp15, 0, r0, c1, c0, 0</span><br><span class="line">movpc, lr@ back to my caller</span><br><span class="line">ENDPROC(cpu_init_cp15)</span><br></pre></td></tr></table></figure><p><code>cpu_init_cp15</code>的处理是通过设置CP15寄存器来禁用TLB、指令和数据cache，禁用MMU及cache</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ENTRY(cpu_init_crit)</span><br><span class="line">/*</span><br><span class="line"> * Jump to board specific initialization...</span><br><span class="line"> * The Mask ROM will have already initialized</span><br><span class="line"> * basic memory. Go here to bump up clock rate and handle</span><br><span class="line"> * wake up conditions.</span><br><span class="line"> */</span><br><span class="line">blowlevel_init@ go setup pll,mux,memory</span><br><span class="line">ENDPROC(cpu_init_crit)</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure><p><code>cpu_init_crit</code>的处理是直接跳转到<code>lowlevel_init</code>，这定义在lowlevel_init.S中</p><h2 id="lowlevel-init-S"><a href="#lowlevel-init-S" class="headerlink" title="lowlevel_init.S"></a>lowlevel_init.S</h2><p>arch/arm/cpu/armv7/lowlevel_init.S中只定义了<code>lowlevel_init</code>一个函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ENTRY(lowlevel_init)</span><br><span class="line">/*</span><br><span class="line"> * Setup a temporary stack</span><br><span class="line"> */</span><br><span class="line">ldrsp, =CONFIG_SYS_INIT_SP_ADDR</span><br><span class="line">bicsp, sp, #7 /* 8-byte alignment for ABI compliance */</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"> * Save the old lr(passed in ip) and the current lr to stack</span><br><span class="line"> */</span><br><span class="line">push&#123;ip, lr&#125;</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"> * go setup pll, mux, memory</span><br><span class="line"> */</span><br><span class="line">bls_init</span><br><span class="line">pop&#123;ip, pc&#125;</span><br><span class="line">ENDPROC(lowlevel_init)</span><br></pre></td></tr></table></figure><p>这里有一个保存栈的操作，先将ip入栈，然后调用了<code>s_init()</code>C函数，定义在<code>xxx/board.c</code>中，主要是初始化系统时钟等，然后返回到start.S中这里</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/* Set stackpointer in internal RAM to call board_init_f */</span><br><span class="line">call_board_init_f:</span><br><span class="line">ldrsp, =(CONFIG_SYS_INIT_SP_ADDR)</span><br><span class="line">bicsp, sp, #7 /* 8-byte alignment for ABI compliance */</span><br><span class="line">ldrr0,=0x00000000</span><br><span class="line">blboard_init_f</span><br></pre></td></tr></table></figure><p>调用lib/board.c中的<code>board_init_f</code>函数</p><h2 id="lib-board-c"><a href="#lib-board-c" class="headerlink" title="lib/board.c"></a>lib/board.c</h2><p>arch/arm/lib/board.c中定义了<code>board_init_f</code></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">board_init_f</span><span class="params">(ulong bootflag)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">bd_t</span> *bd;</span><br><span class="line"><span class="keyword">init_fnc_t</span> **init_fnc_ptr;</span><br><span class="line"><span class="keyword">gd_t</span> *id;</span><br><span class="line">ulong addr, addr_sp;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_PRAM</span></span><br><span class="line">ulong reg;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">bootstage_mark_name(BOOTSTAGE_ID_START_UBOOT_F, <span class="string">"board_init_f"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Pointer is writable since we allocated a register for it */</span></span><br><span class="line">gd = (<span class="keyword">gd_t</span> *) ((CONFIG_SYS_INIT_SP_ADDR) &amp; ~<span class="number">0x07</span>);</span><br><span class="line"><span class="comment">/* compiler optimization barrier needed for GCC &gt;= 3.4 */</span></span><br><span class="line">__asm__ __volatile__(<span class="string">""</span>: : :<span class="string">"memory"</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">memset</span>((<span class="keyword">void</span> *)gd, <span class="number">0</span>, <span class="keyword">sizeof</span>(<span class="keyword">gd_t</span>));</span><br><span class="line"></span><br><span class="line">gd-&gt;mon_len = _bss_end_ofs;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_OF_EMBED</span></span><br><span class="line"><span class="comment">/* Get a pointer to the FDT */</span></span><br><span class="line">gd-&gt;fdt_blob = _binary_dt_dtb_start;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined CONFIG_OF_SEPARATE</span></span><br><span class="line"><span class="comment">/* FDT is at end of image */</span></span><br><span class="line">gd-&gt;fdt_blob = (<span class="keyword">void</span> *)(_end_ofs + _TEXT_BASE);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="comment">/* Allow the early environment to override the fdt address */</span></span><br><span class="line">gd-&gt;fdt_blob = (<span class="keyword">void</span> *)getenv_ulong(<span class="string">"fdtcontroladdr"</span>, <span class="number">16</span>,</span><br><span class="line">(<span class="keyword">uintptr_t</span>)gd-&gt;fdt_blob);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (init_fnc_ptr = init_sequence; *init_fnc_ptr; ++init_fnc_ptr) &#123;</span><br><span class="line"><span class="keyword">if</span> ((*init_fnc_ptr)() != <span class="number">0</span>) &#123;</span><br><span class="line">hang ();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_OF_CONTROL</span></span><br><span class="line"><span class="comment">/* For now, put this check after the console is ready */</span></span><br><span class="line"><span class="keyword">if</span> (fdtdec_prepare_fdt()) &#123;</span><br><span class="line">panic(<span class="string">"** CONFIG_OF_CONTROL defined but no FDT - please see "</span></span><br><span class="line"><span class="string">"doc/README.fdt-control"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">debug(<span class="string">"monitor len: %08lX\n"</span>, gd-&gt;mon_len);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Ram is setup, size stored in gd !!</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">debug(<span class="string">"ramsize: %08lX\n"</span>, gd-&gt;ram_size);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CONFIG_SYS_MEM_TOP_HIDE)</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Subtract specified amount of memory to hide so that it won't</span></span><br><span class="line"><span class="comment"> * get "touched" at all by U-Boot. By fixing up gd-&gt;ram_size</span></span><br><span class="line"><span class="comment"> * the Linux kernel should now get passed the now "corrected"</span></span><br><span class="line"><span class="comment"> * memory size and won't touch it either. This should work</span></span><br><span class="line"><span class="comment"> * for arch/ppc and arch/powerpc. Only Linux board ports in</span></span><br><span class="line"><span class="comment"> * arch/powerpc with bootwrapper support, that recalculate the</span></span><br><span class="line"><span class="comment"> * memory size from the SDRAM controller setup will have to</span></span><br><span class="line"><span class="comment"> * get fixed.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">gd-&gt;ram_size -= CONFIG_SYS_MEM_TOP_HIDE;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">addr = CONFIG_SYS_SDRAM_BASE + gd-&gt;ram_size;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_LOGBUFFER</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> CONFIG_ALT_LB_ADDR</span></span><br><span class="line"><span class="comment">/* reserve kernel log buffer */</span></span><br><span class="line">addr -= (LOGBUFF_RESERVE);</span><br><span class="line">debug(<span class="string">"Reserving %dk for kernel logbuffer at %08lx\n"</span>, LOGBUFF_LEN,</span><br><span class="line">addr);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_PRAM</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * reserve protected RAM</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">reg = getenv_ulong(<span class="string">"pram"</span>, <span class="number">10</span>, CONFIG_PRAM);</span><br><span class="line">addr -= (reg &lt;&lt; <span class="number">10</span>);<span class="comment">/* size is in kB */</span></span><br><span class="line">debug(<span class="string">"Reserving %ldk for protected RAM at %08lx\n"</span>, reg, addr);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* CONFIG_PRAM */</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> !(defined(CONFIG_SYS_ICACHE_OFF) &amp;&amp; defined(CONFIG_SYS_DCACHE_OFF))</span></span><br><span class="line"><span class="comment">/* reserve TLB table */</span></span><br><span class="line">addr -= (<span class="number">4096</span> * <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* round down to next 64 kB limit */</span></span><br><span class="line">addr &amp;= ~(<span class="number">0x10000</span> - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">gd-&gt;tlb_addr = addr;</span><br><span class="line">debug(<span class="string">"TLB table at: %08lx\n"</span>, addr);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* round down to next 4 kB limit */</span></span><br><span class="line">addr &amp;= ~(<span class="number">4096</span> - <span class="number">1</span>);</span><br><span class="line">debug(<span class="string">"Top of RAM usable for U-Boot at: %08lx\n"</span>, addr);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_LCD</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_FB_ADDR</span></span><br><span class="line">gd-&gt;fb_base = CONFIG_FB_ADDR;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="comment">/* reserve memory for LCD display (always full pages) */</span></span><br><span class="line">addr = lcd_setmem(addr);</span><br><span class="line">gd-&gt;fb_base = addr;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* CONFIG_FB_ADDR */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* CONFIG_LCD */</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * reserve memory for U-Boot code, data &amp; bss</span></span><br><span class="line"><span class="comment"> * round down to next 4 kB limit</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">addr -= gd-&gt;mon_len;</span><br><span class="line">addr &amp;= ~(<span class="number">4096</span> - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">debug(<span class="string">"Reserving %ldk for U-Boot at: %08lx\n"</span>, gd-&gt;mon_len &gt;&gt; <span class="number">10</span>, addr);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> CONFIG_SPL_BUILD</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * reserve memory for malloc() arena</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">addr_sp = addr - TOTAL_MALLOC_LEN;</span><br><span class="line">debug(<span class="string">"Reserving %dk for malloc() at: %08lx\n"</span>,</span><br><span class="line">TOTAL_MALLOC_LEN &gt;&gt; <span class="number">10</span>, addr_sp);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * (permanently) allocate a Board Info struct</span></span><br><span class="line"><span class="comment"> * and a permanent copy of the "global" data</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">addr_sp -= <span class="keyword">sizeof</span> (<span class="keyword">bd_t</span>);</span><br><span class="line">bd = (<span class="keyword">bd_t</span> *) addr_sp;</span><br><span class="line">gd-&gt;bd = bd;</span><br><span class="line">debug(<span class="string">"Reserving %zu Bytes for Board Info at: %08lx\n"</span>,</span><br><span class="line"><span class="keyword">sizeof</span> (<span class="keyword">bd_t</span>), addr_sp);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_MACH_TYPE</span></span><br><span class="line">gd-&gt;bd-&gt;bi_arch_number = CONFIG_MACH_TYPE; <span class="comment">/* board id for Linux */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">addr_sp -= <span class="keyword">sizeof</span> (<span class="keyword">gd_t</span>);</span><br><span class="line">id = (<span class="keyword">gd_t</span> *) addr_sp;</span><br><span class="line">debug(<span class="string">"Reserving %zu Bytes for Global Data at: %08lx\n"</span>,</span><br><span class="line"><span class="keyword">sizeof</span> (<span class="keyword">gd_t</span>), addr_sp);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* setup stackpointer for exeptions */</span></span><br><span class="line">gd-&gt;irq_sp = addr_sp;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_USE_IRQ</span></span><br><span class="line">addr_sp -= (CONFIG_STACKSIZE_IRQ+CONFIG_STACKSIZE_FIQ);</span><br><span class="line">debug(<span class="string">"Reserving %zu Bytes for IRQ stack at: %08lx\n"</span>,</span><br><span class="line">CONFIG_STACKSIZE_IRQ+CONFIG_STACKSIZE_FIQ, addr_sp);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="comment">/* leave 3 words for abort-stack    */</span></span><br><span class="line">addr_sp -= <span class="number">12</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 8-byte alignment for ABI compliance */</span></span><br><span class="line">addr_sp &amp;= ~<span class="number">0x07</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">addr_sp += <span class="number">128</span>;<span class="comment">/* leave 32 words for abort-stack   */</span></span><br><span class="line">gd-&gt;irq_sp = addr_sp;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">debug(<span class="string">"New Stack Pointer is: %08lx\n"</span>, addr_sp);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_POST</span></span><br><span class="line">post_bootmode_init();</span><br><span class="line">post_run(<span class="literal">NULL</span>, POST_ROM | post_bootmode_get(<span class="number">0</span>));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">gd-&gt;bd-&gt;bi_baudrate = gd-&gt;baudrate;</span><br><span class="line"><span class="comment">/* Ram ist board specific, so move it to board code ... */</span></span><br><span class="line">dram_init_banksize();</span><br><span class="line">display_dram_config();<span class="comment">/* and display it */</span></span><br><span class="line"></span><br><span class="line">gd-&gt;relocaddr = addr;</span><br><span class="line">gd-&gt;start_addr_sp = addr_sp;</span><br><span class="line">gd-&gt;reloc_off = addr - _TEXT_BASE;</span><br><span class="line">debug(<span class="string">"relocation Offset is: %08lx\n"</span>, gd-&gt;reloc_off);</span><br><span class="line"><span class="built_in">memcpy</span>(id, (<span class="keyword">void</span> *)gd, <span class="keyword">sizeof</span>(<span class="keyword">gd_t</span>));</span><br><span class="line"></span><br><span class="line">relocate_code(addr_sp, id, addr);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* NOTREACHED - relocate_code() does not return */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>维护了一个global data结构，计算uboot的地址及大小，初始化DDR，将uboot拷贝到DDR中，然后再调用<code>relocate_code</code>将uboot拷贝到DDR中，并跳转到uboot</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SPL在uboot的启动过程中是一个非常重要的概念，在uboot的启动相关代码中，可以看到很多与SPL相关判断和处理，了解SPL对于理解CPU以及整个系统的启动过程是很有帮助的。本文主要对以下内容进行介绍&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;什么是SPL，为什么需要SPL？&lt;/
      
    
    </summary>
    
      <category term="CS" scheme="http://yoursite.com/categories/CS/"/>
    
      <category term="uboot" scheme="http://yoursite.com/categories/CS/uboot/"/>
    
    
      <category term="嵌入式" scheme="http://yoursite.com/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
      <category term="uboot" scheme="http://yoursite.com/tags/uboot/"/>
    
  </entry>
  
  <entry>
    <title>VS+CUDA开发环境搭建</title>
    <link href="http://yoursite.com/2022/05/19/VS-CUDA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2022/05/19/VS-CUDA开发环境搭建/</id>
    <published>2022-05-19T09:43:06.000Z</published>
    <updated>2023-02-02T11:42:24.249Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍在Windows环境下，如何搭建Visual Studio + CUDA的开发环境</p><p>首先需要安装好Visual Studio 2015/2017/2019</p><h1 id="CUDA版本确定"><a href="#CUDA版本确定" class="headerlink" title="CUDA版本确定"></a>CUDA版本确定</h1><p>在选择cuda安装时，cuda的版本需要和显卡型号对应算力进行匹配，例如GeForce GT 730算力为3.5。如何查看自己显卡的算力呢？安装了CUDA后可通过CUDA内置的deviceQuery工具输出显卡相关信息，”CUDA Capability Major/Minor version number”这一行的数字就是显卡算力的版本</p><img src="/2022/05/19/VS-CUDA开发环境搭建/01.png"><p>cudav8.0、cudav9.0到cudav10.0都可以兼容最高3.5算力，可以在以下链接中选择不同的cuda版本</p><p><a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a></p><p>阅读在线文档中的”xxx <a href="https://docs.nvidia.com/cuda/archive/9.0/maxwell-compatibility-guide/index.html" target="_blank" rel="noopener">Compatibility Guide</a>”文档，其中显示的编译选项中显示了算力能力</p><img src="/2022/05/19/VS-CUDA开发环境搭建/02.png"> <p>compute_20表示算力2.0，compute_35表示算力3.5</p><p>下载安装对应cuda后，在cmd中输入nvcc -V可查看版本</p><img src="/2022/05/19/VS-CUDA开发环境搭建/03.png"><h1 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world"></a>hello world</h1><p>打开vs，文件→新建→NVIDIA→CUDA 8.0，新建一个test工程</p><img src="/2022/05/19/VS-CUDA开发环境搭建/04.png"><p>创建项目后，工程会自动生成一个kernel.cu源码文件</p><p>点击项目→test属性</p><img src="/2022/05/19/VS-CUDA开发环境搭建/05.png"><p>选中VC++目录→包含目录，为其添加CUDA的头文件路径 “$(CUDA_PATH)\include”</p><img src="/2022/05/19/VS-CUDA开发环境搭建/06.png"><img src="/2022/05/19/VS-CUDA开发环境搭建/07.png"><p>选中库目录，为工程添加CUDA库目录 “$(CUDA_PATH)\lib\x64”</p><img src="/2022/05/19/VS-CUDA开发环境搭建/08.png"><img src="/2022/05/19/VS-CUDA开发环境搭建/09.png"><p>选择Debug模式为x64</p><img src="/2022/05/19/VS-CUDA开发环境搭建/10.png"><p>在main函数最后添加如下函数，暂停程序退出</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">getc(<span class="built_in">stdin</span>);</span><br></pre></td></tr></table></figure><p>点击本地Windows调试器，运行程序</p><img src="/2022/05/19/VS-CUDA开发环境搭建/11.png"><h2 id="Nsight可视化调试"><a href="#Nsight可视化调试" class="headerlink" title="Nsight可视化调试"></a>Nsight可视化调试</h2><p>手动运行Nsight Monitor，在电脑右下脚图标处，右键Nsight→options</p><img src="/2022/05/19/VS-CUDA开发环境搭建/12.png"><p>设置以下选项为True</p><img src="/2022/05/19/VS-CUDA开发环境搭建/13.png"><p>再次右击Nsight图标点击Exit</p><p>在vs中打开Nsight，也在option中选择以下内容为True</p><img src="/2022/05/19/VS-CUDA开发环境搭建/14.png"><p>点击vs中的Nsight→Start Performance Analysis</p><img src="/2022/05/19/VS-CUDA开发环境搭建/15.png"><p>出现如下界面</p><img src="/2022/05/19/VS-CUDA开发环境搭建/16.png"><p>选中Trace Settings→System下面的几个选项和CUDA</p><img src="/2022/05/19/VS-CUDA开发环境搭建/17.png"><p>点击下方中间状态灯的Launch</p><img src="/2022/05/19/VS-CUDA开发环境搭建/18.png"> <p>运行完毕后关闭程序，Nsight会自动显示Session Overview</p><img src="/2022/05/19/VS-CUDA开发环境搭建/19.png"> <p>显示了整个GPU运行的概要信息，左上角下拉框选择Timeline可显示时间线</p><img src="/2022/05/19/VS-CUDA开发环境搭建/20.png">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文介绍在Windows环境下，如何搭建Visual Studio + CUDA的开发环境&lt;/p&gt;
&lt;p&gt;首先需要安装好Visual Studio 2015/2017/2019&lt;/p&gt;
&lt;h1 id=&quot;CUDA版本确定&quot;&gt;&lt;a href=&quot;#CUDA版本确定&quot; class=
      
    
    </summary>
    
      <category term="CS" scheme="http://yoursite.com/categories/CS/"/>
    
      <category term="cuda" scheme="http://yoursite.com/categories/CS/cuda/"/>
    
    
      <category term="cuda" scheme="http://yoursite.com/tags/cuda/"/>
    
      <category term="gpu" scheme="http://yoursite.com/tags/gpu/"/>
    
  </entry>
  
  <entry>
    <title>HDR-曝光融合(Exposure Fusion)</title>
    <link href="http://yoursite.com/2022/05/19/HDR-%E6%9B%9D%E5%85%89%E8%9E%8D%E5%90%88-Exposure-Fusion/"/>
    <id>http://yoursite.com/2022/05/19/HDR-曝光融合-Exposure-Fusion/</id>
    <published>2022-05-19T02:24:50.000Z</published>
    <updated>2023-02-02T11:41:40.376Z</updated>
    
    <content type="html"><![CDATA[<p>Tom Mertens、Jan Kautz等人在”Exposure Fusion”这篇paper中提出了一种简单有效的曝光融合方法，通过将一组不同曝光的图像序列进行直接融合得到一副高质量图像，而不需要先将这些图像序列转化为HDR。传统的HDR做法采用多重曝光获得图像序列，需要将其转换为辐照度估计的radiance map，也就是HDR格式的高动态范围图像，然后再进行tone mapping，将高动态范围图像映射为低动态范围的显示设备能够显示的图像。本文对paper的方法进行介绍，并以python代码进行实作</p><h1 id="paper介绍"><a href="#paper介绍" class="headerlink" title="paper介绍"></a>paper介绍</h1><h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><p>论文中以威尼斯水城的3张不同曝光图像序列作为输入，如下图所示</p><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/01.png"><p>处理后的图像如下</p><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/02.png"><p>输入序列中的3幅图像，第1幅曝光时间最短，天空和水面的纹理细节得以保留，而建筑物和船只的很多细节都丢失了。第2幅图像曝光时间适中，天空和水面仍有部分细节，建筑物细节和船只的细节增多。第3幅图曝光时间最长，天空过曝，水面有部分细节，建筑物和船只的细节最为充分。可以看出，经过融合之后的图像结合了3副图像各自的优势，每幅图像不同区域的细节都得以保留，而信息丢失的部分已经尽可能丢弃掉了，效果非常好</p><h2 id="该方法的优势"><a href="#该方法的优势" class="headerlink" title="该方法的优势"></a>该方法的优势</h2><ul><li><p>pipeline得以简化：通常的HDR做法需要从多张曝光图像序列中合成高动态范围图像，需要恢复相机特定的响应曲线。另外，由于大多数显示设备动态范围有限，不能直接显示HDR图像，需要通过tone mapping压缩动态范围以适应显示设备的动态范围。而本方法则简单很多</p></li><li><p>不需要担心相机的校准问题，也不需要记录每张照片的曝光时间(响应曲线的校准需要知道每张照片的曝光时间)</p></li><li><p>曝光序列中可以允许过度曝光的部分，传统HDR方法由于要恢复响应曲线，存在过曝的图像不能使用</p></li></ul><h2 id="Exposure-Fusion"><a href="#Exposure-Fusion" class="headerlink" title="Exposure Fusion"></a>Exposure Fusion</h2><p>曝光融合通过只保留多次曝光图像序列中的“最佳”部分来计算所需的图像。什么是“最佳”是由一组质量度量指标来确定的，通过这些指标来对图像进行衡量并分配权重。最后合成的图像是利用拉普拉斯金字塔进行融合的。该paper中假定所有图像序列都是对齐的</p><h3 id="质量衡量标准"><a href="#质量衡量标准" class="headerlink" title="质量衡量标准"></a>质量衡量标准</h3><p>由于曝光不足和过度曝光，序列中会包含很多平坦和无色的区域。这样的区域权重应该尽可能少，而颜色鲜艳和细节丰富的区域应该得到充分保留</p><p>paper中提出了以下3种指标</p><ul><li><p>对比度(Contrast)：将拉普拉斯滤波器应用到每张图像，并取滤波器响应的绝对值，将其作为对比度的简单指标C。对比度越高表明纹理和边缘越多，这部分像素的权重应该更高</p></li><li><p>饱和度(Saturation)：在每个像素位置上进行饱和度测量S，计算方式为R、G、B三通道的标准差</p></li><li><p>良好曝光(Well-exposedness)：希望每个像素位置良好曝光(既不要曝光不足也不要曝光过度)，即认为像素值接近中间为最好，例如归一化的像素值为0~1，那么0.5为最好，使用一个均值为0.5的高斯曲线来衡量像素值离0.5的距离，越近代表越好，得到指标E</p></li></ul><p>每个像素不同度量信息相乘，得到每张图像的权重，使用一个幂函数来控制每个指标的影响程度</p><p>\begin{equation}<br>W<em>{ij,k} = (C</em>{IJ,K})^{\omega <em>{C}} \times (S</em>{ij,k})^{\omega<em>{S}} \times (E</em>{ij,k})^{\omega_{E}}<br>\end{equation}</p><p>其中$k$表示曝光序列中的第$k$次曝光，$i,j$表示像素位置，$W_{ij,k}$表示第$k$次曝光图像的像素$i,j$处的权重</p><h2 id="融合"><a href="#融合" class="headerlink" title="融合"></a>融合</h2><p>计算每个像素的加权平均值来融合N个图像。需要对权重进行正则化</p><p>\begin{equation}<br>\hat(W<em>{ij,k}) = [\sum</em>{\acute{k}=1}^{N}W<em>{ij,\acute{k}}]^{-1}W</em>{ij,k}<br>\end{equation}</p><p>paper中提到，如果使用简单的权重和图像进行加权平均，得到的融合图像并不让人满意，会在边界产生光晕和接缝问题。最终paper中选择拉普拉斯金字塔来进行多个图像的融合</p><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/03.png"><p>普拉斯金字塔的详细介绍见另一篇文章<a href="/2022/05/18/DIP-图像金字塔/" title="DIP-图像金字塔">DIP-图像金字塔</a></p><h1 id="python实作"><a href="#python实作" class="headerlink" title="python实作"></a>python实作</h1><p>首先导入依赖库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><p>读入图像并显示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">image_list = [</span><br><span class="line">    <span class="string">'images/Balloon-01.jpg'</span>,</span><br><span class="line">    <span class="string">'images/Balloon-02.jpg'</span>,</span><br><span class="line">    <span class="string">'images/Balloon-03.jpg'</span>,</span><br><span class="line">    <span class="string">'images/Balloon-04.jpg'</span>,</span><br><span class="line">]</span><br><span class="line">images = np.stack([cv2.imread(name) <span class="keyword">for</span> name <span class="keyword">in</span> image_list])</span><br><span class="line"></span><br><span class="line"><span class="comment"># show sequence</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">12</span>))</span><br><span class="line"><span class="keyword">for</span> i, im <span class="keyword">in</span> enumerate(images):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,i+<span class="number">1</span>)</span><br><span class="line">    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.title(<span class="string">'image-0&#123;&#125;'</span>.format(i))</span><br><span class="line">    plt.imshow(im)</span><br></pre></td></tr></table></figure><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/04.png"><p>定义对比度、饱和度和良好曝光的权重函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">contrast_weights</span><span class="params">(im)</span>:</span></span><br><span class="line">    <span class="comment"># 转为灰度图</span></span><br><span class="line">    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="comment"># 进行拉普拉斯算子处理</span></span><br><span class="line">    contrast = cv2.Laplacian(gray, cv2.CV_32F)</span><br><span class="line">    <span class="comment"># 取绝对值   </span></span><br><span class="line">    weights = np.abs(contrast)</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saturation_weights</span><span class="params">(im)</span>:</span></span><br><span class="line">    <span class="comment"># 计算标准差</span></span><br><span class="line">    <span class="keyword">return</span> im.std(axis=<span class="number">2</span>, dtype=np.float32)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">well_exposedmess_weights</span><span class="params">(im, sigma=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.prod(np.exp(-((im - <span class="number">0.5</span>)**<span class="number">2</span>)/(<span class="number">2</span>*sigma)), axis=<span class="number">2</span>, dtype=np.float32)</span><br></pre></td></tr></table></figure><p>对图像序列进行权重计算并显示权重图片</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, im <span class="keyword">in</span> enumerate(images):</span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">    <span class="comment"># origin image</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.title(<span class="string">'origin'</span>)</span><br><span class="line">    plt.imshow(im)</span><br><span class="line">    c_weights = contrast_weights2(im)</span><br><span class="line">    s_weights = saturation_weights2(im)</span><br><span class="line">    e_weights = well_exposedmess_weights2(im)</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.title(<span class="string">'contrast'</span>)</span><br><span class="line">    plt.imshow(c_weights, cmap=<span class="string">'gray'</span>)</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.title(<span class="string">'saturation'</span>)</span><br><span class="line">    plt.imshow(s_weights, cmap=<span class="string">'gray'</span>)</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.title(<span class="string">'well-exposedmess'</span>)</span><br><span class="line">    plt.imshow(e_weights, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure><p>图像1的原图、对比度图、饱和度图以及曝光良好图</p><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/05.png"><p>图像2的原图、对比度图、饱和度图以及曝光良好图</p><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/06.png"><p>图像3的原图、对比度图、饱和度图以及曝光良好图</p><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/07.png"><p>图像4的原图、对比度图、饱和度图以及曝光良好图</p><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/08.png"><p>可以看到对比度图能够提取图像明显的边缘细节，对比度图能够踢球色彩艳丽的区域，曝光良好图能够提取亮度适中的区域</p><p>定义曝光融合函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exposure_fusion</span><span class="params">(images, measure_weights=<span class="params">(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>)</span>, best_expo=<span class="number">0.5</span>, sigma=<span class="number">0.2</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                   layers_nr=<span class="number">7</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 图像转为float32，归一化</span></span><br><span class="line">    images = np.stack([im.astype(<span class="string">'float32'</span>)/<span class="number">255</span> <span class="keyword">for</span> im <span class="keyword">in</span> images], axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 正则化函数</span></span><br><span class="line">    normalize = <span class="keyword">lambda</span> x: x / np.expand_dims(np.sum(x, axis=<span class="number">0</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 权重计算</span></span><br><span class="line">    weights = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(images)):</span><br><span class="line">        <span class="comment"># 计算每幅图像的对比度</span></span><br><span class="line">        c_weights = contrast_weights2(images[i])</span><br><span class="line">        <span class="comment"># 计算每幅图像的饱和度</span></span><br><span class="line">        s_weights = saturation_weights2(images[i])</span><br><span class="line">        <span class="comment"># 计算每幅图像的曝光良好情况</span></span><br><span class="line">        e_weights = well_exposedmess_weights2(images[i])</span><br><span class="line">        <span class="comment"># 对比度、饱和度、曝光良好融合</span></span><br><span class="line">        weight = np.power(c_weights, measure_weights[<span class="number">0</span>]) * \</span><br><span class="line">                 np.power(s_weights, measure_weights[<span class="number">1</span>]) * \</span><br><span class="line">                 np.power(e_weights, measure_weights[<span class="number">2</span>])</span><br><span class="line">        <span class="comment">#print(weight)</span></span><br><span class="line">        weights.append(weight)</span><br><span class="line">    <span class="comment">#layers_show(weights)</span></span><br><span class="line">    weights = np.stack(weights, axis=<span class="number">0</span>)</span><br><span class="line">    weights += <span class="number">1e-12</span></span><br><span class="line">    <span class="comment"># 权重归一化</span></span><br><span class="line">    weights = normalize(weights)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 像素值恢复到0~255区间</span></span><br><span class="line">    images *= <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算图像的拉普拉斯金字塔</span></span><br><span class="line">    images_LPyrs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(images)):</span><br><span class="line">        LPyrs = laplace_pyramid(images[i], layers_nr)</span><br><span class="line">        images_LPyrs.append(LPyrs)</span><br><span class="line">    layers_info_print(images_LPyrs[<span class="number">0</span>], <span class="string">'images_LPyrs'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算权重的高斯金字塔</span></span><br><span class="line">    weight_GPyrs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(weights)):</span><br><span class="line">        GPyrs = gaussian_pyramid(weights[i], layers_nr)</span><br><span class="line">        weight_GPyrs.append(GPyrs)</span><br><span class="line">    layers_info_print(weight_GPyrs[<span class="number">0</span>], <span class="string">'weight_GPyrs'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算融合的拉普拉斯金字塔</span></span><br><span class="line">    fused_LPyrs = [np.sum([images_LPyrs[k][n] * </span><br><span class="line">        np.atleast_3d(weight_GPyrs[k][layers_nr - n <span class="number">-1</span>]) <span class="keyword">for</span> k <span class="keyword">in</span> range(len(images))], axis=<span class="number">0</span>) <span class="keyword">for</span> n <span class="keyword">in</span> range(layers_nr)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 迭代融合</span></span><br><span class="line">    start = fused_LPyrs[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#print('start shape:&#123;&#125;'.format(start.shape))</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, layers_nr):</span><br><span class="line">        upsample = cv2.resize(start, (fused_LPyrs[i].shape[<span class="number">1</span>], fused_LPyrs[i].shape[<span class="number">0</span>]))</span><br><span class="line">        start = fused_LPyrs[i] + upsample</span><br><span class="line">    start = np.clip(start, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">"uint8"</span>)</span><br><span class="line">    plt.imshow(cv2.cvtColor(start, cv2.COLOR_BGR2RGB))</span><br></pre></td></tr></table></figure><p>融合结果如下</p><img src="/2022/05/19/HDR-曝光融合-Exposure-Fusion/09.png"><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><p>Mertens, Tom, Jan Kautz, and Frank Van Reeth. “Exposure fusion.” Computer Graphics and Applications, 2007. PG’07. 15th Pacific Conference on. IEEE, 2007.</p></li><li><p><a href="https://zhuanlan.zhihu.com/p/455674916" target="_blank" rel="noopener">知乎-山与水你和我-exposure fusion 图像曝光融合</a></p></li><li><p><a href="https://mericam.github.io/" target="_blank" rel="noopener">Tom Mertens github</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Tom Mertens、Jan Kautz等人在”Exposure Fusion”这篇paper中提出了一种简单有效的曝光融合方法，通过将一组不同曝光的图像序列进行直接融合得到一副高质量图像，而不需要先将这些图像序列转化为HDR。传统的HDR做法采用多重曝光获得图像序列，需
      
    
    </summary>
    
      <category term="CV" scheme="http://yoursite.com/categories/CV/"/>
    
      <category term="HDR" scheme="http://yoursite.com/categories/CV/HDR/"/>
    
    
      <category term="DIP" scheme="http://yoursite.com/tags/DIP/"/>
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
      <category term="HDR" scheme="http://yoursite.com/tags/HDR/"/>
    
  </entry>
  
  <entry>
    <title>DIP-图像金字塔</title>
    <link href="http://yoursite.com/2022/05/18/DIP-%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/"/>
    <id>http://yoursite.com/2022/05/18/DIP-图像金字塔/</id>
    <published>2022-05-18T01:40:22.000Z</published>
    <updated>2023-02-02T11:41:00.338Z</updated>
    
    <content type="html"><![CDATA[<p>图像金字塔对于执行多尺度的编辑操作非常有效，能够在保持图像细节的同时进行融合。Peter J. Burt等人在1983年的”The Laplacian Pyramid as a Compact Image Code”中提出了拉普拉斯金字塔用于图像压缩，后来该方法被用于图像融合效果很好</p><p>本文首先对拉普拉斯金字塔进行介绍，然后对拉普拉斯用于图像融合进行介绍</p><h1 id="Laplacian-Pyramid"><a href="#Laplacian-Pyramid" class="headerlink" title="Laplacian Pyramid"></a>Laplacian Pyramid</h1><p>拉普拉斯金字塔通过将原始图像减去一个低通滤波的图像来消除像素间的相关性，得到一个净数据压缩，仅保留了差异。将这种做法在多尺度上进行迭代，会得到一个这种差异的金字塔，由于这种做法相当于用拉普拉斯算子对图像进行多尺度采样，因此得到的金字塔叫做拉普拉斯金字塔</p><p>该方法用于数据压缩时，仅需保留金字塔最小分辨率(最低层次)的低通图像以及一个拉普拉斯金字塔，就可以完全恢复原始图像。在重建原始图像时，将最小分辨率的低通图像逐层与拉普拉斯金字塔进行结合，最终获得压缩前的原始图像</p><p>下图是整个拉普拉斯金字塔的构建和重建原始图像的示意图</p><img src="/2022/05/18/DIP-图像金字塔/01.png"><p>该过程中主要涉及到以下几种处理</p><ul><li><p>高斯滤波或高斯模糊(Gaussian Blur)</p></li><li><p>上采样(UpSample)</p></li><li><p>下采样(DownSample)</p></li><li><p>图像相加和相减</p></li></ul><p>高斯滤波主要关注核大小与方差，下采样比较好做，按偶数或奇数行采样即可。上采样可以使用各种插值方法如三次样条插值等</p><h2 id="拉普拉斯金字塔的生成"><a href="#拉普拉斯金字塔的生成" class="headerlink" title="拉普拉斯金字塔的生成"></a>拉普拉斯金字塔的生成</h2><p>拉普拉斯金字塔的生成需要依赖高斯金字塔，上图中的黄色部分是生成高斯金字塔的过程。”Image”表示原始图像，以3层金字塔为例，G0即原始图像，经过高斯滤波和下采样得到尺度缩小为1/4的低通图像G1，重复该过程得到G2、G3，[G0, G1, G2, G3]构成了4层的高斯金字塔</p><p>拉普拉斯金字塔的每层由对应层的高斯金字塔图像与高斯金字塔下层图像的上采样相减得到，例如L3是由1/4原始尺度的G1经过上采样，在与G0相减得到。L2是由G2上采样与G1相减得到。实际需要使用的拉普拉斯金字塔只有3层，即[L1, L2, L3]</p><p>python代码如下</p><p>导入库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><p>定义高斯金字塔生成函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian_pyramid</span><span class="params">(im, layers)</span>:</span></span><br><span class="line">    GPyrs = [im]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, layers):</span><br><span class="line">        <span class="comment"># 高斯滤波</span></span><br><span class="line">        blur_im = cv2.GaussianBlur(GPyrs[i<span class="number">-1</span>], (<span class="number">5</span>,<span class="number">5</span>), <span class="number">0.83</span>)</span><br><span class="line">        <span class="comment"># 下采样，取偶数行</span></span><br><span class="line">        downsample = blur_im[::<span class="number">2</span>, ::<span class="number">2</span>]</span><br><span class="line">        GPyrs.append(downsample)</span><br><span class="line">    <span class="keyword">return</span> GPyrs</span><br></pre></td></tr></table></figure><p>定义拉普拉斯金字塔生成函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">laplace_pyramid</span><span class="params">(im, layers)</span>:</span></span><br><span class="line">    GPyrs = gaussian_pyramid(im, layers)</span><br><span class="line">    LPyrs = [GPyrs[<span class="number">-1</span>]]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, layers):</span><br><span class="line">        <span class="comment"># 上采样，使用opencv默认的采样方法</span></span><br><span class="line">        size = (GPyrs[layers-i<span class="number">-1</span>].shape[<span class="number">1</span>], GPyrs[layers-i<span class="number">-1</span>].shape[<span class="number">0</span>])</span><br><span class="line">        upsample = cv2.resize(GPyrs[layers-i], size)</span><br><span class="line">        <span class="comment"># 上层高斯图像与上采样后图像相减</span></span><br><span class="line">        LPyrs.append(GPyrs[layers-i<span class="number">-1</span>]-upsample)</span><br><span class="line">    <span class="keyword">return</span> LPyrs</span><br></pre></td></tr></table></figure><p>定义金字塔信息打印与显示函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">cv2.namedWindow(<span class="string">'img'</span>, cv2.WINDOW_NORMAL)</span><br><span class="line">dpi = <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layers_show</span><span class="params">(layers)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i, layer <span class="keyword">in</span> enumerate(layers):</span><br><span class="line">        l = layer.astype(<span class="string">'uint8'</span>)</span><br><span class="line">        <span class="comment"># 色彩通道转换，opencv默认是BGR</span></span><br><span class="line">        im = cv2.cvtColor(l, cv2.COLOR_BGR2RGB)</span><br><span class="line">        h, w, _ = im.shape</span><br><span class="line">        figsize = w/float(dpi), h/float(dpi)</span><br><span class="line">        fig = plt.figure(figsize=figsize)</span><br><span class="line">        ax = fig.add_axes([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">        ax.axis(<span class="string">'off'</span>)</span><br><span class="line">        plt.title(<span class="string">'layer[&#123;&#125;] &#123;&#125;'</span>.format(i, im.shape))</span><br><span class="line">        ax.imshow(im)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layers_info_print</span><span class="params">(layers, name)</span>:</span></span><br><span class="line">    print(<span class="string">'---- &#123;&#125;\'s info ----'</span>.format(name))</span><br><span class="line">    <span class="keyword">for</span> i, layer <span class="keyword">in</span> enumerate(layers):</span><br><span class="line">        print(<span class="string">'layer[&#123;&#125;] shape:&#123;&#125;'</span>.format(i, layer.shape))</span><br><span class="line">    print(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure><p>读入图像生成4层的高斯金字塔并显示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">im = cv2.imread(<span class="string">'images/cat.jpeg'</span>)</span><br><span class="line">im.astype(<span class="string">'float32'</span>)</span><br><span class="line">GPyrs = gaussian_pyramid(im)</span><br><span class="line">layers_info_print(GPyrs)</span><br><span class="line">layers_show(GPyrs)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">---- GPyrs's info ----</span><br><span class="line">layer[0] shape:(607, 1080, 3)</span><br><span class="line">layer[1] shape:(304, 540, 3)</span><br><span class="line">layer[2] shape:(152, 270, 3)</span><br><span class="line">layer[3] shape:(76, 135, 3)</span><br></pre></td></tr></table></figure><p>G0层图像</p><img src="/2022/05/18/DIP-图像金字塔/02.png"><p>G1层图像</p><img src="/2022/05/18/DIP-图像金字塔/03.png"><p>G2层图像</p><img src="/2022/05/18/DIP-图像金字塔/04.png"><p>G3层图像</p><img src="/2022/05/18/DIP-图像金字塔/05.png"><p>生成4层拉普拉斯金字塔并显示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LPyrs = laplace_pyramid(im, <span class="number">4</span>)</span><br><span class="line">layers_info_print(LPyrs, <span class="string">"LPyrs"</span>)</span><br><span class="line">layers_show(LPyrs)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">---- LPyrs's info ----</span><br><span class="line">layer[0] shape:(76, 135, 3)</span><br><span class="line">layer[1] shape:(152, 270, 3)</span><br><span class="line">layer[2] shape:(304, 540, 3)</span><br><span class="line">layer[3] shape:(607, 1080, 3)</span><br></pre></td></tr></table></figure><p>L0层图像</p><img src="/2022/05/18/DIP-图像金字塔/06.png"><p>L1层图像</p><img src="/2022/05/18/DIP-图像金字塔/07.png"><p>L2层图像</p><img src="/2022/05/18/DIP-图像金字塔/08.png"><p>L3层图像</p><img src="/2022/05/18/DIP-图像金字塔/09.png"><p>可以看到拉普拉斯图像中的每幅图像主要是纹理特征</p><h2 id="原始图像重建"><a href="#原始图像重建" class="headerlink" title="原始图像重建"></a>原始图像重建</h2><p>重建过程由最小分辨率开始的低通图像开始，经过上采样并与拉普莱斯金字塔对应分辨率图像相加，并经过多次向上迭代，最终得到原始图像并显示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">reconstruction = LPyrs[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">    size = (LPyrs[i].shape[<span class="number">1</span>], LPyrs[i].shape[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 上采样，使用opencv默认的采样方法</span></span><br><span class="line">    upsample = cv2.resize(reconstruction, size)</span><br><span class="line">    <span class="comment"># 上采样后图像与拉普拉斯图像相加</span></span><br><span class="line">    reconstruction = LPyrs[i] + upsample</span><br><span class="line">reconstruction = np.clip(reconstruction, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(<span class="string">'reconstruction'</span>)</span><br><span class="line">plt.imshow(cv2.cvtColor(reconstruction, cv2.COLOR_BGR2RGB))</span><br></pre></td></tr></table></figure><p>结果如下图，能够正常复原原始图像</p><img src="/2022/05/18/DIP-图像金字塔/10.png"><h1 id="图像融合"><a href="#图像融合" class="headerlink" title="图像融合"></a>图像融合</h1><p>利用拉普拉斯金字塔进行图像融合是一个非常有趣的应用。融合后的图像在交界处的变化是非常平滑的，图像上的高频纹理混合得更快，可以避免 “鬼影”效果。为了创建融合图像，每幅图像首先生成自己的拉普拉斯金字塔，然后用一个二值掩模图像生成的高斯金字塔作为融合的权重金字塔，与两幅待融合的拉普拉斯金字塔进行结合，得到融合后的拉普拉斯金字塔，最后用融合后的拉普拉斯金字塔与最小分辨率的融合低通图像进行重建，最终得到融合的图像</p><p>加载左右两幅待融合图像以及二值掩模图像并显示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">layers = <span class="number">7</span></span><br><span class="line">left  = cv2.imread(<span class="string">'images/blend/left.png'</span>)</span><br><span class="line">right = cv2.imread(<span class="string">'images/blend/right.png'</span>)</span><br><span class="line">mask  = cv2.imread(<span class="string">'images/blend/mask.png'</span>, <span class="number">0</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(<span class="string">'left'</span>)</span><br><span class="line">plt.imshow(cv2.cvtColor(left, cv2.COLOR_BGR2RGB))</span><br></pre></td></tr></table></figure><img src="/2022/05/18/DIP-图像金字塔/11.png"><p>显示右图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(<span class="string">'right'</span>)</span><br><span class="line">plt.imshow(cv2.cvtColor(right, cv2.COLOR_BGR2RGB))</span><br></pre></td></tr></table></figure><img src="/2022/05/18/DIP-图像金字塔/12.png"><p>显示二值掩模图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(<span class="string">'mask'</span>)</span><br><span class="line">plt.imshow(mask, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure><img src="/2022/05/18/DIP-图像金字塔/13.png"><p>图像预处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 大小调整为256x256</span></span><br><span class="line">left  = cv2.resize(left, (<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line">right = cv2.resize(right, (<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line">mask  = cv2.resize(mask, (<span class="number">256</span>, <span class="number">256</span>)) </span><br><span class="line"><span class="comment"># 数值定点化为int16，由于拉普拉斯计算减法存在负值</span></span><br><span class="line">left  = left.astype(<span class="string">'int16'</span>)</span><br><span class="line">right = right.astype(<span class="string">'int16'</span>)</span><br><span class="line">mask  = mask.astype(<span class="string">'float32'</span>) / <span class="number">255</span></span><br><span class="line"><span class="comment"># 由于mask为灰度图，将其转化为3通道</span></span><br><span class="line">mask = np.stack([mask, mask, mask], axis=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p>计算left、right、mask的高斯金字塔，left和right的拉普拉斯金字塔</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成高斯金字塔</span></span><br><span class="line">left_G  = gaussian_pyramid(left, layers)</span><br><span class="line">right_G = gaussian_pyramid(right, layers)</span><br><span class="line">mask_G  = gaussian_pyramid(mask, layers)</span><br><span class="line"><span class="comment"># 生成互补的二值掩模</span></span><br><span class="line">mask_G_r = []</span><br><span class="line"><span class="keyword">for</span> mask <span class="keyword">in</span> mask_G:</span><br><span class="line">    mask_G_r.append(<span class="number">1.0</span> - mask)</span><br><span class="line"><span class="comment"># 生成拉普拉斯金字塔</span></span><br><span class="line">left_L  = laplace_pyramid(left, layers)</span><br><span class="line">right_L = laplace_pyramid(right, layers)</span><br></pre></td></tr></table></figure><p>打印各金字塔尺度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">layers_info_print(left_G, <span class="string">'right_G'</span>)</span><br><span class="line">layers_info_print(right_G, <span class="string">'right_G'</span>)</span><br><span class="line">layers_info_print(mask_G, <span class="string">'mask_G'</span>)</span><br><span class="line">layers_info_print(left_L, <span class="string">'left_L'</span>)</span><br><span class="line">layers_info_print(right_L, <span class="string">'right_L'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">---- left_G's info ----</span><br><span class="line">layer[0] shape:(256, 256, 3)</span><br><span class="line">layer[1] shape:(128, 128, 3)</span><br><span class="line">layer[2] shape:(64, 64, 3)</span><br><span class="line">layer[3] shape:(32, 32, 3)</span><br><span class="line">layer[4] shape:(16, 16, 3)</span><br><span class="line">layer[5] shape:(8, 8, 3)</span><br><span class="line">layer[6] shape:(4, 4, 3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---- right_G's info ----</span><br><span class="line">layer[0] shape:(256, 256, 3)</span><br><span class="line">layer[1] shape:(128, 128, 3)</span><br><span class="line">layer[2] shape:(64, 64, 3)</span><br><span class="line">layer[3] shape:(32, 32, 3)</span><br><span class="line">layer[4] shape:(16, 16, 3)</span><br><span class="line">layer[5] shape:(8, 8, 3)</span><br><span class="line">layer[6] shape:(4, 4, 3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---- mask_G's info ----</span><br><span class="line">layer[0] shape:(256, 256, 3)</span><br><span class="line">layer[1] shape:(128, 128, 3)</span><br><span class="line">layer[2] shape:(64, 64, 3)</span><br><span class="line">layer[3] shape:(32, 32, 3)</span><br><span class="line">layer[4] shape:(16, 16, 3)</span><br><span class="line">layer[5] shape:(8, 8, 3)</span><br><span class="line">layer[6] shape:(4, 4, 3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---- left_L's info ----</span><br><span class="line">layer[0] shape:(4, 4, 3)</span><br><span class="line">layer[1] shape:(8, 8, 3)</span><br><span class="line">layer[2] shape:(16, 16, 3)</span><br><span class="line">layer[3] shape:(32, 32, 3)</span><br><span class="line">layer[4] shape:(64, 64, 3)</span><br><span class="line">layer[5] shape:(128, 128, 3)</span><br><span class="line">layer[6] shape:(256, 256, 3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---- right_L's info ----</span><br><span class="line">layer[0] shape:(4, 4, 3)</span><br><span class="line">layer[1] shape:(8, 8, 3)</span><br><span class="line">layer[2] shape:(16, 16, 3)</span><br><span class="line">layer[3] shape:(32, 32, 3)</span><br><span class="line">layer[4] shape:(64, 64, 3)</span><br><span class="line">layer[5] shape:(128, 128, 3)</span><br><span class="line">layer[6] shape:(256, 256, 3)</span><br></pre></td></tr></table></figure><p>生成融合拉普拉斯金字塔</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">blend_L = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(layers):</span><br><span class="line">    l = (mask_G_r[layers-i<span class="number">-1</span>])*left_L[i] + (mask_G[layers-i<span class="number">-1</span>])*right_L[i]</span><br><span class="line">    blend_L.append(l.astype(<span class="string">'int16'</span>))</span><br><span class="line">layers_info_print(blend_L, <span class="string">'blend_L'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">---- blend_L's info ----</span><br><span class="line">layer[0] shape:(4, 4, 3)</span><br><span class="line">layer[1] shape:(8, 8, 3)</span><br><span class="line">layer[2] shape:(16, 16, 3)</span><br><span class="line">layer[3] shape:(32, 32, 3)</span><br><span class="line">layer[4] shape:(64, 64, 3)</span><br><span class="line">layer[5] shape:(128, 128, 3)</span><br><span class="line">layer[6] shape:(256, 256, 3)</span><br></pre></td></tr></table></figure><p>计算最小分辨率低通融合图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">start = (mask_G_r[<span class="number">-1</span>])*left_G[<span class="number">-1</span>] + (mask_G[<span class="number">-1</span>])*right_G[<span class="number">-1</span>]</span><br><span class="line">start = start.astype(<span class="string">'int16'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(<span class="string">'start'</span>)</span><br><span class="line">plt.imshow(cv2.cvtColor(start.astype(<span class="string">'uint8'</span>), cv2.COLOR_BGR2RGB))</span><br></pre></td></tr></table></figure><img src="/2022/05/18/DIP-图像金字塔/14.png"><p>进行融合</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">blend = start</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, layers):</span><br><span class="line">    size = (blend_L[i].shape[<span class="number">1</span>], blend_L[i].shape[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 上采样</span></span><br><span class="line">    upsample = cv2.resize(blend, size)</span><br><span class="line">    <span class="comment"># 上采样图像与融合拉普拉斯对应层相加</span></span><br><span class="line">    blend = blend_L[i] + upsample</span><br><span class="line">    blend = np.clip(blend, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(<span class="string">'blend'</span>)</span><br><span class="line">plt.imshow(cv2.cvtColor(blend, cv2.COLOR_BGR2RGB))</span><br></pre></td></tr></table></figure><p>最终融合后的图像如下</p><img src="/2022/05/18/DIP-图像金字塔/15.png">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;图像金字塔对于执行多尺度的编辑操作非常有效，能够在保持图像细节的同时进行融合。Peter J. Burt等人在1983年的”The Laplacian Pyramid as a Compact Image Code”中提出了拉普拉斯金字塔用于图像压缩，后来该方法被用于图像融
      
    
    </summary>
    
      <category term="CV" scheme="http://yoursite.com/categories/CV/"/>
    
      <category term="DIP" scheme="http://yoursite.com/categories/CV/DIP/"/>
    
    
      <category term="DIP" scheme="http://yoursite.com/tags/DIP/"/>
    
      <category term="图像融合" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>VitisAI-02-环境与资源</title>
    <link href="http://yoursite.com/2022/05/04/VitisAI-02-%E7%8E%AF%E5%A2%83%E4%B8%8E%E8%B5%84%E6%BA%90/"/>
    <id>http://yoursite.com/2022/05/04/VitisAI-02-环境与资源/</id>
    <published>2022-05-04T13:07:31.000Z</published>
    <updated>2023-02-02T11:39:58.641Z</updated>
    
    <content type="html"><![CDATA[<p>在第一篇文章”VitisAI-01-Overview”中，我简要介绍了什么是VitisAI、VitisAI相关的的技术栈、我的开发环境是什么样的以及需要安装下载哪些资源。本文对我的开发环境以及所需资源的下载安装进行一个更为详细的说明</p><h1 id="环境介绍"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍</h1><p>我使用的台式机操作系统是Windows11，我采用的是在虚拟机中搭建VitisAI的方式来进行开发和研究。由于VitisAI开发需要PetaLinux编译，而目前PetaLinux仅支持Linux操作系统，而我并不使用Linux作为我的主操作系统，因此选择在虚拟机中搭建Linux系统的方式。我的系统配置详细信息如下</p><ul><li><p>主操作系统：Windows 11 专业版(22000.613)</p></li><li><p>处理器：12th Gen Intel(R) Core(TM) i7-12700K   3.61 GHz</p></li><li><p>虚拟机：VMware Workstation 16.2.2</p><ul><li><p>操作系统：Ubuntu20.0.4</p></li><li><p>处理器：内核数8</p></li><li><p>内存：12GB</p></li><li><p>磁盘：400GB</p></li></ul></li></ul><p>这里需要注意的是虚拟机中处理器相关的设置，截图如下</p><img src="/2022/05/04/VitisAI-02-环境与资源/01.png"><p>处理器数量选择1，每个处理器的内核数量选择8，因此总内核数为8。虚拟化引擎选中了”虚拟化 Inter VT-x/EPT 或 AMD-V/RVI(V)”。按照我的处理器设置整个VitisAI的开发过程实测是没有问题的。主要容易出问题的地方是PetaLinux编译，因为PetaLinux的多线程编译与内核数量相关，内核数量越多，可同时执行的编译线程越多，8个内核同时只能进行8个编译线程。曾经尝试过将处理器数量调整到12或16以加快PetaLinux的编译，但是编译到一定进度后总会发生停住不动的问题(查看CPU占用率基本为0，表明CPU未分给编译线程资源)，这里并没有搞清楚到底是什么原因，可能是12代CPU使用了Alder Lake的大小核架构与VMware Workstation不兼容问题</p><h1 id="资源下载及安装"><a href="#资源下载及安装" class="headerlink" title="资源下载及安装"></a>资源下载及安装</h1><p>虚拟机软件VMware Workstation与Ubuntu20.0.4虚拟机的下载安装并不包含在内。这里主要介绍与VitisAI相关的各个开发工具的下载与安装。其中Vivado和Vitis 2021.1和2021.2都可以，PetaLinux建议使用2021.2</p><h2 id="Xilinx-Unified-Installer"><a href="#Xilinx-Unified-Installer" class="headerlink" title="Xilinx Unified Installer"></a>Xilinx Unified Installer</h2><p>子2019年之后，Xilinx将软件开发平台进行了统一，其后的软件开发平台称作Vitis统一开发平台，Xilinx Unified Installer就是统一开发平台的安装包，这里推荐下载2021.2版本，打开地址<a href="https://china.xilinx.com/support/download/index.html/content/xilinx/zh/downloadNav/vitis/2021-2.html" target="_blank" rel="noopener">Vitis下载</a>，可以看到如下内容</p><img src="/2022/05/04/VitisAI-02-环境与资源/02.png"><p>点击2021.2，下翻页面到如下位置，点击”<a href="https://china.xilinx.com/member/forms/download/xef.html?filename=Xilinx_Unified_2021.2_1021_0703.tar.gz" target="_blank" rel="noopener">赛灵思统一安装程序 (Xilinx Unified Installer 2021.2) SFD</a> (TAR/GZIP - 71.9 GB)”进行下载</p><img src="/2022/05/04/VitisAI-02-环境与资源/03.png"><p>下载下来是一个.tar.gz的压缩包，将其移动到虚拟机中，解压后运行其中的xsetup即可开始安装，安装过程是UI界面的，选择Vitis，会安装Vivado和Vitis以及一系列相关依赖库，然后选择安装路径即可自动安装</p><p>我的安装路径为”/home/opt/pkg/Xilinx”，安装完成后，可通过如下命令打开Vivado来检查是否安装成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source /home/opt/pkg/Xilinx/Vivado/2021.2/setting64.sh</span><br><span class="line">vivado</span><br></pre></td></tr></table></figure><h2 id="PetaLinux"><a href="#PetaLinux" class="headerlink" title="PetaLinux"></a>PetaLinux</h2><p>PetaLinux的安装文件可单独下载，也可以使用Xilinx Unified Installer进行安装。使用Xilinx Unified Installer安装时仅需要在安装步骤的第一步选择PetaLinux即可。推荐使用Xilinx Unified Installer进行安装</p><p>我的PetaLinux安装路径为”/home/opt/pkg/Xilinx/PetaLinux”，PetaLinux安装完成后，可通过如下命令来查看PetaLinux是否安装成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source /home/opt/pkg/Xilinx/PetaLinux/2021.2/setting64.sh</span><br><span class="line">petalinux -h</span><br></pre></td></tr></table></figure><h3 id="PetaLinux依赖库"><a href="#PetaLinux依赖库" class="headerlink" title="PetaLinux依赖库"></a>PetaLinux依赖库</h3><p>由于PetaLinux编译需要很多额外的依赖库，Xilinx为PetaLinux提供了Release Note来说明不同系统中需要依赖哪些库，打开<a href="https://china.xilinx.com/support/download/index.html/content/xilinx/zh/downloadNav/embedded-design-tools/2021-2.html" target="_blank" rel="noopener">PetaLinux下载地址</a></p><img src="/2022/05/04/VitisAI-02-环境与资源/04.png"><p>在右侧旁边有对应版本的发布说明，点击它，并在打开的页面中下拉到最下方，下载”2021.2_PetaLinux_Package_List.xlsx”</p><img src="/2022/05/04/VitisAI-02-环境与资源/05.png"><p>用Excel打开该文件，内容如下</p><img src="/2022/05/04/VitisAI-02-环境与资源/06.png"><p>其中有Ubuntu系统下的依赖库安装命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install iproute2 gawk python3 python build-essential gcc git make net-tools libncurses5-dev tftpd zlib1g-dev libssl-dev flex bison libselinux1 gnupg wget git-core diffstat chrpath socat xterm autoconf libtool tar unzip texinfo zlib1g-dev gcc-multilib automake zlib1g:i386 screen pax gzip cpio python3-pip python3-pexpect xz-utils debianutils iputils-ping python3-git python3-jinja2 libegl1-mesa libsdl1.2-dev pylint3</span><br></pre></td></tr></table></figure><h3 id="PetaLinux离线编译"><a href="#PetaLinux离线编译" class="headerlink" title="PetaLinux离线编译"></a>PetaLinux离线编译</h3><p>由于PetaLinux在编译过程中需要从网络上下载很多第三方包，而很多第三方包的资源在外网中，编译速度受限于网络下载速度。Xilinx提供了离线的第三方包缓存文件，将其下载到本地后，在配置PetaLinux时选择编译方式为离线编译，即可不依赖网络进行离线编译，加快编译速度。离线缓存文件下载位置仍然在<a href="https://china.xilinx.com/support/download/index.html/content/xilinx/zh/downloadNav/embedded-design-tools/2021-2.html" target="_blank" rel="noopener">PetaLinux下载地址</a>页面，下拉到最下方，选择”<a href="https://china.xilinx.com/member/forms/download/xef.html?filename=sstate_aarch64_2021.2.tar.gz" target="_blank" rel="noopener">aarch64 sstate-cache</a> (TAR/GZIP - 20.27 GB)”和”<a href="https://china.xilinx.com/member/forms/download/xef.html?filename=downloads_2021.2.tar.gz" target="_blank" rel="noopener">下载</a>下载 (TAR/GZIP - 57.4 GB)”</p><img src="/2022/05/04/VitisAI-02-环境与资源/07.png"><h2 id="Vitis-AI仓库"><a href="#Vitis-AI仓库" class="headerlink" title="Vitis AI仓库"></a>Vitis AI仓库</h2><p>Vitis AI相关库和工具在Xilinx官方提供的github仓库中，需要将其克隆到本地，该仓库较大，网络不佳克隆可能需要较长时间，命令为</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/Xilinx/Vitis-AI/tree/master</span><br></pre></td></tr></table></figure><h2 id="Vitis-AI-docker"><a href="#Vitis-AI-docker" class="headerlink" title="Vitis AI docker"></a>Vitis AI docker</h2><p>docker添加到用户组</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo usermod -aG docker &lt;username&gt;</span><br><span class="line">sudo systemctl restart docker</span><br><span class="line">sudo chmod 666 /var/run/docker.sock</span><br></pre></td></tr></table></figure><p>VitisAI docker镜像下载</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd Vitis-AI</span><br><span class="line">docker pull xilinx/vitis-ai:latest</span><br></pre></td></tr></table></figure><p>运行docker镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./docker_run.sh xilinx/vitis-ai</span><br></pre></td></tr></table></figure><p>显示如下界面表示运行成功</p><img src="/2022/05/04/VitisAI-02-环境与资源/08.png"><h2 id="安装主机交叉编译"><a href="#安装主机交叉编译" class="headerlink" title="安装主机交叉编译"></a>安装主机交叉编译</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd Vitis-AI/setup/mpsoc/VART</span><br><span class="line">./host_cross_compiler_setup.sh</span><br></pre></td></tr></table></figure><p>安装后运行以下命令测试是否安装正确</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source ~/petalinux_sdk_2021.2/environment-setup-cortexa72-cortexa53-xilinx-linux</span><br><span class="line">cd Vitis-AI/demo/VART/resnet50</span><br><span class="line">bash –x build.sh</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在第一篇文章”VitisAI-01-Overview”中，我简要介绍了什么是VitisAI、VitisAI相关的的技术栈、我的开发环境是什么样的以及需要安装下载哪些资源。本文对我的开发环境以及所需资源的下载安装进行一个更为详细的说明&lt;/p&gt;
&lt;h1 id=&quot;环境介绍&quot;&gt;&lt;a
      
    
    </summary>
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
      <category term="VitisAI" scheme="http://yoursite.com/categories/AI/VitisAI/"/>
    
    
      <category term="Xilinx" scheme="http://yoursite.com/tags/Xilinx/"/>
    
      <category term="Vitis AI" scheme="http://yoursite.com/tags/Vitis-AI/"/>
    
      <category term="AI加速" scheme="http://yoursite.com/tags/AI%E5%8A%A0%E9%80%9F/"/>
    
  </entry>
  
  <entry>
    <title>Python从PDF提取图片</title>
    <link href="http://yoursite.com/2022/04/29/Python%E4%BB%8EPDF%E6%8F%90%E5%8F%96%E5%9B%BE%E7%89%87/"/>
    <id>http://yoursite.com/2022/04/29/Python从PDF提取图片/</id>
    <published>2022-04-29T05:10:04.000Z</published>
    <updated>2023-02-02T11:39:17.374Z</updated>
    
    <content type="html"><![CDATA[<p>阅读PDF格式的论文或者一些书籍时，经常希望将PDF文件中的图片提取出来，市面上有些PDF格式转换的工具可以做到，但是很多都要收费。通过Python的pymupdf库可以完成该功能</p><p>安装pymupdf</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pymupdf</span><br></pre></td></tr></table></figure><p>这里要注意的是安装的库是pymupdf，但是实际使用的是pymupdf安装时带的fitz模块</p><p>首先是需要加载的库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> fitz</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure><p>然后是定义pdf2image函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pdf2image</span><span class="params">(pdf_path, img_path)</span>:</span></span><br><span class="line">    pdf_name = pdf_path.split(<span class="string">'.pdf'</span>)[<span class="number">0</span>]</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    checkXO = <span class="string">r"/Type(?= */XObject)"</span>    <span class="comment"># 判断是否为XObject的正则</span></span><br><span class="line">    checkIM = <span class="string">r"/Subtype(?= */Image)"</span>   <span class="comment"># 判断是否为图像的正则</span></span><br><span class="line">    doc = fitz.open(pdf_path)           <span class="comment"># 获取pdf的对象树</span></span><br><span class="line">    xref_length = doc.xref_length()     <span class="comment"># 获取对象树的对象实例数</span></span><br><span class="line">    print(<span class="string">"processing &#123;&#125; pages:&#123;&#125; objs:&#123;&#125;"</span>.format(</span><br><span class="line">        pdf_path, len(doc), xref_length - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个对象</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm.tqdm(range(<span class="number">1</span>, xref_length)):</span><br><span class="line">        text = doc.xref_object(i)</span><br><span class="line">        isXObject = re.search(checkXO, text)</span><br><span class="line">        isImage = re.search(checkIM, text)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isXObject <span class="keyword">or</span> <span class="keyword">not</span> isImage:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 将对象转换为像素图</span></span><br><span class="line">        pix = fitz.Pixmap(doc, i)</span><br><span class="line">        new_name = pdf_name.replace(<span class="string">'\\'</span>, <span class="string">'_'</span>) + <span class="string">"img&#123;&#125;.png"</span>.format(count)</span><br><span class="line">        new_name = new_name.replace(<span class="string">':'</span>, <span class="string">''</span>)</span><br><span class="line">        <span class="keyword">if</span> pix.n &lt; <span class="number">4</span>:</span><br><span class="line">            pix.save(os.path.join(img_path, new_name))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pix0 = fitz.Pixmap(fitz.csRGB, pix)</span><br><span class="line">            pix0.save(os.path.join(img_path, new_name))</span><br><span class="line">            pix0 = <span class="literal">None</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    print(<span class="string">"running time:&#123;&#125;s"</span>.format(end_time - start_time))</span><br><span class="line">    print(<span class="string">"get &#123;&#125; images"</span>.format(count))</span><br></pre></td></tr></table></figure><p>定义一个从当前目录获取所有pdf文件列表的函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_pdf_files</span><span class="params">()</span>:</span></span><br><span class="line">    files = os.listdir()</span><br><span class="line">    pdf_files = []</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">        <span class="keyword">if</span> f.find(<span class="string">'.pdf'</span>) &gt;= <span class="number">0</span>:</span><br><span class="line">            pdf_files.append(f)</span><br><span class="line">    <span class="keyword">return</span> pdf_files</span><br></pre></td></tr></table></figure><p>定义main函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    pdf_files = get_pdf_files()</span><br><span class="line">    print(<span class="string">'PDF文件列表:'</span>)</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> pdf_files:</span><br><span class="line">        print(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 循环对每个pdf文件进行图片提取</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> pdf_files:</span><br><span class="line">        pdf_name = f.split(<span class="string">'.pdf'</span>)[<span class="number">0</span>]</span><br><span class="line">        img_dir = <span class="string">"&#123;&#125;-images"</span>.format(pdf_name)</span><br><span class="line">        <span class="comment"># 为每个pdf创建一个 pdfname-images 的文件夹</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(img_dir):</span><br><span class="line">            os.mkdir(img_dir)</span><br><span class="line">        pdf2image(f, img_dir)</span><br><span class="line"></span><br><span class="line">    input(<span class="string">'Enter'</span>)</span><br></pre></td></tr></table></figure><p>运行程序，以”MUSIQ: Multi-scale Image Quality Transformer”论文为例，获取到了如下图片</p><img src="/2022/04/29/Python从PDF提取图片/01.PNG">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;阅读PDF格式的论文或者一些书籍时，经常希望将PDF文件中的图片提取出来，市面上有些PDF格式转换的工具可以做到，但是很多都要收费。通过Python的pymupdf库可以完成该功能&lt;/p&gt;
&lt;p&gt;安装pymupdf&lt;/p&gt;
&lt;figure class=&quot;highlight 
      
    
    </summary>
    
      <category term="CS" scheme="http://yoursite.com/categories/CS/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/CS/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
</feed>
